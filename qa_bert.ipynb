{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InscribeDeeper/bert_utils/blob/master/qa_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "3SsX3j3sfBKk"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Baseline-3:-BioBERT-Pretrained---CNN-only\" data-toc-modified-id=\"Baseline-3:-BioBERT-Pretrained---CNN-only-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Baseline 3: BioBERT Pretrained - CNN only</a></span></li><li><span><a href=\"#1.-Setup\" data-toc-modified-id=\"1.-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Setup</a></span></li><li><span><a href=\"#2.-Parse-data\" data-toc-modified-id=\"2.-Parse-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Parse data</a></span></li><li><span><a href=\"#3.-Tokenization-&amp;-Input-Formatting\" data-toc-modified-id=\"3.-Tokenization-&amp;-Input-Formatting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3. Tokenization &amp; Input Formatting</a></span></li><li><span><a href=\"#4.-Define-model\" data-toc-modified-id=\"4.-Define-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Define model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#6.1.-Evalution-Function\" data-toc-modified-id=\"6.1.-Evalution-Function-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>6.1. Evalution Function</a></span></li></ul></li><li><span><a href=\"#6.3.-4-fold-cross-validation;-one-vs-the-rest\" data-toc-modified-id=\"6.3.-4-fold-cross-validation;-one-vs-the-rest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>6.3. 4-fold cross validation; one-vs-the-rest</a></span></li></ul></li><li><span><a href=\"#7.-Train-a-model-with-all-data-for-prediction\" data-toc-modified-id=\"7.-Train-a-model-with-all-data-for-prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>7. Train a model with all data for prediction</a></span></li><li><span><a href=\"#Predict-sentences\" data-toc-modified-id=\"Predict-sentences-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Predict sentences</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Baseline 3: BioBERT Pretrained - CNN only\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w8elk83nAFKM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmmaqGLR1xx",
        "outputId": "feea701f-87c2-4905-bd5b-6c361498bf0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqHIo4Bzmcef"
      },
      "outputs": [],
      "source": [
        "#pip install --target=$package_path torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LealyJc7ZC8b",
        "outputId": "6d202a50-4600-4f3e-e28c-9c4efa04980e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# nb_path = '/content/rl'\n",
        "# #os.symlink('/content/drive/MyDrive/Colab_Notebooks', nb_path)\n",
        "\n",
        "# package_path = '/content/drive/MyDrive/Colab_Notebooks/packages'\n",
        "# sys.path.insert(0,nb_path)\n",
        "# sys.path.insert(0,package_path)\n",
        "\n",
        "cur_path = os.path.join('/content/drive/MyDrive/Conf_Call/','Conf_Call')\n",
        "print(os.getcwd())\n",
        "os.chdir(cur_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ArSJvtVIJF8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60846ce6-742a-4da1-a0ea-cdaa55cb5678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 76.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import random, pickle\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0X48D4v42vH",
        "outputId": "5fc31629-8ba3-4f9b-a34d-6b1c8c8977cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 25 16:30:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "a99b6e07-5ae3-40be-e9ec-bb1bc90e93ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    device_name =\"/cpu:0\"\n",
        "    print('GPU device not found')\n",
        "    #raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "74441ebe-8219-47fa-d14a-50bc360a18a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available(): \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rs3nVLsyRcJ"
      },
      "source": [
        "Download BioBERT Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "# 2. Parse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "caaea12b-a12e-44d0-e8a4-1096cae8cc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 1,173\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "506   And you are targeting, it sounds like multiple...      0\n",
              "220   Unusual to see CN change guidance this early i...      1\n",
              "1043  And then real briefly on TiO2 feedstock pricin...      0\n",
              "977   I think you mentioned hundreds of units from o...      0\n",
              "174   It??s amazing that there is no common period e...      1\n",
              "584   And finally, I got to ask Atish what??s the bi...      0\n",
              "786   If I was reading the document correctly, it lo...      1\n",
              "1139  So, it wouldn??t have been a material contribu...      0\n",
              "58    I'm wondering why you think we're not seeing i...      1\n",
              "240   And you referred that the last time you saw th...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-328874be-e9c3-4b12-b611-a6d87a470474\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>And you are targeting, it sounds like multiple...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Unusual to see CN change guidance this early i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>And then real briefly on TiO2 feedstock pricin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>I think you mentioned hundreds of units from o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>It??s amazing that there is no common period e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>And finally, I got to ask Atish what??s the bi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>If I was reading the document correctly, it lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>So, it wouldn??t have been a material contribu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>I'm wondering why you think we're not seeing i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>And you referred that the last time you saw th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-328874be-e9c3-4b12-b611-a6d87a470474')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-328874be-e9c3-4b12-b611-a6d87a470474 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-328874be-e9c3-4b12-b611-a6d87a470474');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/temp/merge_qa_label.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = pd.read_csv(\"surprise_checking_internal_0905.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = df[df.Negative==0]\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 2'], axis=1)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/temp/surprise_dt_test_v9_all_kiera.xlsx\")\n",
        "# #df = df[df.Negative==0]\n",
        "# # Report the number of sentences.\n",
        "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "# df = df.drop(['Unnamed: 0'], axis=1)\n",
        "# df = df.rename(columns={'merged':'label'})\n",
        "# # Display 10 random rows from the data.\n",
        "# df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OubtD2dURIfo",
        "outputId": "97d70d4d-b6c5-45a1-cf1c-54f8b9fa6aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1173"
            ]
          },
          "metadata": {},
          "execution_count": 187
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    928\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "len(df)\n",
        "#df[\"label\"] =df[\"label\"].fillna(0)\n",
        "df= df[~df['label'].isna()]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpDUjP7Bu4f",
        "outputId": "35ada8e0-21bb-4a93-9071-c9a152b8b94c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    280\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ],
      "source": [
        "neg = 280\n",
        "import sklearn\n",
        "negs = sklearn.utils.shuffle(df[df.label==0].index.tolist())\n",
        "df = df[(df.label==1) | (df.index.isin(negs[0:neg]))]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.label==0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pfEM9QjFB3MM",
        "outputId": "9c7b56f9-69e0-48c4-ef12-56082392b549"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "0     But I??m just wondering how you actually manag...      0\n",
              "8                                 What was that all in?      0\n",
              "10    Is that any different than it was nine months ...      0\n",
              "30                             How did that come about?      0\n",
              "40    So there wasn't an unusual boost in the North ...      0\n",
              "...                                                 ...    ...\n",
              "1157  And then one other, right; recently, you guys ...      0\n",
              "1159  And then, this contract Salisbury municipality...      0\n",
              "1160  And so how do you see the uptick of that produ...      0\n",
              "1163  I wondered if we could walk through some of th...      0\n",
              "1171  Tim, in your working cap comments, you noted h...      0\n",
              "\n",
              "[280 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e552d9-9398-461e-959b-371b0f0381b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But I??m just wondering how you actually manag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What was that all in?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Is that any different than it was nine months ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How did that come about?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>So there wasn't an unusual boost in the North ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>And then one other, right; recently, you guys ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>And then, this contract Salisbury municipality...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>And so how do you see the uptick of that produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>I wondered if we could walk through some of th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>Tim, in your working cap comments, you noted h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e552d9-9398-461e-959b-371b0f0381b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88e552d9-9398-461e-959b-371b0f0381b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88e552d9-9398-461e-959b-371b0f0381b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuE5BqICAne2",
        "outputId": "87c74701-1af0-4ada-a009-8f7f75ba6d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = [0,1]\n",
        "num_labels = len(labels)\n",
        "df.label.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnyOs8zP8YO",
        "outputId": "eeff1cd6-9fb6-42eb-cd31-8c492cd62a8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 191
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "525\n"
          ]
        }
      ],
      "source": [
        "labels[0:2]\n",
        "print(len(labels))\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "f67c74d09a0945ee97355af7239cb651",
            "7b3f8fe8358d45eaa3706f0829c79817",
            "caed9a071bc745a2857058a4a4063e32",
            "0465b7653db24968b380b9bfcaf898bb",
            "f2ef91a14fe44625b6809e2215f91a3f",
            "a6269806109b433685b58a6bc78f3fe9",
            "940fd10c139948fe85800b4ae73c60cb",
            "a2cd5716e1af4a60b851c2d99c41de7a",
            "4d4e7b4213434d1dbdaa29520f941875",
            "5f2101773bc04933874b1eaf7722f98e",
            "c934695b26154716950f1ba524805e78",
            "99cea7ceba6a4988aa35a759a0c410ce",
            "70f7e7797b374ccc90dbeaab0c2bdf8a",
            "007283e86f0b40918f2bb10ec801cb94",
            "cc13d881468f4b5f8de9bab87097415c",
            "565c06d5fa514b9383ad8414a04f7319",
            "b2246878cba6463690d50f5dd3363a3e",
            "af943e7be0c448d59e6c737c6976fc1b",
            "3b7c311968d54993aeaac0c7779df467",
            "dcaffe1c4c434c9a8b0b8663829b7a82",
            "722daaf92e8141648d07f3e09e960aec",
            "7cf5649e7e604346a0878c2ddeefce66",
            "04e918961e3540c39900d9f43222b0a4",
            "3189bc013269420389cfc8873ce80282",
            "f76d1c8526f24cb69f01ed55fd7c809a",
            "9fc39419759147789e8f5f6cf5a0f66f",
            "aa7f6b2443c84089bb9f1ae30feedb0f",
            "405d5a90ffef48389ccd021f6422d8b1",
            "310db65441b54cd7b8ff5dbea471cef1",
            "942d292328874819a75f72edd818fb38",
            "b4101a18bc2f4a42a45b67838517f398",
            "415d6e98062342e0965d6f7c622d4a40",
            "74baafd6680c454f935942ff04291882",
            "32fa012b008d41c1b7c5000701f16574",
            "146300563b214a22a45177a6d344ab8d",
            "9e6ff21f0d3b4425bff75827505625f1",
            "e879aa4fc46f46299cc16e28f20603f4",
            "2a734800efa94f00be5b10433efc93af",
            "3f1f6f72a35f45be994ecb0b29d571ff",
            "d3bb73d18f71487fa6f25d8e8f703066",
            "5714135c1c28421d972e4c22df668d6a",
            "51126ea631154a99bdac0fd7ff68afa4",
            "e381b668cda141ba963a7673b46b600b",
            "7ab5e0f88d504b509dfb602e81a2d1c9"
          ]
        },
        "id": "Z474sSC6oe7A",
        "outputId": "312a51a0-caf6-4b65-dfa3-ad076b75cbee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f67c74d09a0945ee97355af7239cb651"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99cea7ceba6a4988aa35a759a0c410ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04e918961e3540c39900d9f43222b0a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32fa012b008d41c1b7c5000701f16574"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True )\n",
        "# tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-pretrain', do_lower_case=True )\n",
        "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert', do_lower_case=True )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQO0EzmI-Ck",
        "outputId": "9af54cce-28fc-4e5e-c222-6b600e8d9889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  But I??m just wondering how you actually manage that, when you??re looking at your underwriting teams and trying to manage their risks properly around a business that??s growing at such a high rate.\n",
            "Tokenized:  ['but', 'i', '?', '?', 'm', 'just', 'wondering', 'how', 'you', 'actually', 'manage', 'that', ',', 'when', 'you', '?', '?', 're', 'looking', 'at', 'your', 'under', '##writing', 'teams', 'and', 'trying', 'to', 'manage', 'their', 'risks', 'properly', 'around', 'a', 'business', 'that', '?', '?', 's', 'growing', 'at', 'such', 'a', 'high', 'rate', '.']\n",
            "Token IDs:  [2021, 1045, 1029, 1029, 1049, 2074, 6603, 2129, 2017, 2941, 6133, 2008, 1010, 2043, 2017, 1029, 1029, 2128, 2559, 2012, 2115, 2104, 18560, 2780, 1998, 2667, 2000, 6133, 2037, 10831, 7919, 2105, 1037, 2449, 2008, 1029, 1029, 1055, 3652, 2012, 2107, 1037, 2152, 3446, 1012]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c99c9e8806cf42018fcca8fcfb08e459",
            "4b7b9cbb625d4b85a8b65d86a6b66321",
            "b418bbdbd94348c59515e2c8d5250fcb",
            "e0fcb27adfb54e4a8bf7f23e972e3c8f",
            "fca5d38e61ac4ba4a88b40bc6375daf1",
            "3a8d269656c0429cbd0a4930c59fcfb9",
            "f0c04f18aee14fdd9047f3016347d73a",
            "eb795dc03de94e15bacf50d5ddcac1e4",
            "c3c6a01183fc405aac482d83ec45f5e7",
            "bc348963ff6040749dfc48c002035608",
            "1ef5e61106ec42e58f945ba5c38efbfa"
          ]
        },
        "id": "YxP_VbyCsjXN",
        "outputId": "fa7215c0-b5e0-4d04-e199-23775f0e2be7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99c9e8806cf42018fcca8fcfb08e459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ],
      "source": [
        "\n",
        "bert_model = AutoModel.from_pretrained(\n",
        "    'ProsusAI/finbert',\n",
        "    num_labels = 3, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "        \n",
        "    )\n",
        "bert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "I8WiOzGYTyEW"
      },
      "outputs": [],
      "source": [
        "# Put everything together as a function. This is for pretrained word vectors\n",
        "\n",
        "def get_pretrained_wordvector(sentences, tokenizer, bert_model):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    max_len =100\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        #padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    \n",
        "    # get the last four layers\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # permute axis\n",
        "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # take the mean of the last 4 layers\n",
        "    token_embeddings = token_embeddings.mean(axis=2)\n",
        "\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    return token_embeddings, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpy4z_hVKG2",
        "outputId": "0a0a7feb-64fe-4a33-885b-167e9485f479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 100])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model)\n",
        "print(masks.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "EQvRzM10sped",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b48ac6-d720-44b0-a710-06a5ad653d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 100, 768])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device)\n",
        "print(token_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJ1ZA4etjHG"
      },
      "source": [
        "# 4. Define model\n",
        "\n",
        "\n",
        "The model has two layers:\n",
        "BiLSTM\n",
        "CNN\n",
        "Dense Layer\n",
        "\n",
        "Depending on loss function used, this model can be single-label or multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "exhSQc_7tnqz"
      },
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.emb_dim)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "kzlP7U3xU65k"
      },
      "outputs": [],
      "source": [
        "class lstm_cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, lstm_units, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_units = lstm_units\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        self.lstm = nn.LSTM(emb_dim,\n",
        "                            lstm_units,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, 2*self.lstm_units)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNklenpst7LL",
        "outputId": "db008a63-cc73-4d1b-d379-97c61e699b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "cnn                                      [32, 6]                   582\n",
              "├─ModuleList: 1-1                        --                        --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 100, 1]          3,232\n",
              "│    └─Conv2d: 2-2                       [32, 32, 99, 1]           6,432\n",
              "│    └─Conv2d: 2-3                       [32, 32, 98, 1]           9,632\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "├─Dropout: 1-3                           [32, 96]                  --\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "==========================================================================================\n",
              "Total params: 19,878\n",
              "Trainable params: 19,878\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 60.96\n",
              "==========================================================================================\n",
              "Input size (MB): 1.28\n",
              "Forward/backward pass size (MB): 2.43\n",
              "Params size (MB): 0.08\n",
              "Estimated Total Size (MB): 3.79\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ],
      "source": [
        "model = cnn(100, 100, 32, [1,2,3], 6)\n",
        "#summary(model.to(device),(32, 100, 100))\n",
        "\n",
        "summary(model,(32, 100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9jwsr4qorx"
      },
      "source": [
        "#6. **Define a function to train single-label classifier**\n",
        "\n",
        "The loss function is different from multi-label classifer\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* model: model defined\n",
        "*   num_labels: number of labels\n",
        "*   label_cols: label names\n",
        "*   train_dataloader: train data loader\n",
        "*   validation_dataloader: validation data loader\n",
        "*   optimizer: optimizer. default is Adam\n",
        "*   scheduler: adjust learning rate dynamically; default is None.\n",
        "*   epochs: number of epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxPyzYb7Emm"
      },
      "source": [
        "### 6.1. Evalution Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "9ELmiqyd35w8"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, dataloader, class_weight = None):\n",
        "  tokenized_texts = []\n",
        "  true_labels = []\n",
        "  pred_labels = []\n",
        "\n",
        "  threshold = 0.5\n",
        "\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "\n",
        "      logits = model(b_input_ids)\n",
        "      #loss_func = BCELoss()\n",
        "      #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "      if class_weight != None:\n",
        "          pos_weight=torch.tensor(class_weight).to(device)\n",
        "          loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "      else:\n",
        "          loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "      val_loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation          \n",
        "            \n",
        "      total_eval_loss += val_loss.item()\n",
        "    \n",
        "      pred_label = torch.sigmoid(logits)   \n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      \n",
        "      tokenized_texts.append(b_input_ids)\n",
        "      true_labels.append(b_labels)\n",
        "      pred_labels.append(pred_label)\n",
        "\n",
        "    \n",
        "  # Flatten outputs\n",
        "  pred_labels = np.vstack(pred_labels)\n",
        "  true_labels = np.vstack(true_labels)\n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(dataloader)    \n",
        "\n",
        "  return tokenized_texts, pred_labels, true_labels,avg_val_loss\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZAROYal7AfW"
      },
      "source": [
        "##6.2. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "dwcDj_XyqnIb"
      },
      "outputs": [],
      "source": [
        "def train_single_label_model(model, num_labels, label_cols, train_dataloader, validation_dataloader, model_path,\\\n",
        "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
        "                             class_weight = None, patience = 5):\n",
        "\n",
        "    seed_val = 42\n",
        "\n",
        "    threshold = 0.5\n",
        "    #model_path = 'best_model.model'  # save the best model\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "    \n",
        "    best_score = -0.5\n",
        "    best_epoch = 0\n",
        "    cnt = 0\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    if optimizer==None:\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        #print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            #if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "            #    elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                #print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_labels = batch[1].to(device)\n",
        "            \n",
        "            model.zero_grad()        \n",
        "\n",
        "            logits = model(b_input_ids )\n",
        "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
        "            #loss_func = BCELoss()\n",
        "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            # add class weight\n",
        "            if class_weight != None:\n",
        "              pos_weight=torch.tensor(class_weight).to(device)\n",
        "              loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "              loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "            loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            if scheduler!=None:\n",
        "                scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        #training_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        #print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        " \n",
        "        val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "\n",
        "        #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
        "        #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
        "        print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t Val Loss {2:.4f}\\t Val Acc: {3:.4f}\\t Val F1: {4:.4f}\".\\\n",
        "          format(epoch_i +1, avg_train_loss, avg_val_loss, val_acc, val_f1))\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        #validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
        "        #print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': val_f1,\n",
        "                'Best F1': best_score,\n",
        "                'Best epoch': best_epoch\n",
        "                #'Training Time': training_time,\n",
        "                #'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # early stopping\n",
        "        if val_f1 > best_score:\n",
        "            best_score = val_f1\n",
        "            best_epoch = epoch_i + 1\n",
        "            torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
        "            print(\"model saved\")\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            if cnt == patience:\n",
        "                print(\"\\n\")\n",
        "                print(\"early stopping at epoch {0}\".format(epoch_i+1))\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    #print(\"Training complete!\")\n",
        "\n",
        "    #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    return model, training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEeNyw0Keo4y"
      },
      "source": [
        "## 6.3. 4-fold cross validation; one-vs-the-rest\n",
        "Train single label classifier using one vs. the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcExaiA9WeWu",
        "outputId": "1300e41c-7dc1-4c95-9f1c-8cc4261ecdd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors = vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCICxXmenoB",
        "outputId": "115c761e-8374-4850-a44d-8ffa4cae4f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8118\t Val Loss 0.7453\t Val Acc: 0.7257\t Val F1: 71.4286\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6569\t Val Loss 0.6200\t Val Acc: 0.7657\t Val F1: 72.8477\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5050\t Val Loss 0.6735\t Val Acc: 0.7543\t Val F1: 73.9394\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3701\t Val Loss 0.7113\t Val Acc: 0.7314\t Val F1: 72.8324\n",
            "Epoch 5\t Train Loss: 0.2203\t Val Loss 0.8155\t Val Acc: 0.7371\t Val F1: 73.8636\n",
            "Epoch 6\t Train Loss: 0.0929\t Val Loss 1.3549\t Val Acc: 0.7086\t Val F1: 71.8232\n",
            "Epoch 7\t Train Loss: 0.0478\t Val Loss 1.4319\t Val Acc: 0.7371\t Val F1: 72.6190\n",
            "Epoch 8\t Train Loss: 0.0097\t Val Loss 1.5921\t Val Acc: 0.7371\t Val F1: 72.2892\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7262, Recall: 0.7531, F1: 0.7394, Loss: 0.6735\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77        94\n",
            "           1       0.73      0.75      0.74        81\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.75      0.75      0.75       175\n",
            "weighted avg       0.76      0.75      0.75       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8161\t Val Loss 0.7591\t Val Acc: 0.6914\t Val F1: 73.5294\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6622\t Val Loss 0.6685\t Val Acc: 0.6857\t Val F1: 73.9336\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5624\t Val Loss 0.6321\t Val Acc: 0.7314\t Val F1: 73.7430\n",
            "Epoch 4\t Train Loss: 0.4409\t Val Loss 0.6705\t Val Acc: 0.7600\t Val F1: 72.0000\n",
            "Epoch 5\t Train Loss: 0.3080\t Val Loss 0.8175\t Val Acc: 0.7600\t Val F1: 71.2329\n",
            "Epoch 6\t Train Loss: 0.2134\t Val Loss 0.8428\t Val Acc: 0.7600\t Val F1: 74.6988\n",
            "model saved\n",
            "Epoch 7\t Train Loss: 0.0841\t Val Loss 1.1873\t Val Acc: 0.7371\t Val F1: 71.9512\n",
            "Epoch 8\t Train Loss: 0.0262\t Val Loss 1.4107\t Val Acc: 0.7200\t Val F1: 70.6587\n",
            "Epoch 9\t Train Loss: 0.0073\t Val Loss 1.5551\t Val Acc: 0.7314\t Val F1: 72.1893\n",
            "Epoch 10\t Train Loss: 0.0037\t Val Loss 1.8896\t Val Acc: 0.7600\t Val F1: 73.4177\n",
            "Epoch 11\t Train Loss: 0.0038\t Val Loss 2.0150\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "\n",
            "\n",
            "early stopping at epoch 11\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7381, Recall: 0.7561, F1: 0.7470, Loss: 0.8428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77        93\n",
            "           1       0.74      0.76      0.75        82\n",
            "\n",
            "    accuracy                           0.76       175\n",
            "   macro avg       0.76      0.76      0.76       175\n",
            "weighted avg       0.76      0.76      0.76       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8130\t Val Loss 0.7523\t Val Acc: 0.5314\t Val F1: 66.3934\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6333\t Val Loss 0.5747\t Val Acc: 0.7886\t Val F1: 77.0186\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4862\t Val Loss 0.5683\t Val Acc: 0.7943\t Val F1: 79.3103\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3314\t Val Loss 0.6394\t Val Acc: 0.7371\t Val F1: 73.5632\n",
            "Epoch 5\t Train Loss: 0.1870\t Val Loss 0.7998\t Val Acc: 0.7600\t Val F1: 72.7273\n",
            "Epoch 6\t Train Loss: 0.0913\t Val Loss 0.8773\t Val Acc: 0.7543\t Val F1: 73.9394\n",
            "Epoch 7\t Train Loss: 0.0344\t Val Loss 1.1452\t Val Acc: 0.7200\t Val F1: 73.7968\n",
            "Epoch 8\t Train Loss: 0.0072\t Val Loss 1.2523\t Val Acc: 0.7657\t Val F1: 77.3481\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7500, Recall: 0.8415, F1: 0.7931, Loss: 0.5683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.75      0.80        93\n",
            "           1       0.75      0.84      0.79        82\n",
            "\n",
            "    accuracy                           0.79       175\n",
            "   macro avg       0.80      0.80      0.79       175\n",
            "weighted avg       0.80      0.79      0.79       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name =  \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCo2gdbFOuIm",
        "outputId": "6406b84e-ce53-4d73-b1f9-5ee8de984a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.726190  0.753086  0.739394      3\n",
            "1   0.738095  0.756098  0.746988      6\n",
            "2   0.750000  0.841463  0.793103      3\n",
            " \n",
            "       precision    recall        f1  epoch\n",
            "label                                      \n",
            "label   0.738095  0.783549  0.759828    4.0\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "h4n2alcNZ_hW",
        "outputId": "de7c5759-2814-4b93-ecff-c30e12c8e011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ffb631cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 248
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e7UoiE1gjku",
        "outputId": "a19b219a-f277-476f-f961-553ff928d6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors =  vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utiyYW9ud0ur",
        "outputId": "7ba199b4-1d8e-47f6-b2e9-c52256695f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7436\t Val Loss 0.6971\t Val Acc: 0.6057\t Val F1: 67.6056\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5399\t Val Loss 0.6276\t Val Acc: 0.7314\t Val F1: 69.2810\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4514\t Val Loss 0.7157\t Val Acc: 0.6971\t Val F1: 63.4483\n",
            "Epoch 4\t Train Loss: 0.2968\t Val Loss 0.7453\t Val Acc: 0.7200\t Val F1: 68.3871\n",
            "Epoch 5\t Train Loss: 0.1491\t Val Loss 0.9762\t Val Acc: 0.7371\t Val F1: 68.9189\n",
            "Epoch 6\t Train Loss: 0.0724\t Val Loss 1.1622\t Val Acc: 0.7200\t Val F1: 69.1824\n",
            "Epoch 7\t Train Loss: 0.0258\t Val Loss 1.4120\t Val Acc: 0.7314\t Val F1: 70.0637\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0053\t Val Loss 1.6772\t Val Acc: 0.7371\t Val F1: 71.6049\n",
            "model saved\n",
            "Epoch 9\t Train Loss: 0.0017\t Val Loss 1.8654\t Val Acc: 0.7371\t Val F1: 71.6049\n",
            "Epoch 10\t Train Loss: 0.0007\t Val Loss 1.9758\t Val Acc: 0.7371\t Val F1: 71.6049\n",
            "Epoch 11\t Train Loss: 0.0005\t Val Loss 2.0451\t Val Acc: 0.7371\t Val F1: 71.6049\n",
            "Epoch 12\t Train Loss: 0.0006\t Val Loss 2.1101\t Val Acc: 0.7314\t Val F1: 71.1656\n",
            "Epoch 13\t Train Loss: 0.0005\t Val Loss 2.1664\t Val Acc: 0.7314\t Val F1: 71.5152\n",
            "\n",
            "\n",
            "early stopping at epoch 13\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7160, Recall: 0.7160, F1: 0.7160, Loss: 1.6772\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.76      0.76        94\n",
            "           1       0.72      0.72      0.72        81\n",
            "\n",
            "    accuracy                           0.74       175\n",
            "   macro avg       0.74      0.74      0.74       175\n",
            "weighted avg       0.74      0.74      0.74       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7559\t Val Loss 0.7054\t Val Acc: 0.7371\t Val F1: 64.0625\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6196\t Val Loss 0.5608\t Val Acc: 0.7600\t Val F1: 73.7500\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4626\t Val Loss 0.6141\t Val Acc: 0.6857\t Val F1: 73.1707\n",
            "Epoch 4\t Train Loss: 0.3928\t Val Loss 0.5253\t Val Acc: 0.7543\t Val F1: 73.9394\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.2316\t Val Loss 0.6129\t Val Acc: 0.7486\t Val F1: 71.4286\n",
            "Epoch 6\t Train Loss: 0.1114\t Val Loss 0.8851\t Val Acc: 0.6971\t Val F1: 66.6667\n",
            "Epoch 7\t Train Loss: 0.0425\t Val Loss 1.3100\t Val Acc: 0.7257\t Val F1: 66.6667\n",
            "Epoch 8\t Train Loss: 0.0196\t Val Loss 1.3996\t Val Acc: 0.7200\t Val F1: 67.9739\n",
            "Epoch 9\t Train Loss: 0.0067\t Val Loss 1.3389\t Val Acc: 0.7143\t Val F1: 69.5122\n",
            "\n",
            "\n",
            "early stopping at epoch 9\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7349, Recall: 0.7439, F1: 0.7394, Loss: 0.5253\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.77        93\n",
            "           1       0.73      0.74      0.74        82\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.75      0.75      0.75       175\n",
            "weighted avg       0.75      0.75      0.75       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7498\t Val Loss 0.6835\t Val Acc: 0.7086\t Val F1: 74.8768\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5932\t Val Loss 0.5523\t Val Acc: 0.7657\t Val F1: 73.5484\n",
            "Epoch 3\t Train Loss: 0.5133\t Val Loss 0.5940\t Val Acc: 0.7314\t Val F1: 67.1329\n",
            "Epoch 4\t Train Loss: 0.4134\t Val Loss 0.5708\t Val Acc: 0.7829\t Val F1: 75.6410\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.2669\t Val Loss 0.7004\t Val Acc: 0.7771\t Val F1: 76.3636\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1443\t Val Loss 0.8210\t Val Acc: 0.7714\t Val F1: 75.9036\n",
            "Epoch 7\t Train Loss: 0.0505\t Val Loss 1.2544\t Val Acc: 0.7657\t Val F1: 77.8378\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0190\t Val Loss 1.2611\t Val Acc: 0.7886\t Val F1: 78.8571\n",
            "model saved\n",
            "Epoch 9\t Train Loss: 0.0100\t Val Loss 1.5456\t Val Acc: 0.7943\t Val F1: 78.8235\n",
            "Epoch 10\t Train Loss: 0.0033\t Val Loss 1.7144\t Val Acc: 0.7429\t Val F1: 72.0497\n",
            "Epoch 11\t Train Loss: 0.0018\t Val Loss 1.8381\t Val Acc: 0.7600\t Val F1: 75.0000\n",
            "Epoch 12\t Train Loss: 0.0008\t Val Loss 1.9119\t Val Acc: 0.7543\t Val F1: 74.2515\n",
            "Epoch 13\t Train Loss: 0.0006\t Val Loss 1.9654\t Val Acc: 0.7429\t Val F1: 72.7273\n",
            "\n",
            "\n",
            "early stopping at epoch 13\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 256
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7419, Recall: 0.8415, F1: 0.7886, Loss: 1.2611\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.74      0.79        93\n",
            "           1       0.74      0.84      0.79        82\n",
            "\n",
            "    accuracy                           0.79       175\n",
            "   macro avg       0.79      0.79      0.79       175\n",
            "weighted avg       0.79      0.79      0.79       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use our labeled data\n",
        "\n",
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.5]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name = \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oX2u74djlwQ",
        "outputId": "e3e46f59-3491-4958-f3e9-ad513d2484a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.716049  0.716049  0.716049      8\n",
            "1   0.734940  0.743902  0.739394      4\n",
            "2   0.741935  0.841463  0.788571      8\n",
            " \n",
            "       precision    recall        f1     epoch\n",
            "label                                         \n",
            "label   0.730975  0.767138  0.748005  6.666667\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "j99LBCGGHaZw",
        "outputId": "699c4e76-5a7d-4a6d-f81d-7c021f08b899"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ffb686c90>"
            ]
          },
          "metadata": {},
          "execution_count": 258
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_NnDGxRpEI"
      },
      "source": [
        "# 7. Train a model with all data for prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9CMlS_dkAGD",
        "outputId": "cc6347a9-a9a9-4551-c325-3ccf07415ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 259
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7044\t Val Loss 0.5479\t Val Acc: 0.8200\t Val F1: 88.8889\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5295\t Val Loss 0.4106\t Val Acc: 0.8500\t Val F1: 90.9091\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4005\t Val Loss 0.1956\t Val Acc: 0.9200\t Val F1: 95.4023\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.2935\t Val Loss 0.1417\t Val Acc: 0.9800\t Val F1: 98.8095\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1305\t Val Loss 0.0306\t Val Acc: 1.0000\t Val F1: 100.0000\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.0520\t Val Loss 0.0105\t Val Acc: 1.0000\t Val F1: 100.0000\n",
            "Epoch 7\t Train Loss: 0.0138\t Val Loss 0.0045\t Val Acc: 1.0000\t Val F1: 100.0000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.5]\n",
        "\n",
        "epochs = 7\n",
        "\n",
        "result = []\n",
        "X_train =  torch.tensor(vectors)\n",
        "Y_train = torch.tensor(pd.get_dummies(df.label).values)\n",
        "\n",
        "X_val =  torch.tensor(vectors[0:100])\n",
        "Y_val = torch.tensor(pd.get_dummies(df.label).values[0:100])\n",
        "\n",
        "# not needed. just to fulfill the traning function need\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "val_dataset = TensorDataset(X_val, Y_val)  \n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,  # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset, # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "    batch_size = batch_size # Evaluate with this batch size.\n",
        ")\n",
        "\n",
        "model_name = '/content/drive/MyDrive/temp/bert_model/finbert_forpred'\n",
        "model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, \\\n",
        "                                                        epochs = epochs, patience = 8)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNMfeMGJ9ipY"
      },
      "source": [
        "# Predict sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hEii1FGP88n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "3OsAkD8KSPW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d4589f-ffbb-4016-ce84-ee36d63de7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "bert_pred = pd.read_csv('/content/drive/MyDrive/temp/raw_text_forbert.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DD120gtXSPhu",
        "outputId": "f3a716be-9880-4df9-a623-77b5047a7758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text encoded_unique_ticker_ts  \\\n",
              "0  Chun Hong, you're accusing DRAM of being high ...                   new386   \n",
              "1  So you are talking about trending issue rather...                   new386   \n",
              "2  What do you predict the -- I assume it will be...                   new386   \n",
              "3                                   [indiscernible].                   new386   \n",
              "4                           That covers the cooling?                   new386   \n",
              "\n",
              "   rid  \n",
              "0    1  \n",
              "1    2  \n",
              "2    3  \n",
              "3    4  \n",
              "4    5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-898f26e1-ac09-4926-9fe2-e915a655df5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_unique_ticker_ts</th>\n",
              "      <th>rid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chun Hong, you're accusing DRAM of being high ...</td>\n",
              "      <td>new386</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So you are talking about trending issue rather...</td>\n",
              "      <td>new386</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you predict the -- I assume it will be...</td>\n",
              "      <td>new386</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[indiscernible].</td>\n",
              "      <td>new386</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That covers the cooling?</td>\n",
              "      <td>new386</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-898f26e1-ac09-4926-9fe2-e915a655df5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-898f26e1-ac09-4926-9fe2-e915a655df5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-898f26e1-ac09-4926-9fe2-e915a655df5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "bert_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV3NSd1vYOTL",
        "outputId": "52ab35a4-99d2-4a20-bfea-a08c503cb3bb"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                        30\n",
              "encoded_unique_ticker_ts     0\n",
              "rid                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred = bert_pred.dropna()"
      ],
      "metadata": {
        "id": "3_TakBdoYS4g"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NEW0bWBAahp",
        "outputId": "d5ea92f3-3fc7-43de-9f12-242b53123f7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 264
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ],
      "source": [
        "model_path= '/content/drive/MyDrive/temp/bert_model/finbert_forpred'\n",
        "emb_dim = 768\n",
        "seq_len = 100\n",
        "num_filters = 64\n",
        "kernel_sizes = [1,3,5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.5] \n",
        "    \n",
        "the_model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "the_model.load_state_dict(torch.load(model_path))\n",
        "the_model = the_model.to(device)\n",
        "the_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_ids = bert_pred[\"encoded_unique_ticker_ts\"].unique().tolist()\n",
        "len(conf_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsBfoOzUYrcT",
        "outputId": "66afd6cc-350d-44e0-acb6-386ee1f27d33"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59086"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_file = '/content/drive/MyDrive/temp/predict_all_1.csv'\n",
        "checkpoint = 0\n",
        "\n",
        "if os.path.isfile(target_file):\n",
        "  result = pd.read_csv(target_file)\n",
        "\n",
        "  if len(df) >0:\n",
        "    checkpoint = conf_ids.index(result[\"rid\"].iloc[-1])\n",
        "    checkpoint += 1\n",
        "  else:\n",
        "    result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "    result.to_csv(target_file, header=True, index = False)\n",
        "else:\n",
        "  result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "  result.to_csv(target_file, header=True, index = False)\n",
        "\n",
        "print(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmDte7QlYneS",
        "outputId": "ce1c5536-74bb-4f18-d856-f25789034a7d"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "batch_size  = 200\n",
        "\n",
        "for cid in conf_ids[checkpoint:]:\n",
        "  result = bert_pred[bert_pred.encoded_unique_ticker_ts==cid].copy()\n",
        "  preds = []\n",
        "  for i in range(0, len(result), batch_size):\n",
        "    # get embedding\n",
        "    x, masks = get_pretrained_wordvector(result[\"text\"].iloc[i:(i+batch_size)], tokenizer, bert_model)\n",
        "    x =  x * (masks.unsqueeze(-1).to(device))  ## 这里利用的是 broadcasting\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = the_model(x)\n",
        "      pred = torch.softmax(pred, dim = -1)\n",
        "      pred = pred[:,-1].detach().cpu().numpy()\n",
        "\n",
        "      preds.append(pred)\n",
        "     \n",
        "  result[\"predict\"] = np.concatenate(preds, axis = 0)\n",
        "  result.to_csv(target_file, header=False, index= False, mode='a')\n",
        "\n",
        "  checkpoint += 1\n",
        "\n",
        "  if checkpoint%100 ==0:\n",
        "    print(\"{0}: {1: .2f}\".format(checkpoint, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi722JC2YngX",
        "outputId": "e3bca476-240b-408a-e5d8-86f9fe143cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100:  70.28\n",
            "200:  147.35\n",
            "300:  218.12\n",
            "400:  293.78\n",
            "500:  373.25\n",
            "600:  450.51\n",
            "700:  515.71\n",
            "800:  586.18\n",
            "900:  664.94\n",
            "1000:  745.70\n",
            "1100:  822.86\n",
            "1200:  898.21\n",
            "1300:  982.14\n",
            "1400:  1056.61\n",
            "1500:  1128.29\n",
            "1600:  1193.30\n",
            "1700:  1269.25\n",
            "1800:  1343.01\n",
            "1900:  1414.71\n",
            "2000:  1493.92\n",
            "2100:  1576.81\n",
            "2200:  1642.96\n",
            "2300:  1709.66\n",
            "2400:  1787.40\n",
            "2500:  1871.15\n",
            "2600:  1947.11\n",
            "2700:  2016.55\n",
            "2800:  2078.86\n",
            "2900:  2155.22\n",
            "3000:  2224.85\n",
            "3100:  2307.93\n",
            "3200:  2380.65\n",
            "3300:  2459.99\n",
            "3400:  2545.85\n",
            "3500:  2625.93\n",
            "3600:  2712.93\n",
            "3700:  2796.32\n",
            "3800:  2882.21\n",
            "3900:  2967.73\n",
            "4000:  3024.91\n",
            "4100:  3099.06\n",
            "4200:  3180.58\n",
            "4300:  3246.64\n",
            "4400:  3338.28\n",
            "4500:  3409.72\n",
            "4600:  3505.74\n",
            "4700:  3625.07\n",
            "4800:  3713.29\n",
            "4900:  3791.70\n",
            "5000:  3890.49\n",
            "5100:  3968.22\n",
            "5200:  4029.53\n",
            "5300:  4108.15\n",
            "5400:  4206.34\n",
            "5500:  4268.10\n",
            "5600:  4345.82\n",
            "5700:  4445.61\n",
            "5800:  4525.62\n",
            "5900:  4616.72\n",
            "6000:  4676.46\n",
            "6100:  4741.20\n",
            "6200:  4839.26\n",
            "6300:  4913.18\n",
            "6400:  4988.94\n",
            "6500:  5075.59\n",
            "6600:  5189.67\n",
            "6700:  5262.07\n",
            "6800:  5336.59\n",
            "6900:  5410.09\n",
            "7000:  5511.74\n",
            "7100:  5595.46\n",
            "7200:  5673.86\n",
            "7300:  5767.65\n",
            "7400:  5844.87\n",
            "7500:  5928.26\n",
            "7600:  5999.03\n",
            "7700:  6073.98\n",
            "7800:  6169.14\n",
            "7900:  6254.76\n",
            "8000:  6320.58\n",
            "8100:  6404.17\n",
            "8200:  6491.77\n",
            "8300:  6565.54\n",
            "8400:  6669.11\n",
            "8500:  6743.71\n",
            "8600:  6842.69\n",
            "8700:  6933.29\n",
            "8800:  7025.60\n",
            "8900:  7105.51\n",
            "9000:  7182.35\n",
            "9100:  7259.05\n",
            "9200:  7352.25\n",
            "9300:  7446.84\n",
            "9400:  7522.41\n",
            "9500:  7604.12\n",
            "9600:  7682.62\n",
            "9700:  7745.46\n",
            "9800:  7836.45\n",
            "9900:  7926.56\n",
            "10000:  8002.07\n",
            "10100:  8097.35\n",
            "10200:  8173.48\n",
            "10300:  8242.09\n",
            "10400:  8301.99\n",
            "10500:  8388.80\n",
            "10600:  8456.30\n",
            "10700:  8516.38\n",
            "10800:  8585.98\n",
            "10900:  8661.11\n",
            "11000:  8747.15\n",
            "11100:  8848.12\n",
            "11200:  8922.06\n",
            "11300:  8991.66\n",
            "11400:  9076.47\n",
            "11500:  9145.32\n",
            "11600:  9225.38\n",
            "11700:  9293.65\n",
            "11800:  9369.60\n",
            "11900:  9448.50\n",
            "12000:  9533.07\n",
            "12100:  9613.17\n",
            "12200:  9687.16\n",
            "12300:  9763.90\n",
            "12400:  9839.22\n",
            "12500:  9921.27\n",
            "12600:  10005.80\n",
            "12700:  10080.01\n",
            "12800:  10157.34\n",
            "12900:  10238.82\n",
            "13000:  10315.15\n",
            "13100:  10401.93\n",
            "13200:  10480.19\n",
            "13300:  10559.18\n",
            "13400:  10626.21\n",
            "13500:  10709.76\n",
            "13600:  10795.82\n",
            "13700:  10867.88\n",
            "13800:  10958.59\n",
            "13900:  11050.86\n",
            "14000:  11152.65\n",
            "14100:  11214.51\n",
            "14200:  11297.27\n",
            "14300:  11376.69\n",
            "14400:  11468.38\n",
            "14500:  11594.14\n",
            "14600:  11674.22\n",
            "14700:  11765.60\n",
            "14800:  11842.94\n",
            "14900:  11945.78\n",
            "15000:  12036.84\n",
            "15100:  12112.83\n",
            "15200:  12192.14\n",
            "15300:  12282.85\n",
            "15400:  12356.64\n",
            "15500:  12439.12\n",
            "15600:  12506.33\n",
            "15700:  12581.70\n",
            "15800:  12669.87\n",
            "15900:  12746.26\n",
            "16000:  12831.99\n",
            "16100:  12909.39\n",
            "16200:  13019.56\n",
            "16300:  13093.73\n",
            "16400:  13186.92\n",
            "16500:  13251.16\n",
            "16600:  13310.89\n",
            "16700:  13384.63\n",
            "16800:  13452.05\n",
            "16900:  13536.63\n",
            "17000:  13614.23\n",
            "17100:  13689.90\n",
            "17200:  13760.83\n",
            "17300:  13822.72\n",
            "17400:  13901.29\n",
            "17500:  13980.39\n",
            "17600:  14062.24\n",
            "17700:  14131.81\n",
            "17800:  14222.59\n",
            "17900:  14298.16\n",
            "18000:  14379.79\n",
            "18100:  14463.17\n",
            "18200:  14532.39\n",
            "18300:  14608.72\n",
            "18400:  14678.31\n",
            "18500:  14770.70\n",
            "18600:  14845.18\n",
            "18700:  14921.61\n",
            "18800:  15000.47\n",
            "18900:  15068.21\n",
            "19000:  15152.49\n",
            "19100:  15230.44\n",
            "19200:  15299.83\n",
            "19300:  15371.62\n",
            "19400:  15434.22\n",
            "19500:  15519.50\n",
            "19600:  15595.45\n",
            "19700:  15659.97\n",
            "19800:  15765.18\n",
            "19900:  15864.88\n",
            "20000:  15938.23\n",
            "20100:  16020.63\n",
            "20200:  16090.71\n",
            "20300:  16167.83\n",
            "20400:  16229.15\n",
            "20500:  16308.49\n",
            "20600:  16394.78\n",
            "20700:  16460.10\n",
            "20800:  16535.41\n",
            "20900:  16613.07\n",
            "21000:  16668.11\n",
            "21100:  16735.88\n",
            "21200:  16808.04\n",
            "21300:  16882.42\n",
            "21400:  16948.23\n",
            "21500:  17015.57\n",
            "21600:  17089.11\n",
            "21700:  17162.10\n",
            "21800:  17221.98\n",
            "21900:  17293.16\n",
            "22000:  17358.59\n",
            "22100:  17434.17\n",
            "22200:  17509.26\n",
            "22300:  17578.40\n",
            "22400:  17652.94\n",
            "22500:  17738.58\n",
            "22600:  17820.13\n",
            "22700:  17897.35\n",
            "22800:  17958.99\n",
            "22900:  18029.45\n",
            "23000:  18105.69\n",
            "23100:  18184.18\n",
            "23200:  18268.81\n",
            "23300:  18342.36\n",
            "23400:  18426.35\n",
            "23500:  18493.70\n",
            "23600:  18557.20\n",
            "23700:  18631.00\n",
            "23800:  18699.73\n",
            "23900:  18775.66\n",
            "24000:  18853.40\n",
            "24100:  18936.61\n",
            "24200:  19013.15\n",
            "24300:  19090.27\n",
            "24400:  19166.30\n",
            "24500:  19242.48\n",
            "24600:  19332.53\n",
            "24700:  19390.43\n",
            "24800:  19463.89\n",
            "24900:  19537.44\n",
            "25000:  19622.69\n",
            "25100:  19703.74\n",
            "25200:  19779.75\n",
            "25300:  19857.61\n",
            "25400:  19937.92\n",
            "25500:  19998.02\n",
            "25600:  20067.44\n",
            "25700:  20147.44\n",
            "25800:  20231.86\n",
            "25900:  20303.31\n",
            "26000:  20424.93\n",
            "26100:  20503.45\n",
            "26200:  20576.15\n",
            "26300:  20671.89\n",
            "26400:  20760.02\n",
            "26500:  20849.00\n",
            "26600:  20923.96\n",
            "26700:  21005.25\n",
            "26800:  21070.30\n",
            "26900:  21137.08\n",
            "27000:  21207.52\n",
            "27100:  21281.21\n",
            "27200:  21355.03\n",
            "27300:  21425.82\n",
            "27400:  21494.72\n",
            "27500:  21595.26\n",
            "27600:  21663.93\n",
            "27700:  21732.63\n",
            "27800:  21804.01\n",
            "27900:  21886.81\n",
            "28000:  21969.78\n",
            "28100:  22044.49\n",
            "28200:  22128.81\n",
            "28300:  22203.51\n",
            "28400:  22274.74\n",
            "28500:  22354.09\n",
            "28600:  22442.73\n",
            "28700:  22517.06\n",
            "28800:  22592.84\n",
            "28900:  22683.97\n",
            "29000:  22763.68\n",
            "29100:  22836.68\n",
            "29200:  22905.63\n",
            "29300:  22985.57\n",
            "29400:  23062.61\n",
            "29500:  23140.77\n",
            "29600:  23233.19\n",
            "29700:  23321.70\n",
            "29800:  23392.61\n",
            "29900:  23464.84\n",
            "30000:  23546.00\n",
            "30100:  23625.98\n",
            "30200:  23693.84\n",
            "30300:  23794.47\n",
            "30400:  23879.05\n",
            "30500:  23954.46\n",
            "30600:  24036.35\n",
            "30700:  24119.63\n",
            "30800:  24192.67\n",
            "30900:  24269.83\n",
            "31000:  24336.46\n",
            "31100:  24418.79\n",
            "31200:  24498.71\n",
            "31300:  24579.24\n",
            "31400:  24647.76\n",
            "31500:  24718.97\n",
            "31600:  24800.10\n",
            "31700:  24884.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SS7Mm5gdYnlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLrMP2avP8_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "qa_bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f67c74d09a0945ee97355af7239cb651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b3f8fe8358d45eaa3706f0829c79817",
              "IPY_MODEL_caed9a071bc745a2857058a4a4063e32",
              "IPY_MODEL_0465b7653db24968b380b9bfcaf898bb"
            ],
            "layout": "IPY_MODEL_f2ef91a14fe44625b6809e2215f91a3f"
          }
        },
        "7b3f8fe8358d45eaa3706f0829c79817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6269806109b433685b58a6bc78f3fe9",
            "placeholder": "​",
            "style": "IPY_MODEL_940fd10c139948fe85800b4ae73c60cb",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "caed9a071bc745a2857058a4a4063e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cd5716e1af4a60b851c2d99c41de7a",
            "max": 252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d4e7b4213434d1dbdaa29520f941875",
            "value": 252
          }
        },
        "0465b7653db24968b380b9bfcaf898bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2101773bc04933874b1eaf7722f98e",
            "placeholder": "​",
            "style": "IPY_MODEL_c934695b26154716950f1ba524805e78",
            "value": " 252/252 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "f2ef91a14fe44625b6809e2215f91a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6269806109b433685b58a6bc78f3fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940fd10c139948fe85800b4ae73c60cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2cd5716e1af4a60b851c2d99c41de7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4e7b4213434d1dbdaa29520f941875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f2101773bc04933874b1eaf7722f98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c934695b26154716950f1ba524805e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99cea7ceba6a4988aa35a759a0c410ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70f7e7797b374ccc90dbeaab0c2bdf8a",
              "IPY_MODEL_007283e86f0b40918f2bb10ec801cb94",
              "IPY_MODEL_cc13d881468f4b5f8de9bab87097415c"
            ],
            "layout": "IPY_MODEL_565c06d5fa514b9383ad8414a04f7319"
          }
        },
        "70f7e7797b374ccc90dbeaab0c2bdf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2246878cba6463690d50f5dd3363a3e",
            "placeholder": "​",
            "style": "IPY_MODEL_af943e7be0c448d59e6c737c6976fc1b",
            "value": "Downloading config.json: 100%"
          }
        },
        "007283e86f0b40918f2bb10ec801cb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7c311968d54993aeaac0c7779df467",
            "max": 758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcaffe1c4c434c9a8b0b8663829b7a82",
            "value": 758
          }
        },
        "cc13d881468f4b5f8de9bab87097415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722daaf92e8141648d07f3e09e960aec",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf5649e7e604346a0878c2ddeefce66",
            "value": " 758/758 [00:00&lt;00:00, 29.5kB/s]"
          }
        },
        "565c06d5fa514b9383ad8414a04f7319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2246878cba6463690d50f5dd3363a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af943e7be0c448d59e6c737c6976fc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b7c311968d54993aeaac0c7779df467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcaffe1c4c434c9a8b0b8663829b7a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "722daaf92e8141648d07f3e09e960aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf5649e7e604346a0878c2ddeefce66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e918961e3540c39900d9f43222b0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3189bc013269420389cfc8873ce80282",
              "IPY_MODEL_f76d1c8526f24cb69f01ed55fd7c809a",
              "IPY_MODEL_9fc39419759147789e8f5f6cf5a0f66f"
            ],
            "layout": "IPY_MODEL_aa7f6b2443c84089bb9f1ae30feedb0f"
          }
        },
        "3189bc013269420389cfc8873ce80282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_405d5a90ffef48389ccd021f6422d8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_310db65441b54cd7b8ff5dbea471cef1",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "f76d1c8526f24cb69f01ed55fd7c809a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942d292328874819a75f72edd818fb38",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4101a18bc2f4a42a45b67838517f398",
            "value": 231508
          }
        },
        "9fc39419759147789e8f5f6cf5a0f66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_415d6e98062342e0965d6f7c622d4a40",
            "placeholder": "​",
            "style": "IPY_MODEL_74baafd6680c454f935942ff04291882",
            "value": " 226k/226k [00:00&lt;00:00, 534kB/s]"
          }
        },
        "aa7f6b2443c84089bb9f1ae30feedb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405d5a90ffef48389ccd021f6422d8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310db65441b54cd7b8ff5dbea471cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "942d292328874819a75f72edd818fb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4101a18bc2f4a42a45b67838517f398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "415d6e98062342e0965d6f7c622d4a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74baafd6680c454f935942ff04291882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32fa012b008d41c1b7c5000701f16574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_146300563b214a22a45177a6d344ab8d",
              "IPY_MODEL_9e6ff21f0d3b4425bff75827505625f1",
              "IPY_MODEL_e879aa4fc46f46299cc16e28f20603f4"
            ],
            "layout": "IPY_MODEL_2a734800efa94f00be5b10433efc93af"
          }
        },
        "146300563b214a22a45177a6d344ab8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1f6f72a35f45be994ecb0b29d571ff",
            "placeholder": "​",
            "style": "IPY_MODEL_d3bb73d18f71487fa6f25d8e8f703066",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "9e6ff21f0d3b4425bff75827505625f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5714135c1c28421d972e4c22df668d6a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51126ea631154a99bdac0fd7ff68afa4",
            "value": 112
          }
        },
        "e879aa4fc46f46299cc16e28f20603f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e381b668cda141ba963a7673b46b600b",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab5e0f88d504b509dfb602e81a2d1c9",
            "value": " 112/112 [00:00&lt;00:00, 4.08kB/s]"
          }
        },
        "2a734800efa94f00be5b10433efc93af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1f6f72a35f45be994ecb0b29d571ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3bb73d18f71487fa6f25d8e8f703066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5714135c1c28421d972e4c22df668d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51126ea631154a99bdac0fd7ff68afa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e381b668cda141ba963a7673b46b600b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab5e0f88d504b509dfb602e81a2d1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99c9e8806cf42018fcca8fcfb08e459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b7b9cbb625d4b85a8b65d86a6b66321",
              "IPY_MODEL_b418bbdbd94348c59515e2c8d5250fcb",
              "IPY_MODEL_e0fcb27adfb54e4a8bf7f23e972e3c8f"
            ],
            "layout": "IPY_MODEL_fca5d38e61ac4ba4a88b40bc6375daf1"
          }
        },
        "4b7b9cbb625d4b85a8b65d86a6b66321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8d269656c0429cbd0a4930c59fcfb9",
            "placeholder": "​",
            "style": "IPY_MODEL_f0c04f18aee14fdd9047f3016347d73a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "b418bbdbd94348c59515e2c8d5250fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb795dc03de94e15bacf50d5ddcac1e4",
            "max": 437992753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c6a01183fc405aac482d83ec45f5e7",
            "value": 437992753
          }
        },
        "e0fcb27adfb54e4a8bf7f23e972e3c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc348963ff6040749dfc48c002035608",
            "placeholder": "​",
            "style": "IPY_MODEL_1ef5e61106ec42e58f945ba5c38efbfa",
            "value": " 418M/418M [00:06&lt;00:00, 70.0MB/s]"
          }
        },
        "fca5d38e61ac4ba4a88b40bc6375daf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8d269656c0429cbd0a4930c59fcfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c04f18aee14fdd9047f3016347d73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb795dc03de94e15bacf50d5ddcac1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c6a01183fc405aac482d83ec45f5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc348963ff6040749dfc48c002035608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef5e61106ec42e58f945ba5c38efbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
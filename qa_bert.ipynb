{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InscribeDeeper/bert_utils/blob/master/qa_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "3SsX3j3sfBKk"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Baseline-3:-BioBERT-Pretrained---CNN-only\" data-toc-modified-id=\"Baseline-3:-BioBERT-Pretrained---CNN-only-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Baseline 3: BioBERT Pretrained - CNN only</a></span></li><li><span><a href=\"#1.-Setup\" data-toc-modified-id=\"1.-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Setup</a></span></li><li><span><a href=\"#2.-Parse-data\" data-toc-modified-id=\"2.-Parse-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Parse data</a></span></li><li><span><a href=\"#3.-Tokenization-&amp;-Input-Formatting\" data-toc-modified-id=\"3.-Tokenization-&amp;-Input-Formatting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3. Tokenization &amp; Input Formatting</a></span></li><li><span><a href=\"#4.-Define-model\" data-toc-modified-id=\"4.-Define-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Define model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#6.1.-Evalution-Function\" data-toc-modified-id=\"6.1.-Evalution-Function-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>6.1. Evalution Function</a></span></li></ul></li><li><span><a href=\"#6.3.-4-fold-cross-validation;-one-vs-the-rest\" data-toc-modified-id=\"6.3.-4-fold-cross-validation;-one-vs-the-rest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>6.3. 4-fold cross validation; one-vs-the-rest</a></span></li></ul></li><li><span><a href=\"#7.-Train-a-model-with-all-data-for-prediction\" data-toc-modified-id=\"7.-Train-a-model-with-all-data-for-prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>7. Train a model with all data for prediction</a></span></li><li><span><a href=\"#Predict-sentences\" data-toc-modified-id=\"Predict-sentences-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Predict sentences</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Baseline 3: BioBERT Pretrained - CNN only\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w8elk83nAFKM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmmaqGLR1xx",
        "outputId": "feea701f-87c2-4905-bd5b-6c361498bf0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqHIo4Bzmcef"
      },
      "outputs": [],
      "source": [
        "#pip install --target=$package_path torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LealyJc7ZC8b",
        "outputId": "6d202a50-4600-4f3e-e28c-9c4efa04980e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# nb_path = '/content/rl'\n",
        "# #os.symlink('/content/drive/MyDrive/Colab_Notebooks', nb_path)\n",
        "\n",
        "# package_path = '/content/drive/MyDrive/Colab_Notebooks/packages'\n",
        "# sys.path.insert(0,nb_path)\n",
        "# sys.path.insert(0,package_path)\n",
        "\n",
        "cur_path = os.path.join('/content/drive/MyDrive/Conf_Call/','Conf_Call')\n",
        "print(os.getcwd())\n",
        "os.chdir(cur_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ArSJvtVIJF8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60846ce6-742a-4da1-a0ea-cdaa55cb5678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 76.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import random, pickle\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0X48D4v42vH",
        "outputId": "5fc31629-8ba3-4f9b-a34d-6b1c8c8977cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 25 16:30:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "a99b6e07-5ae3-40be-e9ec-bb1bc90e93ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    device_name =\"/cpu:0\"\n",
        "    print('GPU device not found')\n",
        "    #raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "74441ebe-8219-47fa-d14a-50bc360a18a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available(): \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rs3nVLsyRcJ"
      },
      "source": [
        "Download BioBERT Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "# 2. Parse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "caaea12b-a12e-44d0-e8a4-1096cae8cc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 1,173\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "506   And you are targeting, it sounds like multiple...      0\n",
              "220   Unusual to see CN change guidance this early i...      1\n",
              "1043  And then real briefly on TiO2 feedstock pricin...      0\n",
              "977   I think you mentioned hundreds of units from o...      0\n",
              "174   It??s amazing that there is no common period e...      1\n",
              "584   And finally, I got to ask Atish what??s the bi...      0\n",
              "786   If I was reading the document correctly, it lo...      1\n",
              "1139  So, it wouldn??t have been a material contribu...      0\n",
              "58    I'm wondering why you think we're not seeing i...      1\n",
              "240   And you referred that the last time you saw th...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-328874be-e9c3-4b12-b611-a6d87a470474\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>And you are targeting, it sounds like multiple...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Unusual to see CN change guidance this early i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>And then real briefly on TiO2 feedstock pricin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>I think you mentioned hundreds of units from o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>It??s amazing that there is no common period e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>And finally, I got to ask Atish what??s the bi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>If I was reading the document correctly, it lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>So, it wouldn??t have been a material contribu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>I'm wondering why you think we're not seeing i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>And you referred that the last time you saw th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-328874be-e9c3-4b12-b611-a6d87a470474')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-328874be-e9c3-4b12-b611-a6d87a470474 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-328874be-e9c3-4b12-b611-a6d87a470474');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/temp/merge_qa_label.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = pd.read_csv(\"surprise_checking_internal_0905.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = df[df.Negative==0]\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 2'], axis=1)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/temp/surprise_dt_test_v9_all_kiera.xlsx\")\n",
        "# #df = df[df.Negative==0]\n",
        "# # Report the number of sentences.\n",
        "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "# df = df.drop(['Unnamed: 0'], axis=1)\n",
        "# df = df.rename(columns={'merged':'label'})\n",
        "# # Display 10 random rows from the data.\n",
        "# df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OubtD2dURIfo",
        "outputId": "97d70d4d-b6c5-45a1-cf1c-54f8b9fa6aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1173"
            ]
          },
          "metadata": {},
          "execution_count": 187
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    928\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "len(df)\n",
        "#df[\"label\"] =df[\"label\"].fillna(0)\n",
        "df= df[~df['label'].isna()]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpDUjP7Bu4f",
        "outputId": "35ada8e0-21bb-4a93-9071-c9a152b8b94c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    280\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ],
      "source": [
        "neg = 280\n",
        "import sklearn\n",
        "negs = sklearn.utils.shuffle(df[df.label==0].index.tolist())\n",
        "df = df[(df.label==1) | (df.index.isin(negs[0:neg]))]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.label==0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pfEM9QjFB3MM",
        "outputId": "9c7b56f9-69e0-48c4-ef12-56082392b549"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "0     But I??m just wondering how you actually manag...      0\n",
              "8                                 What was that all in?      0\n",
              "10    Is that any different than it was nine months ...      0\n",
              "30                             How did that come about?      0\n",
              "40    So there wasn't an unusual boost in the North ...      0\n",
              "...                                                 ...    ...\n",
              "1157  And then one other, right; recently, you guys ...      0\n",
              "1159  And then, this contract Salisbury municipality...      0\n",
              "1160  And so how do you see the uptick of that produ...      0\n",
              "1163  I wondered if we could walk through some of th...      0\n",
              "1171  Tim, in your working cap comments, you noted h...      0\n",
              "\n",
              "[280 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e552d9-9398-461e-959b-371b0f0381b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But I??m just wondering how you actually manag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What was that all in?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Is that any different than it was nine months ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How did that come about?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>So there wasn't an unusual boost in the North ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>And then one other, right; recently, you guys ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>And then, this contract Salisbury municipality...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>And so how do you see the uptick of that produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>I wondered if we could walk through some of th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>Tim, in your working cap comments, you noted h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e552d9-9398-461e-959b-371b0f0381b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88e552d9-9398-461e-959b-371b0f0381b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88e552d9-9398-461e-959b-371b0f0381b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuE5BqICAne2",
        "outputId": "87c74701-1af0-4ada-a009-8f7f75ba6d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = [0,1]\n",
        "num_labels = len(labels)\n",
        "df.label.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnyOs8zP8YO",
        "outputId": "eeff1cd6-9fb6-42eb-cd31-8c492cd62a8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 191
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "525\n"
          ]
        }
      ],
      "source": [
        "labels[0:2]\n",
        "print(len(labels))\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "3436279b-c60e-40d6-daf2-0fec54ea3838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True )\n",
        "tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-pretrain', do_lower_case=True )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQO0EzmI-Ck",
        "outputId": "53fc2d06-0fce-4af3-c5c5-881357918e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  But I??m just wondering how you actually manage that, when you??re looking at your underwriting teams and trying to manage their risks properly around a business that??s growing at such a high rate.\n",
            "Tokenized:  ['but', 'i', '?', '?', 'm', 'just', 'wondering', 'how', 'you', 'actually', 'manage', 'that', ',', 'when', 'you', '?', '?', 're', 'looking', 'at', 'your', 'underwriting', 'teams', 'and', 'trying', 'to', 'manage', 'their', 'risks', 'properly', 'around', 'a', 'business', 'that', '?', '?', 's', 'growing', 'at', 'such', 'a', 'high', 'rate', '.']\n",
            "Token IDs:  [71, 44, 4642, 4642, 1276, 160, 2382, 283, 40, 828, 968, 15, 585, 181, 40, 4642, 4642, 482, 601, 28, 185, 1484, 3422, 8, 1658, 9, 968, 104, 288, 4252, 576, 11, 54, 15, 4642, 4642, 58, 929, 28, 72, 11, 307, 102, 48]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "25468e2fcf9744cd9d7b521d0fee310d",
            "341ffbd8205b446596ea67b7b6ec9362",
            "98520cae492643a68e1879efd80c2062",
            "f845eca4045348e8ab4804d282df5874",
            "ec013720e3c94a169893d7bd8fa306f6",
            "b77f455c12d543ca8f294a4cd1417603",
            "da28df6af28c40bda5130140bc5f4656",
            "8b2f90f344214fa9b404b4fbb12e193e",
            "9ae1b1004df24059a69fce966093c8f6",
            "c1ffe076b2e94894a5471f8423a28780",
            "7c227e8a94de4ae19df834b4a62a240c"
          ]
        },
        "id": "YxP_VbyCsjXN",
        "outputId": "05ae2a12-4c18-4c42-b757-52e66a187936"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/421M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25468e2fcf9744cd9d7b521d0fee310d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at yiyanghkust/finbert-pretrain were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "\n",
        "bert_model = AutoModel.from_pretrained(\n",
        "    'yiyanghkust/finbert-pretrain',\n",
        "    num_labels = 2, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "        \n",
        "    )\n",
        "bert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "I8WiOzGYTyEW"
      },
      "outputs": [],
      "source": [
        "# Put everything together as a function. This is for pretrained word vectors\n",
        "\n",
        "def get_pretrained_wordvector(sentences, tokenizer, bert_model):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    max_len =100\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        #padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    \n",
        "    # get the last four layers\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # permute axis\n",
        "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # take the mean of the last 4 layers\n",
        "    token_embeddings = token_embeddings.mean(axis=2)\n",
        "\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    return token_embeddings, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpy4z_hVKG2",
        "outputId": "ff157e02-610c-487c-afd3-89a3cc2ee108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 100])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model)\n",
        "print(masks.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "EQvRzM10sped",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6a39bb-5264-4dd4-fc64-8f50a5fba7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 100, 768])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device)\n",
        "print(token_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJ1ZA4etjHG"
      },
      "source": [
        "# 4. Define model\n",
        "\n",
        "\n",
        "The model has two layers:\n",
        "BiLSTM\n",
        "CNN\n",
        "Dense Layer\n",
        "\n",
        "Depending on loss function used, this model can be single-label or multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "exhSQc_7tnqz"
      },
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.emb_dim)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "kzlP7U3xU65k"
      },
      "outputs": [],
      "source": [
        "class lstm_cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, lstm_units, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_units = lstm_units\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        self.lstm = nn.LSTM(emb_dim,\n",
        "                            lstm_units,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, 2*self.lstm_units)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNklenpst7LL",
        "outputId": "f2539bae-9b56-424a-8a42-fffa33ebb68b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "cnn                                      [32, 6]                   582\n",
              "├─ModuleList: 1-1                        --                        --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 100, 1]          3,232\n",
              "│    └─Conv2d: 2-2                       [32, 32, 99, 1]           6,432\n",
              "│    └─Conv2d: 2-3                       [32, 32, 98, 1]           9,632\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "├─Dropout: 1-3                           [32, 96]                  --\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "==========================================================================================\n",
              "Total params: 19,878\n",
              "Trainable params: 19,878\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 60.96\n",
              "==========================================================================================\n",
              "Input size (MB): 1.28\n",
              "Forward/backward pass size (MB): 2.43\n",
              "Params size (MB): 0.08\n",
              "Estimated Total Size (MB): 3.79\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "model = cnn(100, 100, 32, [1,2,3], 6)\n",
        "#summary(model.to(device),(32, 100, 100))\n",
        "\n",
        "summary(model,(32, 100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9jwsr4qorx"
      },
      "source": [
        "#6. **Define a function to train single-label classifier**\n",
        "\n",
        "The loss function is different from multi-label classifer\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* model: model defined\n",
        "*   num_labels: number of labels\n",
        "*   label_cols: label names\n",
        "*   train_dataloader: train data loader\n",
        "*   validation_dataloader: validation data loader\n",
        "*   optimizer: optimizer. default is Adam\n",
        "*   scheduler: adjust learning rate dynamically; default is None.\n",
        "*   epochs: number of epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxPyzYb7Emm"
      },
      "source": [
        "### 6.1. Evalution Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "9ELmiqyd35w8"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, dataloader, class_weight = None):\n",
        "  tokenized_texts = []\n",
        "  true_labels = []\n",
        "  pred_labels = []\n",
        "\n",
        "  threshold = 0.5\n",
        "\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "\n",
        "      logits = model(b_input_ids)\n",
        "      #loss_func = BCELoss()\n",
        "      #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "      if class_weight != None:\n",
        "          pos_weight=torch.tensor(class_weight).to(device)\n",
        "          loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "      else:\n",
        "          loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "      val_loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation          \n",
        "            \n",
        "      total_eval_loss += val_loss.item()\n",
        "    \n",
        "      pred_label = torch.sigmoid(logits)   \n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      \n",
        "      tokenized_texts.append(b_input_ids)\n",
        "      true_labels.append(b_labels)\n",
        "      pred_labels.append(pred_label)\n",
        "\n",
        "    \n",
        "  # Flatten outputs\n",
        "  pred_labels = np.vstack(pred_labels)\n",
        "  true_labels = np.vstack(true_labels)\n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(dataloader)    \n",
        "\n",
        "  return tokenized_texts, pred_labels, true_labels,avg_val_loss\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZAROYal7AfW"
      },
      "source": [
        "##6.2. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "dwcDj_XyqnIb"
      },
      "outputs": [],
      "source": [
        "def train_single_label_model(model, num_labels, label_cols, train_dataloader, validation_dataloader, model_path,\\\n",
        "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
        "                             class_weight = None, patience = 5):\n",
        "\n",
        "    seed_val = 42\n",
        "\n",
        "    threshold = 0.5\n",
        "    #model_path = 'best_model.model'  # save the best model\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "    \n",
        "    best_score = -0.5\n",
        "    best_epoch = 0\n",
        "    cnt = 0\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    if optimizer==None:\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        #print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            #if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "            #    elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                #print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_labels = batch[1].to(device)\n",
        "            \n",
        "            model.zero_grad()        \n",
        "\n",
        "            logits = model(b_input_ids )\n",
        "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
        "            #loss_func = BCELoss()\n",
        "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            # add class weight\n",
        "            if class_weight != None:\n",
        "              pos_weight=torch.tensor(class_weight).to(device)\n",
        "              loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "              loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "            loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            if scheduler!=None:\n",
        "                scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        #training_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        #print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        " \n",
        "        val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "\n",
        "        #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
        "        #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
        "        print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t Val Loss {2:.4f}\\t Val Acc: {3:.4f}\\t Val F1: {4:.4f}\".\\\n",
        "          format(epoch_i +1, avg_train_loss, avg_val_loss, val_acc, val_f1))\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        #validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
        "        #print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': val_f1,\n",
        "                'Best F1': best_score,\n",
        "                'Best epoch': best_epoch\n",
        "                #'Training Time': training_time,\n",
        "                #'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # early stopping\n",
        "        if val_f1 > best_score:\n",
        "            best_score = val_f1\n",
        "            best_epoch = epoch_i + 1\n",
        "            torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
        "            print(\"model saved\")\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            if cnt == patience:\n",
        "                print(\"\\n\")\n",
        "                print(\"early stopping at epoch {0}\".format(epoch_i+1))\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    #print(\"Training complete!\")\n",
        "\n",
        "    #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    return model, training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEeNyw0Keo4y"
      },
      "source": [
        "## 6.3. 4-fold cross validation; one-vs-the-rest\n",
        "Train single label classifier using one vs. the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcExaiA9WeWu",
        "outputId": "7683e202-6113-4ac0-a193-9b2aa7dd8006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors = vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCICxXmenoB",
        "outputId": "92baf86f-fe88-4f7a-97a0-185421f30456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8262\t Val Loss 0.7848\t Val Acc: 0.7600\t Val F1: 72.3684\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.7254\t Val Loss 0.6721\t Val Acc: 0.7371\t Val F1: 73.2558\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5610\t Val Loss 0.6323\t Val Acc: 0.6914\t Val F1: 70.3297\n",
            "Epoch 4\t Train Loss: 0.3812\t Val Loss 0.7150\t Val Acc: 0.7029\t Val F1: 69.4118\n",
            "Epoch 5\t Train Loss: 0.2006\t Val Loss 0.8653\t Val Acc: 0.6857\t Val F1: 69.2737\n",
            "Epoch 6\t Train Loss: 0.0738\t Val Loss 1.1288\t Val Acc: 0.7086\t Val F1: 67.5159\n",
            "Epoch 7\t Train Loss: 0.0307\t Val Loss 1.3505\t Val Acc: 0.7200\t Val F1: 67.9739\n",
            "\n",
            "\n",
            "early stopping at epoch 7\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6923, Recall: 0.7778, F1: 0.7326, Loss: 0.6721\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.70      0.74        94\n",
            "           1       0.69      0.78      0.73        81\n",
            "\n",
            "    accuracy                           0.74       175\n",
            "   macro avg       0.74      0.74      0.74       175\n",
            "weighted avg       0.74      0.74      0.74       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8109\t Val Loss 0.7808\t Val Acc: 0.6171\t Val F1: 67.6329\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6699\t Val Loss 0.7192\t Val Acc: 0.6514\t Val F1: 69.3467\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5443\t Val Loss 0.7145\t Val Acc: 0.6857\t Val F1: 69.9454\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3947\t Val Loss 0.7697\t Val Acc: 0.6800\t Val F1: 66.2651\n",
            "Epoch 5\t Train Loss: 0.2487\t Val Loss 0.9787\t Val Acc: 0.7086\t Val F1: 67.0968\n",
            "Epoch 6\t Train Loss: 0.1344\t Val Loss 1.1088\t Val Acc: 0.6914\t Val F1: 64.9351\n",
            "Epoch 7\t Train Loss: 0.0465\t Val Loss 1.3598\t Val Acc: 0.6800\t Val F1: 65.0000\n",
            "Epoch 8\t Train Loss: 0.0098\t Val Loss 1.7726\t Val Acc: 0.6971\t Val F1: 66.2420\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6337, Recall: 0.7805, F1: 0.6995, Loss: 0.7145\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.60      0.67        93\n",
            "           1       0.63      0.78      0.70        82\n",
            "\n",
            "    accuracy                           0.69       175\n",
            "   macro avg       0.70      0.69      0.69       175\n",
            "weighted avg       0.70      0.69      0.68       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8130\t Val Loss 0.7677\t Val Acc: 0.5486\t Val F1: 66.0944\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6798\t Val Loss 0.6418\t Val Acc: 0.7543\t Val F1: 71.5232\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5172\t Val Loss 0.6198\t Val Acc: 0.7543\t Val F1: 76.2431\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3791\t Val Loss 0.8173\t Val Acc: 0.6743\t Val F1: 71.9212\n",
            "Epoch 5\t Train Loss: 0.2392\t Val Loss 0.7704\t Val Acc: 0.7543\t Val F1: 70.7483\n",
            "Epoch 6\t Train Loss: 0.1536\t Val Loss 1.0059\t Val Acc: 0.7543\t Val F1: 69.9301\n",
            "Epoch 7\t Train Loss: 0.0494\t Val Loss 1.1181\t Val Acc: 0.7543\t Val F1: 71.8954\n",
            "Epoch 8\t Train Loss: 0.0116\t Val Loss 1.4204\t Val Acc: 0.7429\t Val F1: 69.3878\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 224
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6970, Recall: 0.8415, F1: 0.7624, Loss: 0.6198\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.68      0.75        93\n",
            "           1       0.70      0.84      0.76        82\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.76      0.76      0.75       175\n",
            "weighted avg       0.77      0.75      0.75       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name =  \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCo2gdbFOuIm",
        "outputId": "72ad47dc-8f6b-44bf-d84d-f9a0504b269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.692308  0.777778  0.732558      2\n",
            "1   0.633663  0.780488  0.699454      3\n",
            "2   0.696970  0.841463  0.762431      3\n",
            " \n",
            "       precision   recall        f1     epoch\n",
            "label                                        \n",
            "label   0.674314  0.79991  0.731481  2.666667\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "h4n2alcNZ_hW",
        "outputId": "c72cc471-d4a9-4f82-ac7a-60b11f48b668"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ffb21ea10>"
            ]
          },
          "metadata": {},
          "execution_count": 226
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e7UoiE1gjku",
        "outputId": "ae6171f1-0d0f-43d2-c5e1-1df7b6879f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors =  vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utiyYW9ud0ur",
        "outputId": "780e4bdb-0441-4f09-dd4e-c7df027cb0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7386\t Val Loss 0.7120\t Val Acc: 0.5657\t Val F1: 66.6667\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5728\t Val Loss 0.6589\t Val Acc: 0.6857\t Val F1: 60.9929\n",
            "Epoch 3\t Train Loss: 0.4499\t Val Loss 0.7365\t Val Acc: 0.6800\t Val F1: 64.1026\n",
            "Epoch 4\t Train Loss: 0.2960\t Val Loss 0.8463\t Val Acc: 0.6800\t Val F1: 65.4321\n",
            "Epoch 5\t Train Loss: 0.1466\t Val Loss 1.0609\t Val Acc: 0.7029\t Val F1: 64.8649\n",
            "Epoch 6\t Train Loss: 0.0507\t Val Loss 1.3187\t Val Acc: 0.6571\t Val F1: 66.6667\n",
            "\n",
            "\n",
            "early stopping at epoch 6\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5170, Recall: 0.9383, F1: 0.6667, Loss: 0.7120\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.24      0.38        94\n",
            "           1       0.52      0.94      0.67        81\n",
            "\n",
            "    accuracy                           0.57       175\n",
            "   macro avg       0.67      0.59      0.52       175\n",
            "weighted avg       0.68      0.57      0.51       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7579\t Val Loss 0.7168\t Val Acc: 0.7086\t Val F1: 59.8425\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6228\t Val Loss 0.6355\t Val Acc: 0.6629\t Val F1: 70.9360\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4919\t Val Loss 0.5862\t Val Acc: 0.6914\t Val F1: 71.2766\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3833\t Val Loss 0.5789\t Val Acc: 0.7429\t Val F1: 70.5882\n",
            "Epoch 5\t Train Loss: 0.2322\t Val Loss 0.6326\t Val Acc: 0.7486\t Val F1: 74.7126\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1531\t Val Loss 0.8328\t Val Acc: 0.7143\t Val F1: 73.1183\n",
            "Epoch 7\t Train Loss: 0.0474\t Val Loss 0.8946\t Val Acc: 0.7429\t Val F1: 71.3376\n",
            "Epoch 8\t Train Loss: 0.0166\t Val Loss 1.0817\t Val Acc: 0.7371\t Val F1: 70.8861\n",
            "Epoch 9\t Train Loss: 0.0143\t Val Loss 1.6133\t Val Acc: 0.6971\t Val F1: 72.5389\n",
            "Epoch 10\t Train Loss: 0.0167\t Val Loss 1.3455\t Val Acc: 0.7257\t Val F1: 68.8312\n",
            "\n",
            "\n",
            "early stopping at epoch 10\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7065, Recall: 0.7927, F1: 0.7471, Loss: 0.6326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.71      0.75        93\n",
            "           1       0.71      0.79      0.75        82\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.75      0.75      0.75       175\n",
            "weighted avg       0.75      0.75      0.75       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.7686\t Val Loss 0.7319\t Val Acc: 0.5143\t Val F1: 65.8635\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6620\t Val Loss 0.6116\t Val Acc: 0.7143\t Val F1: 64.2857\n",
            "Epoch 3\t Train Loss: 0.5406\t Val Loss 0.5696\t Val Acc: 0.7486\t Val F1: 72.8395\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.4197\t Val Loss 0.6068\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "Epoch 5\t Train Loss: 0.2471\t Val Loss 0.7207\t Val Acc: 0.7371\t Val F1: 71.9512\n",
            "Epoch 6\t Train Loss: 0.1630\t Val Loss 0.8375\t Val Acc: 0.7429\t Val F1: 70.5882\n",
            "Epoch 7\t Train Loss: 0.1029\t Val Loss 0.9776\t Val Acc: 0.7371\t Val F1: 70.1299\n",
            "Epoch 8\t Train Loss: 0.0367\t Val Loss 1.1476\t Val Acc: 0.7200\t Val F1: 68.7898\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7375, Recall: 0.7195, F1: 0.7284, Loss: 0.5696\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77        93\n",
            "           1       0.74      0.72      0.73        82\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.75      0.75      0.75       175\n",
            "weighted avg       0.75      0.75      0.75       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use our labeled data\n",
        "\n",
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.5]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name = \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oX2u74djlwQ",
        "outputId": "9f3c299e-89a9-4b1a-aa7d-dcd05a378e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.517007  0.938272  0.666667      1\n",
            "1   0.706522  0.792683  0.747126      5\n",
            "2   0.737500  0.719512  0.728395      3\n",
            " \n",
            "       precision    recall        f1  epoch\n",
            "label                                      \n",
            "label   0.653676  0.816822  0.714063    3.0\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "j99LBCGGHaZw",
        "outputId": "f49f9e34-2751-4be8-8619-751e0217c542"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ffb7b1390>"
            ]
          },
          "metadata": {},
          "execution_count": 233
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_NnDGxRpEI"
      },
      "source": [
        "# 7. Train a model with all data for prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9CMlS_dkAGD",
        "outputId": "31706041-3501-4a75-dd6a-2ae86c303af6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 1.0442\t Val Loss 0.9735\t Val Acc: 0.4200\t Val F1: 58.5714\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.9452\t Val Loss 0.8931\t Val Acc: 0.4700\t Val F1: 60.7407\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.7860\t Val Loss 0.6529\t Val Acc: 0.7800\t Val F1: 78.0000\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.5258\t Val Loss 0.4638\t Val Acc: 0.8100\t Val F1: 81.1881\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.2619\t Val Loss 0.1767\t Val Acc: 0.9600\t Val F1: 95.3488\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1193\t Val Loss 0.0599\t Val Acc: 0.9600\t Val F1: 95.3488\n",
            "Epoch 7\t Train Loss: 0.0974\t Val Loss 0.0241\t Val Acc: 1.0000\t Val F1: 100.0000\n",
            "model saved\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,5.0]\n",
        "\n",
        "epochs = 7\n",
        "\n",
        "result = []\n",
        "X_train =  torch.tensor(vectors)\n",
        "Y_train = torch.tensor(pd.get_dummies(df.label).values)\n",
        "\n",
        "X_val =  torch.tensor(vectors[0:100])\n",
        "Y_val = torch.tensor(pd.get_dummies(df.label).values[0:100])\n",
        "\n",
        "# not needed. just to fulfill the traning function need\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "val_dataset = TensorDataset(X_val, Y_val)  \n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,  # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset, # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "    batch_size = batch_size # Evaluate with this batch size.\n",
        ")\n",
        "\n",
        "model_name = 'model_kiera_data'\n",
        "model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, \\\n",
        "                                                        epochs = epochs, patience = 8)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNMfeMGJ9ipY"
      },
      "source": [
        "# Predict sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "MJ9V95SC9i_P",
        "outputId": "e8197fb2-9640-4cf3-e7f0-d545cdf34686"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encoded_unique_ticker_ts</th>\n",
              "      <th>rid</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63130</td>\n",
              "      <td>0</td>\n",
              "      <td>Thanks and good afternoon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63130</td>\n",
              "      <td>0</td>\n",
              "      <td>Can you maybe talk a little bit about the spec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63130</td>\n",
              "      <td>0</td>\n",
              "      <td>And would you say they are all behind you in Q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63130</td>\n",
              "      <td>1</td>\n",
              "      <td>Alright, thanks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63130</td>\n",
              "      <td>1</td>\n",
              "      <td>And then you mentioned that H2 kind of results...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   encoded_unique_ticker_ts  ...                                               text\n",
              "0                     63130  ...                         Thanks and good afternoon.\n",
              "1                     63130  ...  Can you maybe talk a little bit about the spec...\n",
              "2                     63130  ...  And would you say they are all behind you in Q...\n",
              "3                     63130  ...                                   Alright, thanks.\n",
              "4                     63130  ...  And then you mentioned that H2 kind of results...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"conf_sents.txt\", encoding=\"ISO-8859-1\", delimiter=\"|\")\n",
        "\n",
        "data = data[[\"encoded_unique_ticker_ts\",\"rid\", \"text\"]]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGvphiKkAIXm",
        "outputId": "60ecaa4f-005c-4e73-94ea-baa45fe48c83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57171"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conf_ids = data[\"encoded_unique_ticker_ts\"].unique().tolist()\n",
        "len(conf_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NEW0bWBAahp",
        "outputId": "28e05764-c7f4-4abe-99e2-735d4aef1b60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path= 'model_internal_data'\n",
        "emb_dim = 768\n",
        "seq_len = 100\n",
        "num_filters = 64\n",
        "kernel_sizes = [1,3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,5.0] \n",
        "    \n",
        "the_model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "the_model.load_state_dict(torch.load(model_path))\n",
        "the_model = the_model.to(device)\n",
        "the_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t79mpg58zA0m",
        "outputId": "67fa5639-cf6d-42da-f64f-e3904315f953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "target_file = 'predict_internal.csv'\n",
        "checkpoint = 0\n",
        "\n",
        "if os.path.isfile(target_file):\n",
        "  result = pd.read_csv(target_file)\n",
        "\n",
        "  if len(df) >0:\n",
        "    checkpoint = conf_ids.index(result[\"encoded_unique_ticker_ts\"].iloc[-1])\n",
        "    checkpoint += 1\n",
        "  else:\n",
        "    result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "    result.to_csv(target_file, header=True, index = False)\n",
        "else:\n",
        "  result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "  result.to_csv(target_file, header=True, index = False)\n",
        "\n",
        "print(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye1selbT-K5t",
        "outputId": "ee2f6358-940b-4e20-ed0e-236a16bf036e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200:  64.74\n",
            "300:  100.77\n",
            "400:  151.02\n",
            "500:  215.93\n",
            "600:  283.33\n",
            "700:  341.33\n",
            "800:  391.78\n",
            "900:  435.79\n",
            "1000:  496.26\n",
            "1100:  546.74\n",
            "1200:  616.97\n",
            "1300:  674.61\n",
            "1400:  740.21\n",
            "1500:  804.40\n",
            "1600:  880.57\n",
            "1700:  938.93\n",
            "1800:  1016.11\n",
            "1900:  1090.54\n",
            "2000:  1152.65\n",
            "2100:  1193.23\n",
            "2200:  1259.16\n",
            "2300:  1326.22\n",
            "2400:  1373.84\n",
            "2500:  1453.23\n",
            "2600:  1516.25\n",
            "2700:  1593.96\n",
            "2800:  1710.42\n",
            "2900:  1796.79\n",
            "3000:  1855.88\n",
            "3100:  1944.66\n",
            "3200:  2003.70\n",
            "3300:  2054.90\n",
            "3400:  2118.33\n",
            "3500:  2204.06\n",
            "3600:  2255.25\n",
            "3700:  2314.09\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "batch_size  = 200\n",
        "\n",
        "for cid in conf_ids[checkpoint:]:\n",
        "  result = data[data.encoded_unique_ticker_ts==cid].copy()\n",
        "  preds = []\n",
        "  for i in range(0, len(result), batch_size):\n",
        "    # get embedding\n",
        "    x, masks = get_pretrained_wordvector(result[\"text\"].iloc[i:(i+batch_size)], tokenizer, bert_model)\n",
        "    x =  x * (masks.unsqueeze(-1).to(device))  ## 这里利用的是 broadcasting\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = the_model(x)\n",
        "      pred = torch.softmax(pred, dim = -1)\n",
        "      pred = pred[:,-1].detach().cpu().numpy()\n",
        "\n",
        "      preds.append(pred)\n",
        "     \n",
        "  result[\"predict\"] = np.concatenate(preds, axis = 0)\n",
        "  result.to_csv(target_file, header=False, index= False, mode='a')\n",
        "\n",
        "  checkpoint += 1\n",
        "\n",
        "  if checkpoint%100 ==0:\n",
        "    print(\"{0}: {1: .2f}\".format(checkpoint, time.time()-start))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44SX1eQAB4Mu",
        "outputId": "0c453e4b-005f-4521-e959-59b0a0ac2065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7222"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = pd.read_csv(target_file)\n",
        "len(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJMCuncNCI6z",
        "outputId": "48bf9fbd-5a9e-4212-aa3b-6eb58cc1481b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([63130, 63132, 63134, 63133, 63131,  6411,  6407,  6410,  6386,\n",
              "        6390,  6394,  6413,  6387,  6383,  6406,  6382,  6395, 15611,\n",
              "        6415,  6397,  6412,  6409,  6414, 61677,  4594, 61676,  4593,\n",
              "        4595, 79028, 43835, 79026, 43836, 79024, 79029, 79018, 79027,\n",
              "       79022, 43837, 43834, 79020, 43839, 43838, 79021, 79019, 78605,\n",
              "       78604, 78601, 24953, 25531, 24955, 78600, 24954, 78599,     7,\n",
              "       24958, 24951, 78597, 24952, 24950, 58322, 58324, 58321, 58323,\n",
              "       58319, 58317, 58320, 58318, 67257, 67258, 70472, 67255, 70470,\n",
              "       67260, 70456, 70468, 70457, 70453, 70465, 70460, 70463, 70471,\n",
              "       70458, 70459, 67254, 70466, 70454, 67256, 23487, 23488, 23490,\n",
              "       23492, 23500, 23495, 23485, 23494, 23489, 23484, 23493, 23491,\n",
              "       23486])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.encoded_unique_ticker_ts.unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "umZm2Ga9CgZe",
        "outputId": "2ef4578a-f962-4ed7-8fdf-ae24c1b6a7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n",
            "44\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encoded_unique_ticker_ts</th>\n",
              "      <th>rid</th>\n",
              "      <th>text</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3894</th>\n",
              "      <td>24954</td>\n",
              "      <td>1324</td>\n",
              "      <td>Congratulations to go around, of course Mr. Fi...</td>\n",
              "      <td>0.977635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3895</th>\n",
              "      <td>24954</td>\n",
              "      <td>1324</td>\n",
              "      <td>Hey Andrew, obviouslyâ¦</td>\n",
              "      <td>0.899015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3896</th>\n",
              "      <td>24954</td>\n",
              "      <td>1325</td>\n",
              "      <td>And of course Howard, congratulations on you b...</td>\n",
              "      <td>0.754190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3897</th>\n",
              "      <td>24954</td>\n",
              "      <td>1326</td>\n",
              "      <td>Andrew obviously very impressive results, volu...</td>\n",
              "      <td>0.202388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3898</th>\n",
              "      <td>24954</td>\n",
              "      <td>1327</td>\n",
              "      <td>Thank you, good morning.</td>\n",
              "      <td>0.779205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3899</th>\n",
              "      <td>24954</td>\n",
              "      <td>1328</td>\n",
              "      <td>Andrew, Howard and Jim lots of moving parts fo...</td>\n",
              "      <td>0.007249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3900</th>\n",
              "      <td>24954</td>\n",
              "      <td>1329</td>\n",
              "      <td>Hi, good morning.</td>\n",
              "      <td>0.363923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3901</th>\n",
              "      <td>24954</td>\n",
              "      <td>1330</td>\n",
              "      <td>Hi, in your previous corporate filings, you sa...</td>\n",
              "      <td>0.980035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3902</th>\n",
              "      <td>24954</td>\n",
              "      <td>1331</td>\n",
              "      <td>Good morning, Andrew.</td>\n",
              "      <td>0.919567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3903</th>\n",
              "      <td>24954</td>\n",
              "      <td>1332</td>\n",
              "      <td>I just wanted to sort of follow on from the ea...</td>\n",
              "      <td>0.793879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3904</th>\n",
              "      <td>24954</td>\n",
              "      <td>1332</td>\n",
              "      <td>But yet there seems to be this perception that...</td>\n",
              "      <td>0.999303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3905</th>\n",
              "      <td>24954</td>\n",
              "      <td>1332</td>\n",
              "      <td>Could you broadly give us your view of supply/...</td>\n",
              "      <td>0.730092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>24954</td>\n",
              "      <td>1333</td>\n",
              "      <td>Thanks and good morning everyone.</td>\n",
              "      <td>0.688436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>24954</td>\n",
              "      <td>1333</td>\n",
              "      <td>Just wondering if you can give us an update on...</td>\n",
              "      <td>0.001918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>24954</td>\n",
              "      <td>1334</td>\n",
              "      <td>Yes, thank you.</td>\n",
              "      <td>0.563987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>24954</td>\n",
              "      <td>1334</td>\n",
              "      <td>How much of that double-digit volume growth in...</td>\n",
              "      <td>0.717780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>24954</td>\n",
              "      <td>1335</td>\n",
              "      <td>Yes, good morning, good morning.</td>\n",
              "      <td>0.710444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>24954</td>\n",
              "      <td>1336</td>\n",
              "      <td>Wall Street analysts are again talking backend...</td>\n",
              "      <td>0.030923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>24954</td>\n",
              "      <td>1337</td>\n",
              "      <td>Good morning.</td>\n",
              "      <td>0.398066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>24954</td>\n",
              "      <td>1337</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>0.173320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3914</th>\n",
              "      <td>24954</td>\n",
              "      <td>1337</td>\n",
              "      <td>I was wondering if you could elaborate on Dow ...</td>\n",
              "      <td>0.013998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3915</th>\n",
              "      <td>24954</td>\n",
              "      <td>1338</td>\n",
              "      <td>Good morning.</td>\n",
              "      <td>0.398066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3916</th>\n",
              "      <td>24954</td>\n",
              "      <td>1338</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>0.173320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3917</th>\n",
              "      <td>24954</td>\n",
              "      <td>1339</td>\n",
              "      <td>I had a couple questions, I guess, I could ask...</td>\n",
              "      <td>0.000346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3918</th>\n",
              "      <td>24954</td>\n",
              "      <td>1339</td>\n",
              "      <td>It looks like you guys really hit an inflectio...</td>\n",
              "      <td>0.914536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3919</th>\n",
              "      <td>24954</td>\n",
              "      <td>1339</td>\n",
              "      <td>And similarly on the margin side, you've now h...</td>\n",
              "      <td>0.999305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3920</th>\n",
              "      <td>24954</td>\n",
              "      <td>1339</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>0.173320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3921</th>\n",
              "      <td>24954</td>\n",
              "      <td>1340</td>\n",
              "      <td>I just have a couple of questions on Ag what w...</td>\n",
              "      <td>0.000056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922</th>\n",
              "      <td>24954</td>\n",
              "      <td>1340</td>\n",
              "      <td>You talked about an asset sale and I know you ...</td>\n",
              "      <td>0.998167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3923</th>\n",
              "      <td>24954</td>\n",
              "      <td>1341</td>\n",
              "      <td>Good morning guys.</td>\n",
              "      <td>0.220604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3924</th>\n",
              "      <td>24954</td>\n",
              "      <td>1342</td>\n",
              "      <td>Good morning.</td>\n",
              "      <td>0.398066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925</th>\n",
              "      <td>24954</td>\n",
              "      <td>1342</td>\n",
              "      <td>I was also curious about that volume in Perfor...</td>\n",
              "      <td>0.805731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3926</th>\n",
              "      <td>24954</td>\n",
              "      <td>1342</td>\n",
              "      <td>Iâm assuming someone most also be selling et...</td>\n",
              "      <td>0.054232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3927</th>\n",
              "      <td>24954</td>\n",
              "      <td>1343</td>\n",
              "      <td>Thanks, could you talk about the impacts that ...</td>\n",
              "      <td>0.689651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3928</th>\n",
              "      <td>24954</td>\n",
              "      <td>1344</td>\n",
              "      <td>Hey good morning, itâs Brian Maguire on for ...</td>\n",
              "      <td>0.134082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3929</th>\n",
              "      <td>24954</td>\n",
              "      <td>1345</td>\n",
              "      <td>Itâs been a while since I got I guess an upd...</td>\n",
              "      <td>0.013977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3930</th>\n",
              "      <td>24954</td>\n",
              "      <td>1345</td>\n",
              "      <td>Iâm just wondering with all the changes in f...</td>\n",
              "      <td>0.279136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3931</th>\n",
              "      <td>24954</td>\n",
              "      <td>1346</td>\n",
              "      <td>Perfect, thank you very much.</td>\n",
              "      <td>0.957114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3932</th>\n",
              "      <td>24954</td>\n",
              "      <td>1346</td>\n",
              "      <td>In credit it is still in the early stages, but...</td>\n",
              "      <td>0.112249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3933</th>\n",
              "      <td>24954</td>\n",
              "      <td>1346</td>\n",
              "      <td>And also have you heard any preliminary feedba...</td>\n",
              "      <td>0.641647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3934</th>\n",
              "      <td>24954</td>\n",
              "      <td>1347</td>\n",
              "      <td>Thank you and good morning.</td>\n",
              "      <td>0.799340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3935</th>\n",
              "      <td>24954</td>\n",
              "      <td>1347</td>\n",
              "      <td>Andrew, in your price declines of 19% overall,...</td>\n",
              "      <td>0.319046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3936</th>\n",
              "      <td>24954</td>\n",
              "      <td>1347</td>\n",
              "      <td>And then across your product chains where are ...</td>\n",
              "      <td>0.009019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3937</th>\n",
              "      <td>24954</td>\n",
              "      <td>1347</td>\n",
              "      <td>Thank you.</td>\n",
              "      <td>0.173320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      encoded_unique_ticker_ts  ...   predict\n",
              "3894                     24954  ...  0.977635\n",
              "3895                     24954  ...  0.899015\n",
              "3896                     24954  ...  0.754190\n",
              "3897                     24954  ...  0.202388\n",
              "3898                     24954  ...  0.779205\n",
              "3899                     24954  ...  0.007249\n",
              "3900                     24954  ...  0.363923\n",
              "3901                     24954  ...  0.980035\n",
              "3902                     24954  ...  0.919567\n",
              "3903                     24954  ...  0.793879\n",
              "3904                     24954  ...  0.999303\n",
              "3905                     24954  ...  0.730092\n",
              "3906                     24954  ...  0.688436\n",
              "3907                     24954  ...  0.001918\n",
              "3908                     24954  ...  0.563987\n",
              "3909                     24954  ...  0.717780\n",
              "3910                     24954  ...  0.710444\n",
              "3911                     24954  ...  0.030923\n",
              "3912                     24954  ...  0.398066\n",
              "3913                     24954  ...  0.173320\n",
              "3914                     24954  ...  0.013998\n",
              "3915                     24954  ...  0.398066\n",
              "3916                     24954  ...  0.173320\n",
              "3917                     24954  ...  0.000346\n",
              "3918                     24954  ...  0.914536\n",
              "3919                     24954  ...  0.999305\n",
              "3920                     24954  ...  0.173320\n",
              "3921                     24954  ...  0.000056\n",
              "3922                     24954  ...  0.998167\n",
              "3923                     24954  ...  0.220604\n",
              "3924                     24954  ...  0.398066\n",
              "3925                     24954  ...  0.805731\n",
              "3926                     24954  ...  0.054232\n",
              "3927                     24954  ...  0.689651\n",
              "3928                     24954  ...  0.134082\n",
              "3929                     24954  ...  0.013977\n",
              "3930                     24954  ...  0.279136\n",
              "3931                     24954  ...  0.957114\n",
              "3932                     24954  ...  0.112249\n",
              "3933                     24954  ...  0.641647\n",
              "3934                     24954  ...  0.799340\n",
              "3935                     24954  ...  0.319046\n",
              "3936                     24954  ...  0.009019\n",
              "3937                     24954  ...  0.173320\n",
              "\n",
              "[44 rows x 4 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(result[result.encoded_unique_ticker_ts == 24954]))\n",
        "print(len(data[data.encoded_unique_ticker_ts == 24954]))\n",
        "\n",
        "result[result.encoded_unique_ticker_ts == 24954]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "qa_bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25468e2fcf9744cd9d7b521d0fee310d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_341ffbd8205b446596ea67b7b6ec9362",
              "IPY_MODEL_98520cae492643a68e1879efd80c2062",
              "IPY_MODEL_f845eca4045348e8ab4804d282df5874"
            ],
            "layout": "IPY_MODEL_ec013720e3c94a169893d7bd8fa306f6"
          }
        },
        "341ffbd8205b446596ea67b7b6ec9362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77f455c12d543ca8f294a4cd1417603",
            "placeholder": "​",
            "style": "IPY_MODEL_da28df6af28c40bda5130140bc5f4656",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "98520cae492643a68e1879efd80c2062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b2f90f344214fa9b404b4fbb12e193e",
            "max": 441551705,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ae1b1004df24059a69fce966093c8f6",
            "value": 441551705
          }
        },
        "f845eca4045348e8ab4804d282df5874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ffe076b2e94894a5471f8423a28780",
            "placeholder": "​",
            "style": "IPY_MODEL_7c227e8a94de4ae19df834b4a62a240c",
            "value": " 421M/421M [00:06&lt;00:00, 69.9MB/s]"
          }
        },
        "ec013720e3c94a169893d7bd8fa306f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77f455c12d543ca8f294a4cd1417603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da28df6af28c40bda5130140bc5f4656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b2f90f344214fa9b404b4fbb12e193e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae1b1004df24059a69fce966093c8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1ffe076b2e94894a5471f8423a28780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c227e8a94de4ae19df834b4a62a240c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
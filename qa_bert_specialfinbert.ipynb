{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InscribeDeeper/bert_utils/blob/master/qa_bert_specialfinbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "3SsX3j3sfBKk"
      },
      "source": [
        "<h1>Table of Contents: training with sub dataset<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Baseline-3:-BioBERT-Pretrained---CNN-only\" data-toc-modified-id=\"Baseline-3:-BioBERT-Pretrained---CNN-only-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Baseline 3: BioBERT Pretrained - CNN only</a></span></li><li><span><a href=\"#1.-Setup\" data-toc-modified-id=\"1.-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Setup</a></span></li><li><span><a href=\"#2.-Parse-data\" data-toc-modified-id=\"2.-Parse-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Parse data</a></span></li><li><span><a href=\"#3.-Tokenization-&amp;-Input-Formatting\" data-toc-modified-id=\"3.-Tokenization-&amp;-Input-Formatting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3. Tokenization &amp; Input Formatting</a></span></li><li><span><a href=\"#4.-Define-model\" data-toc-modified-id=\"4.-Define-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Define model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#6.1.-Evalution-Function\" data-toc-modified-id=\"6.1.-Evalution-Function-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>6.1. Evalution Function</a></span></li></ul></li><li><span><a href=\"#6.3.-4-fold-cross-validation;-one-vs-the-rest\" data-toc-modified-id=\"6.3.-4-fold-cross-validation;-one-vs-the-rest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>6.3. 4-fold cross validation; one-vs-the-rest</a></span></li></ul></li><li><span><a href=\"#7.-Train-a-model-with-all-data-for-prediction\" data-toc-modified-id=\"7.-Train-a-model-with-all-data-for-prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>7. Train a model with all data for prediction</a></span></li><li><span><a href=\"#Predict-sentences\" data-toc-modified-id=\"Predict-sentences-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Predict sentences</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Baseline 3: BioBERT Pretrained - CNN only\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8elk83nAFKM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmmaqGLR1xx",
        "outputId": "923ebd56-18da-4be8-c25e-be85f2d1bfeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHIo4Bzmcef"
      },
      "outputs": [],
      "source": [
        "#pip install --target=$package_path torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LealyJc7ZC8b",
        "outputId": "6e731b2a-275d-4a9d-bd01-7e765ba6d167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# nb_path = '/content/rl'\n",
        "# #os.symlink('/content/drive/MyDrive/Colab_Notebooks', nb_path)\n",
        "\n",
        "# package_path = '/content/drive/MyDrive/Colab_Notebooks/packages'\n",
        "# sys.path.insert(0,nb_path)\n",
        "# sys.path.insert(0,package_path)\n",
        "\n",
        "cur_path = os.path.join('/content/drive/MyDrive/Conf_Call/','Conf_Call')\n",
        "print(os.getcwd())\n",
        "os.chdir(cur_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArSJvtVIJF8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ce6d19-2665-4478-f301-5eff608f5f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import random, pickle\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0X48D4v42vH",
        "outputId": "94b56eed-7091-4a43-8a96-c68ed6df15b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 11 17:05:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "4d156ba9-0ee5-4284-cc5f-9d736c2793c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    device_name =\"/cpu:0\"\n",
        "    print('GPU device not found')\n",
        "    #raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "a1793ef0-6997-469c-8da0-7a259487f442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available(): \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6CJaQXuL0BD",
        "outputId": "98324ae0-a7b4-4424-d1c2-1f0c96e7c139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd8b72b2f50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XygCjrnuL0Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rs3nVLsyRcJ"
      },
      "source": [
        "Download BioBERT Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "# 2. Parse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "690f8a06-7b49-4a0c-dc7b-ba2533c8254e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 1,173\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "316   That is also a same store number because we??v...      0\n",
              "171   How has that sort of changed the marketplace, ...      0\n",
              "396   How has that been trending in the last quarter...      0\n",
              "196   I'm just wondering why is this, given the Olym...      1\n",
              "357   And they are on track to continue that through...      0\n",
              "1058  You don??t think the industry, like everyone s...      0\n",
              "284   So, you are displacing - you are gaining marke...      1\n",
              "1033  How -- what was the timing, like was it at the...      0\n",
              "48    A few questions, first of all on the New Londo...      0\n",
              "366   Why do you think it decelerated from Q3 high s...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22cc9e38-4390-4644-b87a-eec73788fc47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>That is also a same store number because we??v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>How has that sort of changed the marketplace, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>How has that been trending in the last quarter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>I'm just wondering why is this, given the Olym...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>And they are on track to continue that through...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>You don??t think the industry, like everyone s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>So, you are displacing - you are gaining marke...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>How -- what was the timing, like was it at the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>A few questions, first of all on the New Londo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>Why do you think it decelerated from Q3 high s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22cc9e38-4390-4644-b87a-eec73788fc47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22cc9e38-4390-4644-b87a-eec73788fc47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22cc9e38-4390-4644-b87a-eec73788fc47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/temp/merge_qa_label.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = pd.read_csv(\"surprise_checking_internal_0905.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = df[df.Negative==0]\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 2'], axis=1)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/temp/surprise_dt_test_v9_all_kiera.xlsx\")\n",
        "# #df = df[df.Negative==0]\n",
        "# # Report the number of sentences.\n",
        "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "# df = df.drop(['Unnamed: 0'], axis=1)\n",
        "# df = df.rename(columns={'merged':'label'})\n",
        "# # Display 10 random rows from the data.\n",
        "# df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(3)"
      ],
      "metadata": {
        "id": "nlJIz3HcCqQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ecjszS0spgyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OubtD2dURIfo",
        "outputId": "1a8cfbdf-67d6-4994-c8d6-88adb98b2516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1173"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    928\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(df)\n",
        "#df[\"label\"] =df[\"label\"].fillna(0)\n",
        "df= df[~df['label'].isna()]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpDUjP7Bu4f",
        "outputId": "6af07a37-26bd-46b7-d22a-59e87e5506c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    280\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "neg = 280\n",
        "import sklearn\n",
        "negs = sklearn.utils.shuffle(df[df.label==0].index.tolist())\n",
        "df = df[(df.label==1) | (df.index.isin(negs[0:neg]))]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.label==0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pfEM9QjFB3MM",
        "outputId": "3d858d25-ec51-4904-8292-4d8a1d0625ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "0     But I??m just wondering how you actually manag...      0\n",
              "8                                 What was that all in?      0\n",
              "10    Is that any different than it was nine months ...      0\n",
              "30                             How did that come about?      0\n",
              "40    So there wasn't an unusual boost in the North ...      0\n",
              "...                                                 ...    ...\n",
              "1157  And then one other, right; recently, you guys ...      0\n",
              "1159  And then, this contract Salisbury municipality...      0\n",
              "1160  And so how do you see the uptick of that produ...      0\n",
              "1163  I wondered if we could walk through some of th...      0\n",
              "1171  Tim, in your working cap comments, you noted h...      0\n",
              "\n",
              "[280 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But I??m just wondering how you actually manag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What was that all in?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Is that any different than it was nine months ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How did that come about?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>So there wasn't an unusual boost in the North ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>And then one other, right; recently, you guys ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>And then, this contract Salisbury municipality...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>And so how do you see the uptick of that produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>I wondered if we could walk through some of th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>Tim, in your working cap comments, you noted h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/temp/traingsample.csv')"
      ],
      "metadata": {
        "id": "bwLfYDEg6GbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuE5BqICAne2",
        "outputId": "529b9778-1d24-4c71-f21f-41af32f0977a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = [0,1]\n",
        "num_labels = len(labels)\n",
        "df.label.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnyOs8zP8YO",
        "outputId": "fa655350-3470-42c7-aa0c-947e17319305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "525\n"
          ]
        }
      ],
      "source": [
        "labels[0:2]\n",
        "print(len(labels))\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_csv('/content/drive/MyDrive/temp/traingsample.csv',index=False)"
      ],
      "metadata": {
        "id": "8U6RHQC5Ro3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "9140bc9254014524a256b38330f7e2df",
            "7e336a62ed68445f98d8956717cc14ae",
            "0c58a7422b7a46ae8ba2e17b559314a2",
            "f215215edc814edbb1f8bd25882de85c",
            "8ad8a343da8049cc813005a5de9e86f5",
            "f5fea0b915fb4eadbe81ed56d50a3474",
            "5086e81e40054a0ea2fc4f10291105e5",
            "5d40b325408b45ff9bedc9e37f899fa5",
            "d73942f85f294eabb06b2b142b3a52da",
            "856cce17dae24677884e9892817c6f59",
            "f08b11bd68fb4931a35bbba229c8fd78",
            "f65f078a91e14f8a8ad74c8d2f00d6d3",
            "eff0f6e55a884d39b13ab5804f4926be",
            "4ae5c6e1cdaa4d2fa53516d40b76e494",
            "d9868f4b72e545d0b5753094a80fdb13",
            "8fd26e0b1a6e409084616dfa3ec76b19",
            "2953265005324c4ba142859d1ff8adb6",
            "14e0be4ca21342fa9a2d222b8a9f2762",
            "782e644b19f64e0a8a8ecf60a78b5d99",
            "b2bc3fcac066441f86a3ececdb04abf2",
            "336b19c9497745598c3079eec3829397",
            "31b17596b19a47bfb438e064b155a913",
            "8b89152c3bb149b3ae29b1887e472dd0",
            "5667da6fdd844cb3890ffde1dd15075c",
            "8bca7ddc4c784943a74f258b154a26c0",
            "b7a8953b432946dbbe66264cf9133115",
            "69d06ae5f776452f867f8f2637b652d4",
            "a06c23e12d1445ddbe2ec0325bdc02af",
            "be4e4438f04d49c9939b89838033c949",
            "12091a6e14ef46efa718df1d127272f1",
            "f621af9cc0144276893ac540dcba3667",
            "c849f103940b42de85dad0c007635a56",
            "d23d6775089c4233a50fa97771927119",
            "5076a7ea0b3f4ab8abaa47f596bdb274",
            "4208fc2e67c2408092508130e0372f63",
            "ad5c4be50ea744d29a54314f7bddee2b",
            "80fc41ed1e9049f0913bb0b200dfa108",
            "6eb62d69b7934647825c441b8daf807c",
            "1ffc571bf60040d0be2fe38ea1881531",
            "51e000b324f24e2f9503157753283d40",
            "b78079fdaba24b4183f0d58fed6b46a2",
            "0bb421f086f84d939b12b7cadd690399",
            "d41d9d980cd046a980cb6c66c23e32c1",
            "4b9cfd2bbf694a5a9d2ea07540da42b8"
          ]
        },
        "id": "Z474sSC6oe7A",
        "outputId": "be4587c7-504b-460a-f3c1-3bcae9ad2db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9140bc9254014524a256b38330f7e2df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f65f078a91e14f8a8ad74c8d2f00d6d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b89152c3bb149b3ae29b1887e472dd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5076a7ea0b3f4ab8abaa47f596bdb274"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-pretrain', do_lower_case=True )\n",
        "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert', do_lower_case=True )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQO0EzmI-Ck",
        "outputId": "2d1cc518-e4a7-4e55-93ff-d28634db1242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  But I??m just wondering how you actually manage that, when you??re looking at your underwriting teams and trying to manage their risks properly around a business that??s growing at such a high rate.\n",
            "Tokenized:  ['but', 'i', '?', '?', 'm', 'just', 'wondering', 'how', 'you', 'actually', 'manage', 'that', ',', 'when', 'you', '?', '?', 're', 'looking', 'at', 'your', 'under', '##writing', 'teams', 'and', 'trying', 'to', 'manage', 'their', 'risks', 'properly', 'around', 'a', 'business', 'that', '?', '?', 's', 'growing', 'at', 'such', 'a', 'high', 'rate', '.']\n",
            "Token IDs:  [2021, 1045, 1029, 1029, 1049, 2074, 6603, 2129, 2017, 2941, 6133, 2008, 1010, 2043, 2017, 1029, 1029, 2128, 2559, 2012, 2115, 2104, 18560, 2780, 1998, 2667, 2000, 6133, 2037, 10831, 7919, 2105, 1037, 2449, 2008, 1029, 1029, 1055, 3652, 2012, 2107, 1037, 2152, 3446, 1012]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ff95a97ed654f818c85eb84aa78ce87",
            "463226d86f9f4fff92c03e237f43e1fe",
            "48aabb48c8124991b1852d9ad0a7dbcd",
            "1326c43d0a9f4ed09daebe4ed0bfda2b",
            "3595e91a323340ac8bc1b6bb97df38b3",
            "f6b6c0bfe7ab4601b3c9382c21cbc691",
            "44ee7587a9e348539c5820f0fa7140e9",
            "5d6c1c82dd8e41fc80e675cd301f69d1",
            "188121873ee04155b8264ae6588c4ca4",
            "96fd543fc66141dea90f8fc1b0cc2374",
            "ec9a5ff4bbbb4df688827ac30b405714"
          ]
        },
        "id": "YxP_VbyCsjXN",
        "outputId": "e8f915da-3892-4dad-d455-4897488511c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ff95a97ed654f818c85eb84aa78ce87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "bert_model = AutoModel.from_pretrained(\n",
        "    'ProsusAI/finbert',\n",
        "    # 'bert-base-uncased',\n",
        "    num_labels = 3, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "    )\n",
        "bert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8WiOzGYTyEW"
      },
      "outputs": [],
      "source": [
        "# Put everything together as a function. This is for pretrained word vectors\n",
        "\n",
        "def get_pretrained_wordvector(sentences, tokenizer, bert_model):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    max_len =100\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        #padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    \n",
        "    # get the last four layers\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # permute axis\n",
        "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # take the mean of the last 4 layers\n",
        "    token_embeddings = token_embeddings.mean(axis=2)\n",
        "\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    return token_embeddings, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "NDpy4z_hVKG2",
        "outputId": "585e7dd3-389e-4107-ae37-61edcdd188eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2c408e19ee3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pretrained_wordvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
          ]
        }
      ],
      "source": [
        "token_embeddings, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model)\n",
        "print(masks.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQvRzM10sped"
      },
      "outputs": [],
      "source": [
        "token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device)\n",
        "print(token_embeddings.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJ1ZA4etjHG"
      },
      "source": [
        "# 4. Define model\n",
        "\n",
        "\n",
        "The model has two layers:\n",
        "BiLSTM\n",
        "CNN\n",
        "Dense Layer\n",
        "\n",
        "Depending on loss function used, this model can be single-label or multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exhSQc_7tnqz"
      },
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.emb_dim)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzlP7U3xU65k"
      },
      "outputs": [],
      "source": [
        "class lstm_cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, lstm_units, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_units = lstm_units\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        # input: [1173, 100, 768]\n",
        "        # self.norm1 = torch.nn.LayerNorm([self.seq_len , self.emb_dim])\n",
        "        # self.norm1 = nn.BatchNorm1d(seq_len)\n",
        "        self.lstm = nn.LSTM(emb_dim,\n",
        "                            lstm_units,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)  # \n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, 2*self.lstm_units)) for f in self.kernel_sizes])\n",
        "        # self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.lstm_units)) for f in self.kernel_sizes])\n",
        "        #self.norm2 = nn.BatchNorm1d(len(kernel_sizes)*self.num_filters)\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "       # x = self.norm1(x)\n",
        "\n",
        "        x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        #x = self.norm2(x)\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNklenpst7LL",
        "outputId": "8dd9b5d1-6a4c-4694-a643-10f6aec7e849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "cnn                                      [32, 6]                   582\n",
              "├─ModuleList: 1-1                        --                        --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 100, 1]          3,232\n",
              "│    └─Conv2d: 2-2                       [32, 32, 99, 1]           6,432\n",
              "│    └─Conv2d: 2-3                       [32, 32, 98, 1]           9,632\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "├─Dropout: 1-3                           [32, 96]                  --\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "==========================================================================================\n",
              "Total params: 19,878\n",
              "Trainable params: 19,878\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 60.96\n",
              "==========================================================================================\n",
              "Input size (MB): 1.28\n",
              "Forward/backward pass size (MB): 2.43\n",
              "Params size (MB): 0.08\n",
              "Estimated Total Size (MB): 3.79\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model = cnn(100, 100, 32, [1,2,3], 6)\n",
        "#summary(model.to(device),(32, 100, 100))\n",
        "summary(model,(32, 100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9jwsr4qorx"
      },
      "source": [
        "#6. **Define a function to train single-label classifier**\n",
        "\n",
        "The loss function is different from multi-label classifer\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* model: model defined\n",
        "*   num_labels: number of labels\n",
        "*   label_cols: label names\n",
        "*   train_dataloader: train data loader\n",
        "*   validation_dataloader: validation data loader\n",
        "*   optimizer: optimizer. default is Adam\n",
        "*   scheduler: adjust learning rate dynamically; default is None.\n",
        "*   epochs: number of epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxPyzYb7Emm"
      },
      "source": [
        "### 6.1. Evalution Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ELmiqyd35w8"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, dataloader, class_weight = None):\n",
        "  tokenized_texts = []\n",
        "  true_labels = []\n",
        "  pred_labels = []\n",
        "\n",
        "  threshold = 0.5\n",
        "\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "\n",
        "      logits = model(b_input_ids)\n",
        "      #loss_func = BCELoss()\n",
        "      #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "      if class_weight != None:\n",
        "          pos_weight=torch.tensor(class_weight).to(device)\n",
        "          loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "      else:\n",
        "          loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "      val_loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation          \n",
        "            \n",
        "      total_eval_loss += val_loss.item()\n",
        "    \n",
        "      pred_label = torch.sigmoid(logits)   \n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      \n",
        "      tokenized_texts.append(b_input_ids)\n",
        "      true_labels.append(b_labels)\n",
        "      pred_labels.append(pred_label)\n",
        "\n",
        "    \n",
        "  # Flatten outputs\n",
        "  pred_labels = np.vstack(pred_labels)\n",
        "  true_labels = np.vstack(true_labels)\n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(dataloader)    \n",
        "\n",
        "  return tokenized_texts, pred_labels, true_labels,avg_val_loss\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZAROYal7AfW"
      },
      "source": [
        "##6.2. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwcDj_XyqnIb"
      },
      "outputs": [],
      "source": [
        "def train_single_label_model(model, num_labels, label_cols, train_dataloader, validation_dataloader, model_path,\\\n",
        "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
        "                             class_weight = None, patience = 5):\n",
        "\n",
        "    seed_val = 42\n",
        "\n",
        "    threshold = 0.5\n",
        "    #model_path = 'best_model.model'  # save the best model\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "    \n",
        "    best_score = -0.5\n",
        "    best_epoch = 0\n",
        "    cnt = 0\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    if optimizer==None:\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        #print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            #if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "            #    elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                #print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_labels = batch[1].to(device)\n",
        "            \n",
        "            model.zero_grad()        \n",
        "\n",
        "            logits = model(b_input_ids)\n",
        "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
        "            #loss_func = BCELoss()\n",
        "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            # add class weight\n",
        "            if class_weight != None:\n",
        "              pos_weight=torch.tensor(class_weight).to(device)\n",
        "              loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "              loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "            loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            if scheduler!=None:\n",
        "                scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        #training_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        #print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        " \n",
        "        val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "\n",
        "        #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
        "        #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
        "        print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t Val Loss {2:.4f}\\t Val Acc: {3:.4f}\\t Val F1: {4:.4f}\".\\\n",
        "          format(epoch_i +1, avg_train_loss, avg_val_loss, val_acc, val_f1))\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        #validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
        "        #print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': val_f1,\n",
        "                'Best F1': best_score,\n",
        "                'Best epoch': best_epoch\n",
        "                #'Training Time': training_time,\n",
        "                #'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # early stopping\n",
        "        if val_f1 > best_score:\n",
        "            best_score = val_f1\n",
        "            best_epoch = epoch_i + 1\n",
        "            torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
        "            print(\"model saved\")\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            if cnt == patience:\n",
        "                print(\"\\n\")\n",
        "                print(\"early stopping at epoch {0}\".format(epoch_i+1))\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    #print(\"Training complete!\")\n",
        "\n",
        "    #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    return model, training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEeNyw0Keo4y"
      },
      "source": [
        "## 6.3. 4-fold cross validation; one-vs-the-rest\n",
        "Train single label classifier using one vs. the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "XcExaiA9WeWu",
        "outputId": "8bf434ff-8795-4c45-8130-b029a5a7b1f8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c4d50071fafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#labels = list(df1.one_hot_labels.values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#num_labels = len(label_cols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors = vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCICxXmenoB",
        "outputId": "73b44458-434c-497d-e07b-65e9cf919e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8290\t Val Loss 0.7777\t Val Acc: 0.6971\t Val F1: 70.3911\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6995\t Val Loss 0.6528\t Val Acc: 0.7314\t Val F1: 71.5152\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5336\t Val Loss 0.7061\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 4\t Train Loss: 0.3788\t Val Loss 0.7453\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 5\t Train Loss: 0.2493\t Val Loss 0.7977\t Val Acc: 0.7257\t Val F1: 71.7647\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1193\t Val Loss 1.3048\t Val Acc: 0.6914\t Val F1: 70.6522\n",
            "Epoch 7\t Train Loss: 0.0750\t Val Loss 1.4521\t Val Acc: 0.7314\t Val F1: 74.0331\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0150\t Val Loss 1.4820\t Val Acc: 0.7429\t Val F1: 72.0497\n",
            "Epoch 9\t Train Loss: 0.0068\t Val Loss 1.5977\t Val Acc: 0.7486\t Val F1: 72.5000\n",
            "Epoch 10\t Train Loss: 0.0029\t Val Loss 1.8047\t Val Acc: 0.7486\t Val F1: 71.7949\n",
            "Epoch 11\t Train Loss: 0.0024\t Val Loss 1.8821\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 12\t Train Loss: 0.0010\t Val Loss 2.1333\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "\n",
            "\n",
            "early stopping at epoch 12\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6700, Recall: 0.8272, F1: 0.7403, Loss: 1.4521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.65      0.72        94\n",
            "           1       0.67      0.83      0.74        81\n",
            "\n",
            "    accuracy                           0.73       175\n",
            "   macro avg       0.74      0.74      0.73       175\n",
            "weighted avg       0.75      0.73      0.73       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8060\t Val Loss 0.7495\t Val Acc: 0.7257\t Val F1: 73.3333\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6508\t Val Loss 0.6531\t Val Acc: 0.7086\t Val F1: 74.8768\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5120\t Val Loss 0.7055\t Val Acc: 0.7200\t Val F1: 75.3769\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.4442\t Val Loss 0.6932\t Val Acc: 0.7486\t Val F1: 70.2703\n",
            "Epoch 5\t Train Loss: 0.2864\t Val Loss 0.9322\t Val Acc: 0.7371\t Val F1: 67.6056\n",
            "Epoch 6\t Train Loss: 0.2055\t Val Loss 0.8885\t Val Acc: 0.7429\t Val F1: 73.0539\n",
            "Epoch 7\t Train Loss: 0.0849\t Val Loss 1.1818\t Val Acc: 0.7143\t Val F1: 69.8795\n",
            "Epoch 8\t Train Loss: 0.0218\t Val Loss 1.4575\t Val Acc: 0.7200\t Val F1: 72.0000\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6410, Recall: 0.9146, F1: 0.7538, Loss: 0.7055\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.55      0.68        93\n",
            "           1       0.64      0.91      0.75        82\n",
            "\n",
            "    accuracy                           0.72       175\n",
            "   macro avg       0.76      0.73      0.71       175\n",
            "weighted avg       0.77      0.72      0.71       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.8027\t Val Loss 0.7447\t Val Acc: 0.5371\t Val F1: 65.8228\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6225\t Val Loss 0.5784\t Val Acc: 0.7657\t Val F1: 74.8466\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4641\t Val Loss 0.5695\t Val Acc: 0.7714\t Val F1: 75.9036\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3056\t Val Loss 0.6434\t Val Acc: 0.7657\t Val F1: 76.0234\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1460\t Val Loss 0.8293\t Val Acc: 0.7714\t Val F1: 72.9730\n",
            "Epoch 6\t Train Loss: 0.0587\t Val Loss 0.9876\t Val Acc: 0.7429\t Val F1: 71.6981\n",
            "Epoch 7\t Train Loss: 0.0161\t Val Loss 1.3674\t Val Acc: 0.7314\t Val F1: 67.1329\n",
            "Epoch 8\t Train Loss: 0.0202\t Val Loss 1.3070\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "Epoch 9\t Train Loss: 0.0216\t Val Loss 1.3371\t Val Acc: 0.7543\t Val F1: 72.6115\n",
            "\n",
            "\n",
            "early stopping at epoch 9\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7303, Recall: 0.7927, F1: 0.7602, Loss: 0.6434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.74      0.77        93\n",
            "           1       0.73      0.79      0.76        82\n",
            "\n",
            "    accuracy                           0.77       175\n",
            "   macro avg       0.77      0.77      0.77       175\n",
            "weighted avg       0.77      0.77      0.77       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name =  \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCo2gdbFOuIm",
        "outputId": "a28350ab-1146-4810-e0fd-05f286621f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.670000  0.827160  0.740331      7\n",
            "1   0.641026  0.914634  0.753769      3\n",
            "2   0.730337  0.792683  0.760234      4\n",
            " \n",
            "       precision    recall        f1     epoch\n",
            "label                                         \n",
            "label   0.680454  0.844826  0.751445  4.666667\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "h4n2alcNZ_hW",
        "outputId": "9912cb0c-b750-4132-b851-73d018c4d20d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f57a4716750>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e7UoiE1gjku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd32547-4424-4bb3-f957-2580292dbf1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors =  vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utiyYW9ud0ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e84d462-edea-4c4d-c6df-afd384877ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.6666\t Val Loss 0.6339\t Val Acc: 0.6457\t Val F1: 67.7083\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.4935\t Val Loss 0.5564\t Val Acc: 0.7486\t Val F1: 70.2703\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4257\t Val Loss 0.6488\t Val Acc: 0.7200\t Val F1: 66.2069\n",
            "Epoch 4\t Train Loss: 0.2802\t Val Loss 0.6445\t Val Acc: 0.7086\t Val F1: 68.3230\n",
            "Epoch 5\t Train Loss: 0.1513\t Val Loss 0.8183\t Val Acc: 0.7086\t Val F1: 65.3061\n",
            "Epoch 6\t Train Loss: 0.0872\t Val Loss 1.0525\t Val Acc: 0.7143\t Val F1: 64.7887\n",
            "Epoch 7\t Train Loss: 0.0240\t Val Loss 1.2340\t Val Acc: 0.7314\t Val F1: 68.8742\n",
            "\n",
            "\n",
            "early stopping at epoch 7\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7761, Recall: 0.6420, F1: 0.7027, Loss: 0.5564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.84      0.78        94\n",
            "           1       0.78      0.64      0.70        81\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.75      0.74      0.74       175\n",
            "weighted avg       0.75      0.75      0.75       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.6704\t Val Loss 0.6116\t Val Acc: 0.7257\t Val F1: 60.6557\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5551\t Val Loss 0.5002\t Val Acc: 0.7486\t Val F1: 70.2703\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4052\t Val Loss 0.5291\t Val Acc: 0.7086\t Val F1: 71.1864\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3164\t Val Loss 0.5050\t Val Acc: 0.7429\t Val F1: 71.6981\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1827\t Val Loss 0.5716\t Val Acc: 0.7257\t Val F1: 70.3704\n",
            "Epoch 6\t Train Loss: 0.0997\t Val Loss 0.8921\t Val Acc: 0.7314\t Val F1: 64.6617\n",
            "Epoch 7\t Train Loss: 0.0401\t Val Loss 0.9074\t Val Acc: 0.7143\t Val F1: 67.1053\n",
            "Epoch 8\t Train Loss: 0.0157\t Val Loss 1.0623\t Val Acc: 0.7486\t Val F1: 70.2703\n",
            "Epoch 9\t Train Loss: 0.0084\t Val Loss 1.1581\t Val Acc: 0.7657\t Val F1: 73.2026\n",
            "model saved\n",
            "Epoch 10\t Train Loss: 0.0041\t Val Loss 1.2872\t Val Acc: 0.7600\t Val F1: 70.4225\n",
            "Epoch 11\t Train Loss: 0.0025\t Val Loss 1.3902\t Val Acc: 0.7200\t Val F1: 70.3030\n",
            "Epoch 12\t Train Loss: 0.0020\t Val Loss 1.5253\t Val Acc: 0.7371\t Val F1: 65.6716\n",
            "Epoch 13\t Train Loss: 0.0048\t Val Loss 1.5395\t Val Acc: 0.6857\t Val F1: 68.5714\n",
            "Epoch 14\t Train Loss: 0.0012\t Val Loss 1.6156\t Val Acc: 0.7486\t Val F1: 67.6471\n",
            "\n",
            "\n",
            "early stopping at epoch 14\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7887, Recall: 0.6829, F1: 0.7320, Loss: 1.1581\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79        93\n",
            "           1       0.79      0.68      0.73        82\n",
            "\n",
            "    accuracy                           0.77       175\n",
            "   macro avg       0.77      0.76      0.76       175\n",
            "weighted avg       0.77      0.77      0.76       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.6911\t Val Loss 0.6567\t Val Acc: 0.7029\t Val F1: 72.0430\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5788\t Val Loss 0.5247\t Val Acc: 0.7257\t Val F1: 65.2174\n",
            "Epoch 3\t Train Loss: 0.4807\t Val Loss 0.5381\t Val Acc: 0.7143\t Val F1: 63.7681\n",
            "Epoch 4\t Train Loss: 0.3856\t Val Loss 0.5442\t Val Acc: 0.7200\t Val F1: 64.2336\n",
            "Epoch 5\t Train Loss: 0.2474\t Val Loss 0.6139\t Val Acc: 0.7943\t Val F1: 77.5000\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1460\t Val Loss 0.7428\t Val Acc: 0.7600\t Val F1: 73.4177\n",
            "Epoch 7\t Train Loss: 0.0594\t Val Loss 1.0460\t Val Acc: 0.7771\t Val F1: 78.4530\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0157\t Val Loss 1.1674\t Val Acc: 0.7829\t Val F1: 77.3810\n",
            "Epoch 9\t Train Loss: 0.0047\t Val Loss 1.3328\t Val Acc: 0.7543\t Val F1: 73.6196\n",
            "Epoch 10\t Train Loss: 0.0025\t Val Loss 1.5887\t Val Acc: 0.7371\t Val F1: 73.8636\n",
            "Epoch 11\t Train Loss: 0.0016\t Val Loss 1.6098\t Val Acc: 0.7314\t Val F1: 71.5152\n",
            "Epoch 12\t Train Loss: 0.0006\t Val Loss 1.6873\t Val Acc: 0.7371\t Val F1: 73.2558\n",
            "\n",
            "\n",
            "early stopping at epoch 12\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7172, Recall: 0.8659, F1: 0.7845, Loss: 1.0460\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.70      0.77        93\n",
            "           1       0.72      0.87      0.78        82\n",
            "\n",
            "    accuracy                           0.78       175\n",
            "   macro avg       0.79      0.78      0.78       175\n",
            "weighted avg       0.79      0.78      0.78       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use our labeled data\n",
        "\n",
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name = \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oX2u74djlwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360e4c21-2663-4210-e535-500c7d5959a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.776119  0.641975  0.702703      2\n",
            "1   0.788732  0.682927  0.732026      9\n",
            "2   0.717172  0.865854  0.784530      7\n",
            " \n",
            "       precision    recall        f1  epoch\n",
            "label                                      \n",
            "label   0.760675  0.730252  0.739753    6.0\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j99LBCGGHaZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "d8119d49-a16c-4c8a-ad10-dbc6b5141c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f57a40f90d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_NnDGxRpEI"
      },
      "source": [
        "# 7. Train a model with all data for prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9CMlS_dkAGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e45020f-96b2-44e2-e9cf-bdf46d776550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Train Loss: 0.6567\t Val Loss 0.5651\t Val Acc: 0.8100\t Val F1: 88.0503\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5071\t Val Loss 0.4252\t Val Acc: 0.8600\t Val F1: 91.1392\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.3702\t Val Loss 0.1683\t Val Acc: 0.9300\t Val F1: 95.9064\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.2547\t Val Loss 0.0982\t Val Acc: 0.9700\t Val F1: 98.2249\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1427\t Val Loss 0.0568\t Val Acc: 0.9900\t Val F1: 99.4083\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.0603\t Val Loss 0.0425\t Val Acc: 0.9900\t Val F1: 99.4083\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.0]\n",
        "\n",
        "epochs = 6\n",
        "\n",
        "result = []\n",
        "X_train =  torch.tensor(vectors)\n",
        "Y_train = torch.tensor(pd.get_dummies(df.label).values)\n",
        "\n",
        "X_val =  torch.tensor(vectors[0:100])\n",
        "Y_val = torch.tensor(pd.get_dummies(df.label).values[0:100])\n",
        "\n",
        "# not needed. just to fulfill the traning function need\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "val_dataset = TensorDataset(X_val, Y_val)  \n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,  # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset, # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "    batch_size = batch_size # Evaluate with this batch size.\n",
        ")\n",
        "\n",
        "model_name = '/content/drive/MyDrive/temp/bert_model/genbert_forpred_v1'\n",
        "model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, \\\n",
        "                                                        epochs = epochs, patience = 8)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNMfeMGJ9ipY"
      },
      "source": [
        "# Predict sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hEii1FGP88n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OsAkD8KSPW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a431a5cf-4747-4ad4-cdef-0e2fd97c9a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "bert_pred = pd.read_csv('/content/drive/MyDrive/temp/raw_text_forbert.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DD120gtXSPhu",
        "outputId": "4f585d96-c76f-49fb-ce22-931b7040fd97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text encoded_unique_ticker_ts  \\\n",
              "0  Chun Hong, you're accusing DRAM of being high ...                   new386   \n",
              "1  So you are talking about trending issue rather...                   new386   \n",
              "2  What do you predict the -- I assume it will be...                   new386   \n",
              "3                                   [indiscernible].                   new386   \n",
              "4                           That covers the cooling?                   new386   \n",
              "\n",
              "   rid  \n",
              "0    1  \n",
              "1    2  \n",
              "2    3  \n",
              "3    4  \n",
              "4    5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-998a0f3d-7316-4bc0-99c3-880bcf83c586\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_unique_ticker_ts</th>\n",
              "      <th>rid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chun Hong, you're accusing DRAM of being high ...</td>\n",
              "      <td>new386</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So you are talking about trending issue rather...</td>\n",
              "      <td>new386</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you predict the -- I assume it will be...</td>\n",
              "      <td>new386</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[indiscernible].</td>\n",
              "      <td>new386</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That covers the cooling?</td>\n",
              "      <td>new386</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-998a0f3d-7316-4bc0-99c3-880bcf83c586')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-998a0f3d-7316-4bc0-99c3-880bcf83c586 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-998a0f3d-7316-4bc0-99c3-880bcf83c586');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "bert_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV3NSd1vYOTL",
        "outputId": "93c44c36-48d5-4d92-9a49-7ee9e35bfcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                        30\n",
              "encoded_unique_ticker_ts     0\n",
              "rid                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred = bert_pred.dropna()"
      ],
      "metadata": {
        "id": "3_TakBdoYS4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyEiB-RHi-pN",
        "outputId": "e6b8fb36-202b-47e1-f08d-88d94d4725fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4334161, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NEW0bWBAahp",
        "outputId": "31b97b6e-a73f-4c7f-92a3-d4823adb44af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model_path= '/content/drive/MyDrive/temp/bert_model/finbert_forpred_v1'\n",
        "emb_dim = 768\n",
        "seq_len = 100\n",
        "num_filters = 64\n",
        "kernel_sizes = [1,3,5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2] \n",
        "    \n",
        "the_model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "the_model.load_state_dict(torch.load(model_path))\n",
        "the_model = the_model.to(device)\n",
        "the_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_ids = bert_pred[\"encoded_unique_ticker_ts\"].unique().tolist()\n",
        "len(conf_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsBfoOzUYrcT",
        "outputId": "ba391f67-9810-4699-d65c-828a642058b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59086"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_file = '/content/drive/MyDrive/temp/predict_skp_fin.csv'\n",
        "checkpoint = 0\n",
        "\n",
        "if os.path.isfile(target_file):\n",
        "  result = pd.read_csv(target_file)\n",
        "\n",
        "  if len(bert_pred) >0:\n",
        "    checkpoint = conf_ids.index(result[\"rid\"].iloc[-1])\n",
        "    checkpoint += 1\n",
        "  else:\n",
        "    result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "    result.to_csv(target_file, header=True, index = False)\n",
        "else:\n",
        "  result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "  result.to_csv(target_file, header=True, index = False)\n",
        "\n",
        "print(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmDte7QlYneS",
        "outputId": "11e5294d-d86b-4437-8bc4-31008d67d4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoKkAiqbdVnQ",
        "outputId": "f5d6069a-e41a-4a39-a38a-02a59d491e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "batch_size  = 200\n",
        "\n",
        "for cid in conf_ids[checkpoint:]:\n",
        "  result = bert_pred[bert_pred.encoded_unique_ticker_ts==cid].copy()\n",
        "  preds = []\n",
        "  for i in range(0, len(result), batch_size):\n",
        "    # get embedding\n",
        "    x, masks = get_pretrained_wordvector(result[\"text\"].iloc[i:(i+batch_size)], tokenizer, bert_model)\n",
        "    x =  x * (masks.unsqueeze(-1).to(device))  ## 这里利用的是 broadcasting\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = the_model(x)\n",
        "      pred = torch.softmax(pred, dim = -1)\n",
        "      pred = pred[:,-1].detach().cpu().numpy()\n",
        "\n",
        "      preds.append(pred)\n",
        "     \n",
        "  result[\"predict\"] = np.concatenate(preds, axis = 0)\n",
        "  result.to_csv(target_file, header=False, index= False, mode='a')\n",
        "\n",
        "  checkpoint += 1\n",
        "\n",
        "  if checkpoint%100 ==0:\n",
        "    print(\"{0}: {1: .2f}\".format(checkpoint, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi722JC2YngX",
        "outputId": "d5bae746-d47b-4929-c8c3-0ffba2a4b586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100:  48.40\n",
            "200:  99.77\n",
            "300:  148.75\n",
            "400:  200.00\n",
            "500:  252.30\n",
            "600:  303.54\n",
            "700:  350.03\n",
            "800:  398.49\n",
            "900:  449.95\n",
            "1000:  502.41\n",
            "1100:  553.21\n",
            "1200:  603.69\n",
            "1300:  657.62\n",
            "1400:  707.44\n",
            "1500:  756.68\n",
            "1600:  803.49\n",
            "1700:  854.47\n",
            "1800:  904.36\n",
            "1900:  953.44\n",
            "2000:  1005.32\n",
            "2100:  1059.94\n",
            "2200:  1108.12\n",
            "2300:  1156.38\n",
            "2400:  1209.15\n",
            "2500:  1263.94\n",
            "2600:  1315.87\n",
            "2700:  1364.86\n",
            "2800:  1411.03\n",
            "2900:  1462.99\n",
            "3000:  1512.15\n",
            "3100:  1566.36\n",
            "3200:  1616.44\n",
            "3300:  1669.77\n",
            "3400:  1725.78\n",
            "3500:  1779.74\n",
            "3600:  1836.24\n",
            "3700:  1891.21\n",
            "3800:  1946.39\n",
            "3900:  2000.52\n",
            "4000:  2043.04\n",
            "4100:  2092.17\n",
            "4200:  2144.53\n",
            "4300:  2190.76\n",
            "4400:  2247.38\n",
            "4500:  2295.93\n",
            "4600:  2354.58\n",
            "4700:  2423.34\n",
            "4800:  2478.71\n",
            "4900:  2529.87\n",
            "5000:  2590.10\n",
            "5100:  2640.96\n",
            "5200:  2685.41\n",
            "5300:  2736.79\n",
            "5400:  2796.48\n",
            "5500:  2841.00\n",
            "5600:  2892.00\n",
            "5700:  2951.57\n",
            "5800:  3003.30\n",
            "5900:  3059.98\n",
            "6000:  3103.45\n",
            "6100:  3148.92\n",
            "6200:  3208.06\n",
            "6300:  3257.25\n",
            "6400:  3307.26\n",
            "6500:  3361.57\n",
            "6600:  3427.46\n",
            "6700:  3475.50\n",
            "6800:  3524.69\n",
            "6900:  3573.08\n",
            "7000:  3633.41\n",
            "7100:  3686.28\n",
            "7200:  3736.85\n",
            "7300:  3794.08\n",
            "7400:  3844.25\n",
            "7500:  3897.08\n",
            "7600:  3944.68\n",
            "7700:  3994.23\n",
            "7800:  4051.92\n",
            "7900:  4105.64\n",
            "8000:  4151.33\n",
            "8100:  4204.15\n",
            "8200:  4258.55\n",
            "8300:  4307.13\n",
            "8400:  4368.74\n",
            "8500:  4418.09\n",
            "8600:  4477.20\n",
            "8700:  4532.86\n",
            "8800:  4589.40\n",
            "8900:  4640.63\n",
            "9000:  4690.79\n",
            "9100:  4740.87\n",
            "9200:  4797.66\n",
            "9300:  4855.15\n",
            "9400:  4905.11\n",
            "9500:  4957.45\n",
            "9600:  5008.01\n",
            "9700:  5051.86\n",
            "9800:  5106.43\n",
            "9900:  5161.51\n",
            "10000:  5210.36\n",
            "10100:  5267.35\n",
            "10200:  5316.61\n",
            "10300:  5363.26\n",
            "10400:  5405.68\n",
            "10500:  5459.05\n",
            "10600:  5504.43\n",
            "10700:  5547.18\n",
            "10800:  5594.06\n",
            "10900:  5642.88\n",
            "11000:  5695.74\n",
            "11100:  5755.35\n",
            "11200:  5803.77\n",
            "11300:  5850.46\n",
            "11400:  5903.46\n",
            "11500:  5949.72\n",
            "11600:  6000.59\n",
            "11700:  6046.73\n",
            "11800:  6095.61\n",
            "11900:  6145.92\n",
            "12000:  6198.34\n",
            "12100:  6248.95\n",
            "12200:  6297.01\n",
            "12300:  6346.26\n",
            "12400:  6394.69\n",
            "12500:  6445.99\n",
            "12600:  6498.33\n",
            "12700:  6546.57\n",
            "12800:  6596.38\n",
            "12900:  6648.02\n",
            "13000:  6697.70\n",
            "13100:  6751.38\n",
            "13200:  6801.49\n",
            "13300:  6851.71\n",
            "13400:  6897.32\n",
            "13500:  6949.78\n",
            "13600:  7003.10\n",
            "13700:  7050.50\n",
            "13800:  7105.57\n",
            "13900:  7161.07\n",
            "14000:  7220.73\n",
            "14100:  7264.30\n",
            "14200:  7316.27\n",
            "14300:  7366.41\n",
            "14400:  7421.33\n",
            "14500:  7491.09\n",
            "14600:  7541.53\n",
            "14700:  7596.42\n",
            "14800:  7645.84\n",
            "14900:  7705.80\n",
            "15000:  7760.54\n",
            "15100:  7809.23\n",
            "15200:  7859.70\n",
            "15300:  7914.55\n",
            "15400:  7962.30\n",
            "15500:  8013.63\n",
            "15600:  8058.49\n",
            "15700:  8106.97\n",
            "15800:  8160.99\n",
            "15900:  8210.29\n",
            "16000:  8263.10\n",
            "16100:  8312.29\n",
            "16200:  8375.38\n",
            "16300:  8423.61\n",
            "16400:  8480.01\n",
            "16500:  8524.36\n",
            "16600:  8566.98\n",
            "16700:  8614.95\n",
            "16800:  8660.49\n",
            "16900:  8712.96\n",
            "17000:  8762.41\n",
            "17100:  8811.06\n",
            "17200:  8857.87\n",
            "17300:  8901.06\n",
            "17400:  8951.02\n",
            "17500:  9000.84\n",
            "17600:  9052.08\n",
            "17700:  9098.21\n",
            "17800:  9153.52\n",
            "17900:  9202.60\n",
            "18000:  9253.22\n",
            "18100:  9304.68\n",
            "18200:  9350.52\n",
            "18300:  9399.19\n",
            "18400:  9445.67\n",
            "18500:  9501.55\n",
            "18600:  9550.03\n",
            "18700:  9599.26\n",
            "18800:  9649.49\n",
            "18900:  9695.07\n",
            "19000:  9747.36\n",
            "19100:  9797.63\n",
            "19200:  9843.88\n",
            "19300:  9891.57\n",
            "19400:  9935.16\n",
            "19500:  9987.57\n",
            "19600:  10036.40\n",
            "19700:  10080.42\n",
            "19800:  10141.02\n",
            "19900:  10199.33\n",
            "20000:  10246.77\n",
            "20100:  10298.29\n",
            "20200:  10344.70\n",
            "20300:  10394.06\n",
            "20400:  10437.10\n",
            "20500:  10487.57\n",
            "20600:  10540.42\n",
            "20700:  10585.13\n",
            "20800:  10633.87\n",
            "20900:  10683.93\n",
            "21000:  10724.72\n",
            "21100:  10770.71\n",
            "21200:  10818.18\n",
            "21300:  10866.91\n",
            "21400:  10912.61\n",
            "21500:  10958.65\n",
            "21600:  11006.93\n",
            "21700:  11055.23\n",
            "21800:  11098.02\n",
            "21900:  11145.73\n",
            "22000:  11190.57\n",
            "22100:  11239.94\n",
            "22200:  11289.06\n",
            "22300:  11335.89\n",
            "22400:  11385.03\n",
            "22500:  11438.46\n",
            "22600:  11490.45\n",
            "22700:  11540.22\n",
            "22800:  11583.81\n",
            "22900:  11630.37\n",
            "23000:  11679.22\n",
            "23100:  11729.56\n",
            "23200:  11782.25\n",
            "23300:  11829.95\n",
            "23400:  11881.79\n",
            "23500:  11927.24\n",
            "23600:  11971.03\n",
            "23700:  12019.23\n",
            "23800:  12065.78\n",
            "23900:  12115.11\n",
            "24000:  12165.19\n",
            "24100:  12217.10\n",
            "24200:  12266.26\n",
            "24300:  12315.74\n",
            "24400:  12364.96\n",
            "24500:  12414.24\n",
            "24600:  12468.72\n",
            "24700:  12510.21\n",
            "24800:  12557.80\n",
            "24900:  12605.56\n",
            "25000:  12657.63\n",
            "25100:  12708.53\n",
            "25200:  12757.21\n",
            "25300:  12806.57\n",
            "25400:  12857.06\n",
            "25500:  12899.42\n",
            "25600:  12945.25\n",
            "25700:  12995.46\n",
            "25800:  13047.25\n",
            "25900:  13094.15\n",
            "26000:  13162.66\n",
            "26100:  13211.74\n",
            "26200:  13258.64\n",
            "26300:  13316.65\n",
            "26400:  13370.31\n",
            "26500:  13424.13\n",
            "26600:  13472.61\n",
            "26700:  13522.86\n",
            "26800:  13566.76\n",
            "26900:  13611.79\n",
            "27000:  13658.30\n",
            "27100:  13705.63\n",
            "27200:  13753.47\n",
            "27300:  13799.84\n",
            "27400:  13845.42\n",
            "27500:  13904.65\n",
            "27600:  13950.35\n",
            "27700:  13995.88\n",
            "27800:  14042.41\n",
            "27900:  14093.95\n",
            "28000:  14145.44\n",
            "28100:  14193.68\n",
            "28200:  14245.69\n",
            "28300:  14293.84\n",
            "28400:  14340.25\n",
            "28500:  14390.66\n",
            "28600:  14444.29\n",
            "28700:  14492.34\n",
            "28800:  14540.80\n",
            "28900:  14595.92\n",
            "29000:  14646.27\n",
            "29100:  14693.65\n",
            "29200:  14738.75\n",
            "29300:  14788.26\n",
            "29400:  14836.98\n",
            "29500:  14885.59\n",
            "29600:  14940.12\n",
            "29700:  14993.01\n",
            "29800:  15038.05\n",
            "29900:  15083.64\n",
            "30000:  15133.33\n",
            "30100:  15183.19\n",
            "30200:  15228.39\n",
            "30300:  15286.80\n",
            "30400:  15338.70\n",
            "30500:  15386.90\n",
            "30600:  15437.47\n",
            "30700:  15488.86\n",
            "30800:  15535.70\n",
            "30900:  15584.65\n",
            "31000:  15629.34\n",
            "31100:  15680.48\n",
            "31200:  15730.73\n",
            "31300:  15781.06\n",
            "31400:  15826.18\n",
            "31500:  15872.28\n",
            "31600:  15922.41\n",
            "31700:  15974.01\n",
            "31800:  16019.49\n",
            "31900:  16067.54\n",
            "32000:  16119.17\n",
            "32100:  16164.49\n",
            "32200:  16207.73\n",
            "32300:  16267.52\n",
            "32400:  16315.63\n",
            "32500:  16367.12\n",
            "32600:  16413.81\n",
            "32700:  16463.37\n",
            "32800:  16504.99\n",
            "32900:  16552.87\n",
            "33000:  16614.15\n",
            "33100:  16663.98\n",
            "33200:  16718.19\n",
            "33300:  16766.19\n",
            "33400:  16813.82\n",
            "33500:  16863.55\n",
            "33600:  16909.75\n",
            "33700:  16956.48\n",
            "33800:  17002.42\n",
            "33900:  17055.92\n",
            "34000:  17100.71\n",
            "34100:  17149.81\n",
            "34200:  17197.80\n",
            "34300:  17240.09\n",
            "34400:  17288.21\n",
            "34500:  17338.73\n",
            "34600:  17387.57\n",
            "34700:  17442.57\n",
            "34800:  17501.53\n",
            "34900:  17547.52\n",
            "35000:  17599.90\n",
            "35100:  17653.29\n",
            "35200:  17696.96\n",
            "35300:  17741.17\n",
            "35400:  17794.72\n",
            "35500:  17845.89\n",
            "35600:  17895.69\n",
            "35700:  17943.25\n",
            "35800:  17987.54\n",
            "35900:  18041.05\n",
            "36000:  18093.41\n",
            "36100:  18146.01\n",
            "36200:  18191.52\n",
            "36300:  18240.16\n",
            "36400:  18290.32\n",
            "36500:  18338.12\n",
            "36600:  18391.27\n",
            "36700:  18443.48\n",
            "36800:  18490.43\n",
            "36900:  18532.71\n",
            "37000:  18581.37\n",
            "37100:  18623.79\n",
            "37200:  18667.96\n",
            "37300:  18713.08\n",
            "37400:  18762.99\n",
            "37500:  18812.80\n",
            "37600:  18869.58\n",
            "37700:  18916.67\n",
            "37800:  18961.20\n",
            "37900:  19010.14\n",
            "38000:  19058.68\n",
            "38100:  19105.93\n",
            "38200:  19153.43\n",
            "38300:  19196.61\n",
            "38400:  19239.83\n",
            "38500:  19285.97\n",
            "38600:  19345.70\n",
            "38700:  19397.15\n",
            "38800:  19444.94\n",
            "38900:  19487.58\n",
            "39000:  19535.71\n",
            "39100:  19589.05\n",
            "39200:  19638.90\n",
            "39300:  19691.18\n",
            "39400:  19740.74\n",
            "39500:  19793.29\n",
            "39600:  19842.64\n",
            "39700:  19896.65\n",
            "39800:  19946.57\n",
            "39900:  19992.81\n",
            "40000:  20038.63\n",
            "40100:  20091.62\n",
            "40200:  20136.74\n",
            "40300:  20191.92\n",
            "40400:  20239.61\n",
            "40500:  20289.29\n",
            "40600:  20341.86\n",
            "40700:  20389.31\n",
            "40800:  20440.10\n",
            "40900:  20484.33\n",
            "41000:  20529.03\n",
            "41100:  20579.42\n",
            "41200:  20629.12\n",
            "41300:  20676.85\n",
            "41400:  20734.20\n",
            "41500:  20781.73\n",
            "41600:  20830.34\n",
            "41700:  20885.03\n",
            "41800:  20944.13\n",
            "41900:  20995.39\n",
            "42000:  21042.56\n",
            "42100:  21093.16\n",
            "42200:  21144.61\n",
            "42300:  21191.21\n",
            "42400:  21237.58\n",
            "42500:  21287.23\n",
            "42600:  21337.19\n",
            "42700:  21382.07\n",
            "42800:  21429.00\n",
            "42900:  21482.54\n",
            "43000:  21529.57\n",
            "43100:  21577.45\n",
            "43200:  21623.76\n",
            "43300:  21676.35\n",
            "43400:  21725.60\n",
            "43500:  21780.59\n",
            "43600:  21832.77\n",
            "43700:  21877.77\n",
            "43800:  21932.44\n",
            "43900:  21978.12\n",
            "44000:  22023.40\n",
            "44100:  22070.34\n",
            "44200:  22116.09\n",
            "44300:  22165.79\n",
            "44400:  22216.40\n",
            "44500:  22265.86\n",
            "44600:  22313.32\n",
            "44700:  22364.30\n",
            "44800:  22413.98\n",
            "44900:  22459.83\n",
            "45000:  22500.36\n",
            "45100:  22543.68\n",
            "45200:  22597.24\n",
            "45300:  22650.70\n",
            "45400:  22698.57\n",
            "45500:  22748.01\n",
            "45600:  22794.81\n",
            "45700:  22845.34\n",
            "45800:  22889.69\n",
            "45900:  22931.02\n",
            "46000:  22981.07\n",
            "46100:  23023.81\n",
            "46200:  23070.04\n",
            "46300:  23118.28\n",
            "46400:  23158.62\n",
            "46500:  23208.05\n",
            "46600:  23256.88\n",
            "46700:  23307.01\n",
            "46800:  23355.75\n",
            "46900:  23400.56\n",
            "47000:  23449.19\n",
            "47100:  23492.62\n",
            "47200:  23539.21\n",
            "47300:  23584.31\n",
            "47400:  23629.81\n",
            "47500:  23682.96\n",
            "47600:  23733.35\n",
            "47700:  23777.68\n",
            "47800:  23823.82\n",
            "47900:  23869.93\n",
            "48000:  23920.06\n",
            "48100:  23968.80\n",
            "48200:  24014.60\n",
            "48300:  24066.37\n",
            "48400:  24113.68\n",
            "48500:  24160.85\n",
            "48600:  24205.65\n",
            "48700:  24253.03\n",
            "48800:  24302.05\n",
            "48900:  24348.73\n",
            "49000:  24392.39\n",
            "49100:  24436.88\n",
            "49200:  24484.90\n",
            "49300:  24528.16\n",
            "49400:  24575.38\n",
            "49500:  24622.72\n",
            "49600:  24671.57\n",
            "49700:  24719.18\n",
            "49800:  24767.22\n",
            "49900:  24819.77\n",
            "50000:  24865.48\n",
            "50100:  24911.14\n",
            "50200:  24963.95\n",
            "50300:  25018.12\n",
            "50400:  25062.69\n",
            "50500:  25109.95\n",
            "50600:  25162.33\n",
            "50700:  25208.13\n",
            "50800:  25258.91\n",
            "50900:  25300.57\n",
            "51000:  25341.90\n",
            "51100:  25387.52\n",
            "51200:  25436.95\n",
            "51300:  25487.08\n",
            "51400:  25531.31\n",
            "51500:  25584.35\n",
            "51600:  25627.16\n",
            "51700:  25673.12\n",
            "51800:  25722.97\n",
            "51900:  25771.21\n",
            "52000:  25816.21\n",
            "52100:  25864.38\n",
            "52200:  25911.62\n",
            "52300:  25961.94\n",
            "52400:  26010.89\n",
            "52500:  26054.39\n",
            "52600:  26098.90\n",
            "52700:  26139.44\n",
            "52800:  26188.84\n",
            "52900:  26234.82\n",
            "53000:  26285.27\n",
            "53100:  26334.29\n",
            "53200:  26386.11\n",
            "53300:  26437.29\n",
            "53400:  26482.84\n",
            "53500:  26534.45\n",
            "53600:  26583.57\n",
            "53700:  26631.63\n",
            "53800:  26674.95\n",
            "53900:  26721.83\n",
            "54000:  26774.05\n",
            "54100:  26821.78\n",
            "54200:  26870.85\n",
            "54300:  26919.94\n",
            "54400:  26971.50\n",
            "54500:  27017.58\n",
            "54600:  27066.79\n",
            "54700:  27115.65\n",
            "54800:  27157.27\n",
            "54900:  27208.44\n",
            "55000:  27258.45\n",
            "55100:  27305.22\n",
            "55200:  27347.36\n",
            "55300:  27391.12\n",
            "55400:  27434.95\n",
            "55500:  27480.01\n",
            "55600:  27527.21\n",
            "55700:  27580.10\n",
            "55800:  27625.69\n",
            "55900:  27677.73\n",
            "56000:  27723.58\n",
            "56100:  27768.30\n",
            "56200:  27812.63\n",
            "56300:  27859.13\n",
            "56400:  27904.64\n",
            "56500:  27953.48\n",
            "56600:  28002.00\n",
            "56700:  28050.52\n",
            "56800:  28097.67\n",
            "56900:  28146.54\n",
            "57000:  28196.63\n",
            "57100:  28247.38\n",
            "57200:  28296.10\n",
            "57300:  28346.08\n",
            "57400:  28393.08\n",
            "57500:  28443.49\n",
            "57600:  28497.30\n",
            "57700:  28540.01\n",
            "57800:  28582.21\n",
            "57900:  28625.12\n",
            "58000:  28670.00\n",
            "58100:  28720.41\n",
            "58200:  28763.73\n",
            "58300:  28810.03\n",
            "58400:  28862.61\n",
            "58500:  28918.68\n",
            "58600:  28963.45\n",
            "58700:  29009.94\n",
            "58800:  29058.55\n",
            "58900:  29106.29\n",
            "59000:  29150.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXqK0r9YZH0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SS7Mm5gdYnlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLrMP2avP8_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9140bc9254014524a256b38330f7e2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e336a62ed68445f98d8956717cc14ae",
              "IPY_MODEL_0c58a7422b7a46ae8ba2e17b559314a2",
              "IPY_MODEL_f215215edc814edbb1f8bd25882de85c"
            ],
            "layout": "IPY_MODEL_8ad8a343da8049cc813005a5de9e86f5"
          }
        },
        "7e336a62ed68445f98d8956717cc14ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5fea0b915fb4eadbe81ed56d50a3474",
            "placeholder": "​",
            "style": "IPY_MODEL_5086e81e40054a0ea2fc4f10291105e5",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "0c58a7422b7a46ae8ba2e17b559314a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d40b325408b45ff9bedc9e37f899fa5",
            "max": 252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d73942f85f294eabb06b2b142b3a52da",
            "value": 252
          }
        },
        "f215215edc814edbb1f8bd25882de85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856cce17dae24677884e9892817c6f59",
            "placeholder": "​",
            "style": "IPY_MODEL_f08b11bd68fb4931a35bbba229c8fd78",
            "value": " 252/252 [00:00&lt;00:00, 6.64kB/s]"
          }
        },
        "8ad8a343da8049cc813005a5de9e86f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fea0b915fb4eadbe81ed56d50a3474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5086e81e40054a0ea2fc4f10291105e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d40b325408b45ff9bedc9e37f899fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73942f85f294eabb06b2b142b3a52da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "856cce17dae24677884e9892817c6f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08b11bd68fb4931a35bbba229c8fd78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f65f078a91e14f8a8ad74c8d2f00d6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eff0f6e55a884d39b13ab5804f4926be",
              "IPY_MODEL_4ae5c6e1cdaa4d2fa53516d40b76e494",
              "IPY_MODEL_d9868f4b72e545d0b5753094a80fdb13"
            ],
            "layout": "IPY_MODEL_8fd26e0b1a6e409084616dfa3ec76b19"
          }
        },
        "eff0f6e55a884d39b13ab5804f4926be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2953265005324c4ba142859d1ff8adb6",
            "placeholder": "​",
            "style": "IPY_MODEL_14e0be4ca21342fa9a2d222b8a9f2762",
            "value": "Downloading config.json: 100%"
          }
        },
        "4ae5c6e1cdaa4d2fa53516d40b76e494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782e644b19f64e0a8a8ecf60a78b5d99",
            "max": 758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2bc3fcac066441f86a3ececdb04abf2",
            "value": 758
          }
        },
        "d9868f4b72e545d0b5753094a80fdb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336b19c9497745598c3079eec3829397",
            "placeholder": "​",
            "style": "IPY_MODEL_31b17596b19a47bfb438e064b155a913",
            "value": " 758/758 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "8fd26e0b1a6e409084616dfa3ec76b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2953265005324c4ba142859d1ff8adb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e0be4ca21342fa9a2d222b8a9f2762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782e644b19f64e0a8a8ecf60a78b5d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bc3fcac066441f86a3ececdb04abf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "336b19c9497745598c3079eec3829397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b17596b19a47bfb438e064b155a913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b89152c3bb149b3ae29b1887e472dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5667da6fdd844cb3890ffde1dd15075c",
              "IPY_MODEL_8bca7ddc4c784943a74f258b154a26c0",
              "IPY_MODEL_b7a8953b432946dbbe66264cf9133115"
            ],
            "layout": "IPY_MODEL_69d06ae5f776452f867f8f2637b652d4"
          }
        },
        "5667da6fdd844cb3890ffde1dd15075c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06c23e12d1445ddbe2ec0325bdc02af",
            "placeholder": "​",
            "style": "IPY_MODEL_be4e4438f04d49c9939b89838033c949",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "8bca7ddc4c784943a74f258b154a26c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12091a6e14ef46efa718df1d127272f1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f621af9cc0144276893ac540dcba3667",
            "value": 231508
          }
        },
        "b7a8953b432946dbbe66264cf9133115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c849f103940b42de85dad0c007635a56",
            "placeholder": "​",
            "style": "IPY_MODEL_d23d6775089c4233a50fa97771927119",
            "value": " 226k/226k [00:00&lt;00:00, 890kB/s]"
          }
        },
        "69d06ae5f776452f867f8f2637b652d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06c23e12d1445ddbe2ec0325bdc02af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4e4438f04d49c9939b89838033c949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12091a6e14ef46efa718df1d127272f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f621af9cc0144276893ac540dcba3667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c849f103940b42de85dad0c007635a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23d6775089c4233a50fa97771927119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5076a7ea0b3f4ab8abaa47f596bdb274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4208fc2e67c2408092508130e0372f63",
              "IPY_MODEL_ad5c4be50ea744d29a54314f7bddee2b",
              "IPY_MODEL_80fc41ed1e9049f0913bb0b200dfa108"
            ],
            "layout": "IPY_MODEL_6eb62d69b7934647825c441b8daf807c"
          }
        },
        "4208fc2e67c2408092508130e0372f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ffc571bf60040d0be2fe38ea1881531",
            "placeholder": "​",
            "style": "IPY_MODEL_51e000b324f24e2f9503157753283d40",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "ad5c4be50ea744d29a54314f7bddee2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78079fdaba24b4183f0d58fed6b46a2",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bb421f086f84d939b12b7cadd690399",
            "value": 112
          }
        },
        "80fc41ed1e9049f0913bb0b200dfa108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41d9d980cd046a980cb6c66c23e32c1",
            "placeholder": "​",
            "style": "IPY_MODEL_4b9cfd2bbf694a5a9d2ea07540da42b8",
            "value": " 112/112 [00:00&lt;00:00, 3.68kB/s]"
          }
        },
        "6eb62d69b7934647825c441b8daf807c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffc571bf60040d0be2fe38ea1881531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51e000b324f24e2f9503157753283d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78079fdaba24b4183f0d58fed6b46a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb421f086f84d939b12b7cadd690399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d41d9d980cd046a980cb6c66c23e32c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9cfd2bbf694a5a9d2ea07540da42b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff95a97ed654f818c85eb84aa78ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_463226d86f9f4fff92c03e237f43e1fe",
              "IPY_MODEL_48aabb48c8124991b1852d9ad0a7dbcd",
              "IPY_MODEL_1326c43d0a9f4ed09daebe4ed0bfda2b"
            ],
            "layout": "IPY_MODEL_3595e91a323340ac8bc1b6bb97df38b3"
          }
        },
        "463226d86f9f4fff92c03e237f43e1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b6c0bfe7ab4601b3c9382c21cbc691",
            "placeholder": "​",
            "style": "IPY_MODEL_44ee7587a9e348539c5820f0fa7140e9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "48aabb48c8124991b1852d9ad0a7dbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6c1c82dd8e41fc80e675cd301f69d1",
            "max": 437992753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_188121873ee04155b8264ae6588c4ca4",
            "value": 437992753
          }
        },
        "1326c43d0a9f4ed09daebe4ed0bfda2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fd543fc66141dea90f8fc1b0cc2374",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9a5ff4bbbb4df688827ac30b405714",
            "value": " 418M/418M [00:10&lt;00:00, 41.6MB/s]"
          }
        },
        "3595e91a323340ac8bc1b6bb97df38b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b6c0bfe7ab4601b3c9382c21cbc691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ee7587a9e348539c5820f0fa7140e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d6c1c82dd8e41fc80e675cd301f69d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188121873ee04155b8264ae6588c4ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96fd543fc66141dea90f8fc1b0cc2374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9a5ff4bbbb4df688827ac30b405714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
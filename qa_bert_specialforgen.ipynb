{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InscribeDeeper/bert_utils/blob/master/qa_bert_specialforgen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SsX3j3sfBKk",
        "toc": true
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Baseline-3:-BioBERT-Pretrained---CNN-only\" data-toc-modified-id=\"Baseline-3:-BioBERT-Pretrained---CNN-only-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Baseline 3: BioBERT Pretrained - CNN only</a></span></li><li><span><a href=\"#1.-Setup\" data-toc-modified-id=\"1.-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Setup</a></span></li><li><span><a href=\"#2.-Parse-data\" data-toc-modified-id=\"2.-Parse-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Parse data</a></span></li><li><span><a href=\"#3.-Tokenization-&amp;-Input-Formatting\" data-toc-modified-id=\"3.-Tokenization-&amp;-Input-Formatting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3. Tokenization &amp; Input Formatting</a></span></li><li><span><a href=\"#4.-Define-model\" data-toc-modified-id=\"4.-Define-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Define model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#6.1.-Evalution-Function\" data-toc-modified-id=\"6.1.-Evalution-Function-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>6.1. Evalution Function</a></span></li></ul></li><li><span><a href=\"#6.3.-4-fold-cross-validation;-one-vs-the-rest\" data-toc-modified-id=\"6.3.-4-fold-cross-validation;-one-vs-the-rest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>6.3. 4-fold cross validation; one-vs-the-rest</a></span></li></ul></li><li><span><a href=\"#7.-Train-a-model-with-all-data-for-prediction\" data-toc-modified-id=\"7.-Train-a-model-with-all-data-for-prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>7. Train a model with all data for prediction</a></span></li><li><span><a href=\"#Predict-sentences\" data-toc-modified-id=\"Predict-sentences-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Predict sentences</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Baseline 3: BioBERT Pretrained - CNN only\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8elk83nAFKM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmmaqGLR1xx",
        "outputId": "43d65f59-901d-46c2-9d77-7c0a879b21c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHIo4Bzmcef"
      },
      "outputs": [],
      "source": [
        "#pip install --target=$package_path torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LealyJc7ZC8b",
        "outputId": "5d2d4b78-9e39-47fd-8fff-2c66daf1e0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# nb_path = '/content/rl'\n",
        "# #os.symlink('/content/drive/MyDrive/Colab_Notebooks', nb_path)\n",
        "\n",
        "# package_path = '/content/drive/MyDrive/Colab_Notebooks/packages'\n",
        "# sys.path.insert(0,nb_path)\n",
        "# sys.path.insert(0,package_path)\n",
        "\n",
        "cur_path = os.path.join('/content/drive/MyDrive/Conf_Call/','Conf_Call')\n",
        "print(os.getcwd())\n",
        "os.chdir(cur_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660,
          "referenced_widgets": [
            "ae2b44daf1eb42b4856f8e904c42bba9",
            "676db17bed42496c9c573c16942ac10c",
            "dcd98b2453024598ad3de4b6a5819cc2",
            "eadecbee1e9748f580b2ff3711026247",
            "a9af45b31f434b67917cf13b770bb58d",
            "3c61014751624528a7ddd3b131354d06",
            "68bfc5eb341f4f79ab831026fa3fb169",
            "2bee06b1c197441996f4aaf65e4b7909",
            "a424c272de154766ba398d315490580c",
            "eab53918d4db48edb41b55010714c0c2",
            "56f92b1f942c4680bd4acb939319cb45"
          ]
        },
        "id": "ArSJvtVIJF8V",
        "outputId": "f726f226-1abd-4e26-997d-b7e6c2d00331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 81.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 75.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae2b44daf1eb42b4856f8e904c42bba9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import random, pickle\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0X48D4v42vH",
        "outputId": "9d4da394-5455-4bb5-92cb-6f8e11a19c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Sep 16 04:29:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "29ca4516-cc57-4dbe-e181-0c1b38c74b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    device_name =\"/cpu:0\"\n",
        "    print('GPU device not found')\n",
        "    #raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "fdda12f6-bf66-4ba1-e939-c0bca3b5e1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available(): \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6CJaQXuL0BD",
        "outputId": "ca888e7c-49b6-46e5-fabe-bd064acfb210"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1ff9034e30>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set seed\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XygCjrnuL0Kn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rs3nVLsyRcJ"
      },
      "source": [
        "Download BioBERT Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "# 2. Parse data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "690f8a06-7b49-4a0c-dc7b-ba2533c8254e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,173\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22cc9e38-4390-4644-b87a-eec73788fc47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>That is also a same store number because we??v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>How has that sort of changed the marketplace, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>How has that been trending in the last quarter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>I'm just wondering why is this, given the Olym...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>And they are on track to continue that through...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>You don??t think the industry, like everyone s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>So, you are displacing - you are gaining marke...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>How -- what was the timing, like was it at the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>A few questions, first of all on the New Londo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>Why do you think it decelerated from Q3 high s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22cc9e38-4390-4644-b87a-eec73788fc47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22cc9e38-4390-4644-b87a-eec73788fc47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22cc9e38-4390-4644-b87a-eec73788fc47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "316   That is also a same store number because we??v...      0\n",
              "171   How has that sort of changed the marketplace, ...      0\n",
              "396   How has that been trending in the last quarter...      0\n",
              "196   I'm just wondering why is this, given the Olym...      1\n",
              "357   And they are on track to continue that through...      0\n",
              "1058  You don??t think the industry, like everyone s...      0\n",
              "284   So, you are displacing - you are gaining marke...      1\n",
              "1033  How -- what was the timing, like was it at the...      0\n",
              "48    A few questions, first of all on the New Londo...      0\n",
              "366   Why do you think it decelerated from Q3 high s...      0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/temp/merge_qa_label.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = pd.read_csv(\"surprise_checking_internal_0905.csv\", encoding=\"ISO-8859-1\")\n",
        "#df = df[df.Negative==0]\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 2'], axis=1)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/temp/surprise_dt_test_v9_all_kiera.xlsx\")\n",
        "# #df = df[df.Negative==0]\n",
        "# # Report the number of sentences.\n",
        "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "# df = df.drop(['Unnamed: 0'], axis=1)\n",
        "# df = df.rename(columns={'merged':'label'})\n",
        "# # Display 10 random rows from the data.\n",
        "# df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlJIz3HcCqQx"
      },
      "outputs": [],
      "source": [
        "random.seed(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecjszS0spgyL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OubtD2dURIfo",
        "outputId": "1a8cfbdf-67d6-4994-c8d6-88adb98b2516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1173"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0    928\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)\n",
        "#df[\"label\"] =df[\"label\"].fillna(0)\n",
        "df= df[~df['label'].isna()]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpDUjP7Bu4f",
        "outputId": "6af07a37-26bd-46b7-d22a-59e87e5506c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    280\n",
              "1    245\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg = 280\n",
        "import sklearn\n",
        "negs = sklearn.utils.shuffle(df[df.label==0].index.tolist())\n",
        "df = df[(df.label==1) | (df.index.isin(negs[0:neg]))]\n",
        "\n",
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pfEM9QjFB3MM",
        "outputId": "3d858d25-ec51-4904-8292-4d8a1d0625ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But I??m just wondering how you actually manag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What was that all in?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Is that any different than it was nine months ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How did that come about?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>So there wasn't an unusual boost in the North ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>And then one other, right; recently, you guys ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>And then, this contract Salisbury municipality...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>And so how do you see the uptick of that produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>I wondered if we could walk through some of th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>Tim, in your working cap comments, you noted h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a4f3cad-5c0e-4bb4-a393-c5568b6520e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "0     But I??m just wondering how you actually manag...      0\n",
              "8                                 What was that all in?      0\n",
              "10    Is that any different than it was nine months ...      0\n",
              "30                             How did that come about?      0\n",
              "40    So there wasn't an unusual boost in the North ...      0\n",
              "...                                                 ...    ...\n",
              "1157  And then one other, right; recently, you guys ...      0\n",
              "1159  And then, this contract Salisbury municipality...      0\n",
              "1160  And so how do you see the uptick of that produ...      0\n",
              "1163  I wondered if we could walk through some of th...      0\n",
              "1171  Tim, in your working cap comments, you noted h...      0\n",
              "\n",
              "[280 rows x 2 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.label==0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwLfYDEg6GbL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/temp/traingsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuE5BqICAne2",
        "outputId": "ca20b5f0-8f42-4e84-fab1-f7a42221cf3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "245"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = [0,1]\n",
        "num_labels = len(labels)\n",
        "df.label.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnyOs8zP8YO",
        "outputId": "36757ace-2267-43e1-a249-9e56a74a9ab6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "525\n"
          ]
        }
      ],
      "source": [
        "labels[0:2]\n",
        "print(len(labels))\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U6RHQC5Ro3V"
      },
      "outputs": [],
      "source": [
        "#df.to_csv('/content/drive/MyDrive/temp/traingsample.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "065e7c53-61b9-4a0c-a263-7c1c34ef2871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-pretrain', do_lower_case=True )\n",
        "# tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert', do_lower_case=True )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQO0EzmI-Ck",
        "outputId": "173f5abf-da8b-4c87-c26b-2f43bf5b665e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  But I??m just wondering how you actually manage that, when you??re looking at your underwriting teams and trying to manage their risks properly around a business that??s growing at such a high rate.\n",
            "Tokenized:  ['but', 'i', '?', '?', 'm', 'just', 'wondering', 'how', 'you', 'actually', 'manage', 'that', ',', 'when', 'you', '?', '?', 're', 'looking', 'at', 'your', 'under', '##writing', 'teams', 'and', 'trying', 'to', 'manage', 'their', 'risks', 'properly', 'around', 'a', 'business', 'that', '?', '?', 's', 'growing', 'at', 'such', 'a', 'high', 'rate', '.']\n",
            "Token IDs:  [2021, 1045, 1029, 1029, 1049, 2074, 6603, 2129, 2017, 2941, 6133, 2008, 1010, 2043, 2017, 1029, 1029, 2128, 2559, 2012, 2115, 2104, 18560, 2780, 1998, 2667, 2000, 6133, 2037, 10831, 7919, 2105, 1037, 2449, 2008, 1029, 1029, 1055, 3652, 2012, 2107, 1037, 2152, 3446, 1012]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxP_VbyCsjXN",
        "outputId": "03cd2a5c-f6dc-4546-91d3-975831429de6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "bert_model = AutoModel.from_pretrained(\n",
        "    # 'ProsusAI/finbert',\n",
        "    'bert-base-uncased',\n",
        "    num_labels = 2, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "    )\n",
        "bert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8WiOzGYTyEW"
      },
      "outputs": [],
      "source": [
        "# Put everything together as a function. This is for pretrained word vectors\n",
        "\n",
        "def get_pretrained_wordvector(sentences, tokenizer, bert_model):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    max_len =100\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        #padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    \n",
        "    # get the last four layers\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # permute axis\n",
        "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # take the mean of the last 4 layers\n",
        "    token_embeddings = token_embeddings.mean(axis=2)\n",
        "\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    return token_embeddings, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpy4z_hVKG2",
        "outputId": "44e0df36-cd74-43e1-dc26-3dbc7582f054"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([525, 100])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model)\n",
        "print(masks.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvRzM10sped",
        "outputId": "18c81cda-e27c-436c-a2f0-2e6298d76242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([525, 100, 768])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device)\n",
        "print(token_embeddings.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJ1ZA4etjHG"
      },
      "source": [
        "# 4. Define model\n",
        "\n",
        "\n",
        "The model has two layers:\n",
        "BiLSTM\n",
        "CNN\n",
        "Dense Layer\n",
        "\n",
        "Depending on loss function used, this model can be single-label or multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exhSQc_7tnqz"
      },
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        \n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.emb_dim)) for f in self.kernel_sizes])\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzlP7U3xU65k"
      },
      "outputs": [],
      "source": [
        "class lstm_cnn(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, emb_dim, seq_len, lstm_units, num_filters, kernel_sizes, num_classes, dropout_rate = 0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_units = lstm_units\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        # input: [1173, 100, 768]\n",
        "        # self.norm1 = torch.nn.LayerNorm([self.seq_len , self.emb_dim])\n",
        "        # self.norm1 = nn.BatchNorm1d(seq_len)\n",
        "        self.lstm = nn.LSTM(emb_dim,\n",
        "                            lstm_units,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)  # \n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, 2*self.lstm_units)) for f in self.kernel_sizes])\n",
        "        # self.convs = nn.ModuleList([nn.Conv2d(1,self.num_filters, (f, self.lstm_units)) for f in self.kernel_sizes])\n",
        "        #self.norm2 = nn.BatchNorm1d(len(kernel_sizes)*self.num_filters)\n",
        "        self.fc = nn.Linear(len(kernel_sizes)*self.num_filters, self.num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "       # x = self.norm1(x)\n",
        "\n",
        "        x, _ = self.lstm(x)  # (N, seq_len, 2*lstm_units)\n",
        "\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        x = [F.relu(conv(x).squeeze(-1)) for conv in self.convs]  # output of three conv\n",
        "\n",
        "        #print(x[0].size())\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] # continue with 3 maxpooling\n",
        "\n",
        "        x = torch.cat(x, 1)  # N, len(filter_sizes)* num_filters\n",
        "        #print(x.size())\n",
        "\n",
        "        #x = self.norm2(x)\n",
        "\n",
        "        x = self.dropout(x)  # N, len(filter_sizes)* num_filters\n",
        "\n",
        "        logit = self.fc(x)  # (N, num_classes)\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNklenpst7LL",
        "outputId": "98cd3947-3589-4a31-8467-b964881bf934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "cnn                                      [32, 6]                   582\n",
              "├─ModuleList: 1-1                        --                        --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 100, 1]          3,232\n",
              "│    └─Conv2d: 2-2                       [32, 32, 99, 1]           6,432\n",
              "│    └─Conv2d: 2-3                       [32, 32, 98, 1]           9,632\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "├─Dropout: 1-3                           [32, 96]                  --\n",
              "├─Linear: 1-4                            [32, 6]                   (recursive)\n",
              "==========================================================================================\n",
              "Total params: 19,878\n",
              "Trainable params: 19,878\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 60.96\n",
              "==========================================================================================\n",
              "Input size (MB): 1.28\n",
              "Forward/backward pass size (MB): 2.43\n",
              "Params size (MB): 0.08\n",
              "Estimated Total Size (MB): 3.79\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = cnn(100, 100, 32, [1,2,3], 6)\n",
        "#summary(model.to(device),(32, 100, 100))\n",
        "summary(model,(32, 100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9jwsr4qorx"
      },
      "source": [
        "#6. **Define a function to train single-label classifier**\n",
        "\n",
        "The loss function is different from multi-label classifer\n",
        "\n",
        "Parameters:\n",
        "\n",
        "* model: model defined\n",
        "*   num_labels: number of labels\n",
        "*   label_cols: label names\n",
        "*   train_dataloader: train data loader\n",
        "*   validation_dataloader: validation data loader\n",
        "*   optimizer: optimizer. default is Adam\n",
        "*   scheduler: adjust learning rate dynamically; default is None.\n",
        "*   epochs: number of epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxPyzYb7Emm"
      },
      "source": [
        "### 6.1. Evalution Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ELmiqyd35w8"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, dataloader, class_weight = None):\n",
        "  tokenized_texts = []\n",
        "  true_labels = []\n",
        "  pred_labels = []\n",
        "\n",
        "  threshold = 0.5\n",
        "\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "\n",
        "      logits = model(b_input_ids)\n",
        "      #loss_func = BCELoss()\n",
        "      #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "      if class_weight != None:\n",
        "          pos_weight=torch.tensor(class_weight).to(device)\n",
        "          loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "      else:\n",
        "          loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "      val_loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation          \n",
        "            \n",
        "      total_eval_loss += val_loss.item()\n",
        "    \n",
        "      pred_label = torch.sigmoid(logits)   \n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      \n",
        "      tokenized_texts.append(b_input_ids)\n",
        "      true_labels.append(b_labels)\n",
        "      pred_labels.append(pred_label)\n",
        "\n",
        "    \n",
        "  # Flatten outputs\n",
        "  pred_labels = np.vstack(pred_labels)\n",
        "  true_labels = np.vstack(true_labels)\n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(dataloader)    \n",
        "\n",
        "  return tokenized_texts, pred_labels, true_labels,avg_val_loss\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZAROYal7AfW"
      },
      "source": [
        "##6.2. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwcDj_XyqnIb"
      },
      "outputs": [],
      "source": [
        "def train_single_label_model(model, num_labels, label_cols, train_dataloader, validation_dataloader, model_path,\\\n",
        "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
        "                             class_weight = None, patience = 5):\n",
        "\n",
        "    seed_val = 42\n",
        "\n",
        "    threshold = 0.5\n",
        "    #model_path = 'best_model.model'  # save the best model\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "    \n",
        "    best_score = -0.5\n",
        "    best_epoch = 0\n",
        "    cnt = 0\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    if optimizer==None:\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        #print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            #if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "            #    elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                #print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_labels = batch[1].to(device)\n",
        "            \n",
        "            model.zero_grad()        \n",
        "\n",
        "            logits = model(b_input_ids)\n",
        "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
        "            #loss_func = BCELoss()\n",
        "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            # add class weight\n",
        "            if class_weight != None:\n",
        "              pos_weight=torch.tensor(class_weight).to(device)\n",
        "              loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "              loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "            loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            if scheduler!=None:\n",
        "                scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        #training_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        #print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        " \n",
        "        val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "\n",
        "        #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
        "        #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
        "        print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t Val Loss {2:.4f}\\t Val Acc: {3:.4f}\\t Val F1: {4:.4f}\".\\\n",
        "          format(epoch_i +1, avg_train_loss, avg_val_loss, val_acc, val_f1))\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        #validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
        "        #print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': val_f1,\n",
        "                'Best F1': best_score,\n",
        "                'Best epoch': best_epoch\n",
        "                #'Training Time': training_time,\n",
        "                #'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # early stopping\n",
        "        if val_f1 > best_score:\n",
        "            best_score = val_f1\n",
        "            best_epoch = epoch_i + 1\n",
        "            torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
        "            print(\"model saved\")\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            if cnt == patience:\n",
        "                print(\"\\n\")\n",
        "                print(\"early stopping at epoch {0}\".format(epoch_i+1))\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    #print(\"Training complete!\")\n",
        "\n",
        "    #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    return model, training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEeNyw0Keo4y"
      },
      "source": [
        "## 6.3. 4-fold cross validation; one-vs-the-rest\n",
        "Train single label classifier using one vs. the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcExaiA9WeWu",
        "outputId": "1257e6bf-9fde-4582-b8d7-ac767c48a1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors = vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCICxXmenoB",
        "outputId": "73b44458-434c-497d-e07b-65e9cf919e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.8290\t Val Loss 0.7777\t Val Acc: 0.6971\t Val F1: 70.3911\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6995\t Val Loss 0.6528\t Val Acc: 0.7314\t Val F1: 71.5152\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5336\t Val Loss 0.7061\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 4\t Train Loss: 0.3788\t Val Loss 0.7453\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 5\t Train Loss: 0.2493\t Val Loss 0.7977\t Val Acc: 0.7257\t Val F1: 71.7647\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1193\t Val Loss 1.3048\t Val Acc: 0.6914\t Val F1: 70.6522\n",
            "Epoch 7\t Train Loss: 0.0750\t Val Loss 1.4521\t Val Acc: 0.7314\t Val F1: 74.0331\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0150\t Val Loss 1.4820\t Val Acc: 0.7429\t Val F1: 72.0497\n",
            "Epoch 9\t Train Loss: 0.0068\t Val Loss 1.5977\t Val Acc: 0.7486\t Val F1: 72.5000\n",
            "Epoch 10\t Train Loss: 0.0029\t Val Loss 1.8047\t Val Acc: 0.7486\t Val F1: 71.7949\n",
            "Epoch 11\t Train Loss: 0.0024\t Val Loss 1.8821\t Val Acc: 0.7200\t Val F1: 71.3450\n",
            "Epoch 12\t Train Loss: 0.0010\t Val Loss 2.1333\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "\n",
            "\n",
            "early stopping at epoch 12\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6700, Recall: 0.8272, F1: 0.7403, Loss: 1.4521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.65      0.72        94\n",
            "           1       0.67      0.83      0.74        81\n",
            "\n",
            "    accuracy                           0.73       175\n",
            "   macro avg       0.74      0.74      0.73       175\n",
            "weighted avg       0.75      0.73      0.73       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.8060\t Val Loss 0.7495\t Val Acc: 0.7257\t Val F1: 73.3333\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6508\t Val Loss 0.6531\t Val Acc: 0.7086\t Val F1: 74.8768\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.5120\t Val Loss 0.7055\t Val Acc: 0.7200\t Val F1: 75.3769\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.4442\t Val Loss 0.6932\t Val Acc: 0.7486\t Val F1: 70.2703\n",
            "Epoch 5\t Train Loss: 0.2864\t Val Loss 0.9322\t Val Acc: 0.7371\t Val F1: 67.6056\n",
            "Epoch 6\t Train Loss: 0.2055\t Val Loss 0.8885\t Val Acc: 0.7429\t Val F1: 73.0539\n",
            "Epoch 7\t Train Loss: 0.0849\t Val Loss 1.1818\t Val Acc: 0.7143\t Val F1: 69.8795\n",
            "Epoch 8\t Train Loss: 0.0218\t Val Loss 1.4575\t Val Acc: 0.7200\t Val F1: 72.0000\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6410, Recall: 0.9146, F1: 0.7538, Loss: 0.7055\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.55      0.68        93\n",
            "           1       0.64      0.91      0.75        82\n",
            "\n",
            "    accuracy                           0.72       175\n",
            "   macro avg       0.76      0.73      0.71       175\n",
            "weighted avg       0.77      0.72      0.71       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.8027\t Val Loss 0.7447\t Val Acc: 0.5371\t Val F1: 65.8228\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.6225\t Val Loss 0.5784\t Val Acc: 0.7657\t Val F1: 74.8466\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4641\t Val Loss 0.5695\t Val Acc: 0.7714\t Val F1: 75.9036\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3056\t Val Loss 0.6434\t Val Acc: 0.7657\t Val F1: 76.0234\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1460\t Val Loss 0.8293\t Val Acc: 0.7714\t Val F1: 72.9730\n",
            "Epoch 6\t Train Loss: 0.0587\t Val Loss 0.9876\t Val Acc: 0.7429\t Val F1: 71.6981\n",
            "Epoch 7\t Train Loss: 0.0161\t Val Loss 1.3674\t Val Acc: 0.7314\t Val F1: 67.1329\n",
            "Epoch 8\t Train Loss: 0.0202\t Val Loss 1.3070\t Val Acc: 0.7486\t Val F1: 72.1519\n",
            "Epoch 9\t Train Loss: 0.0216\t Val Loss 1.3371\t Val Acc: 0.7543\t Val F1: 72.6115\n",
            "\n",
            "\n",
            "early stopping at epoch 9\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7303, Recall: 0.7927, F1: 0.7602, Loss: 0.6434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.74      0.77        93\n",
            "           1       0.73      0.79      0.76        82\n",
            "\n",
            "    accuracy                           0.77       175\n",
            "   macro avg       0.77      0.77      0.77       175\n",
            "weighted avg       0.77      0.77      0.77       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name =  \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCo2gdbFOuIm",
        "outputId": "a28350ab-1146-4810-e0fd-05f286621f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.670000  0.827160  0.740331      7\n",
            "1   0.641026  0.914634  0.753769      3\n",
            "2   0.730337  0.792683  0.760234      4\n",
            " \n",
            "       precision    recall        f1     epoch\n",
            "label                                         \n",
            "label   0.680454  0.844826  0.751445  4.666667\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "h4n2alcNZ_hW",
        "outputId": "9912cb0c-b750-4132-b851-73d018c4d20d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f57a4716750>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e7UoiE1gjku",
        "outputId": "01198bab-2138-4bc6-af68-225ddea91565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "525\n"
          ]
        }
      ],
      "source": [
        "sentences = df.sentence.values\n",
        "print(len(sentences))\n",
        "#labels = list(df1.one_hot_labels.values)\n",
        "#num_labels = len(label_cols)\n",
        "\n",
        "vectors, masks = get_pretrained_wordvector(sentences, tokenizer, bert_model) \n",
        "vectors =  vectors.to(device) * masks.unsqueeze(-1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utiyYW9ud0ur",
        "outputId": "bbd32b95-6a5d-4520-c3fd-0a2a1adb2c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------\n",
            "label\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.6799\t Val Loss 0.6479\t Val Acc: 0.6914\t Val F1: 67.8571\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5372\t Val Loss 0.5536\t Val Acc: 0.7314\t Val F1: 65.1852\n",
            "Epoch 3\t Train Loss: 0.4209\t Val Loss 0.6596\t Val Acc: 0.7029\t Val F1: 62.3188\n",
            "Epoch 4\t Train Loss: 0.3131\t Val Loss 0.6396\t Val Acc: 0.7314\t Val F1: 68.0272\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1829\t Val Loss 0.7523\t Val Acc: 0.7314\t Val F1: 69.2810\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.0807\t Val Loss 0.9601\t Val Acc: 0.7200\t Val F1: 67.5497\n",
            "Epoch 7\t Train Loss: 0.0224\t Val Loss 1.2085\t Val Acc: 0.7314\t Val F1: 70.4403\n",
            "model saved\n",
            "Epoch 8\t Train Loss: 0.0100\t Val Loss 1.6133\t Val Acc: 0.6686\t Val F1: 67.7778\n",
            "Epoch 9\t Train Loss: 0.0057\t Val Loss 1.6232\t Val Acc: 0.6800\t Val F1: 67.4419\n",
            "Epoch 10\t Train Loss: 0.0019\t Val Loss 1.6069\t Val Acc: 0.7486\t Val F1: 70.6667\n",
            "model saved\n",
            "Epoch 11\t Train Loss: 0.0014\t Val Loss 1.7661\t Val Acc: 0.7200\t Val F1: 70.6587\n",
            "Epoch 12\t Train Loss: 0.0007\t Val Loss 1.8678\t Val Acc: 0.7029\t Val F1: 69.7674\n",
            "Epoch 13\t Train Loss: 0.0004\t Val Loss 1.8235\t Val Acc: 0.7429\t Val F1: 71.3376\n",
            "model saved\n",
            "Epoch 14\t Train Loss: 0.0002\t Val Loss 1.8583\t Val Acc: 0.7314\t Val F1: 69.2810\n",
            "Epoch 15\t Train Loss: 0.0003\t Val Loss 1.9023\t Val Acc: 0.7314\t Val F1: 70.0637\n",
            "Epoch 16\t Train Loss: 0.0002\t Val Loss 1.9447\t Val Acc: 0.7314\t Val F1: 70.0637\n",
            "Epoch 17\t Train Loss: 0.0002\t Val Loss 1.9765\t Val Acc: 0.7314\t Val F1: 70.0637\n",
            "Epoch 18\t Train Loss: 0.0002\t Val Loss 2.0055\t Val Acc: 0.7314\t Val F1: 69.6774\n",
            "\n",
            "\n",
            "early stopping at epoch 18\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7368, Recall: 0.6914, F1: 0.7134, Loss: 1.8235\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77        94\n",
            "           1       0.74      0.69      0.71        81\n",
            "\n",
            "    accuracy                           0.74       175\n",
            "   macro avg       0.74      0.74      0.74       175\n",
            "weighted avg       0.74      0.74      0.74       175\n",
            "\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.6838\t Val Loss 0.6566\t Val Acc: 0.5543\t Val F1: 9.3023\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5851\t Val Loss 0.5687\t Val Acc: 0.6857\t Val F1: 69.2737\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.4494\t Val Loss 0.5758\t Val Acc: 0.6914\t Val F1: 72.7273\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.3695\t Val Loss 0.5476\t Val Acc: 0.7257\t Val F1: 65.2174\n",
            "Epoch 5\t Train Loss: 0.2264\t Val Loss 0.5874\t Val Acc: 0.7543\t Val F1: 69.9301\n",
            "Epoch 6\t Train Loss: 0.1255\t Val Loss 0.7687\t Val Acc: 0.7429\t Val F1: 68.0851\n",
            "Epoch 7\t Train Loss: 0.0377\t Val Loss 1.0241\t Val Acc: 0.7371\t Val F1: 71.9512\n",
            "Epoch 8\t Train Loss: 0.0113\t Val Loss 1.2451\t Val Acc: 0.7257\t Val F1: 69.2308\n",
            "\n",
            "\n",
            "early stopping at epoch 8\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6207, Recall: 0.8780, F1: 0.7273, Loss: 0.5758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.53      0.64        93\n",
            "           1       0.62      0.88      0.73        82\n",
            "\n",
            "    accuracy                           0.69       175\n",
            "   macro avg       0.73      0.70      0.69       175\n",
            "weighted avg       0.73      0.69      0.68       175\n",
            "\n",
            "\n",
            "fold 2 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.6910\t Val Loss 0.6593\t Val Acc: 0.7029\t Val F1: 69.4118\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5837\t Val Loss 0.5460\t Val Acc: 0.7200\t Val F1: 63.1579\n",
            "Epoch 3\t Train Loss: 0.4681\t Val Loss 0.5202\t Val Acc: 0.7314\t Val F1: 65.6934\n",
            "Epoch 4\t Train Loss: 0.3796\t Val Loss 0.5623\t Val Acc: 0.7143\t Val F1: 62.6866\n",
            "Epoch 5\t Train Loss: 0.2348\t Val Loss 0.5901\t Val Acc: 0.7829\t Val F1: 75.9494\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.1521\t Val Loss 0.6756\t Val Acc: 0.7429\t Val F1: 69.3878\n",
            "Epoch 7\t Train Loss: 0.0651\t Val Loss 0.8417\t Val Acc: 0.7543\t Val F1: 73.9394\n",
            "Epoch 8\t Train Loss: 0.0169\t Val Loss 1.1765\t Val Acc: 0.7200\t Val F1: 69.1824\n",
            "Epoch 9\t Train Loss: 0.0038\t Val Loss 1.6708\t Val Acc: 0.7200\t Val F1: 72.9282\n",
            "Epoch 10\t Train Loss: 0.0020\t Val Loss 1.5605\t Val Acc: 0.7029\t Val F1: 65.7895\n",
            "\n",
            "\n",
            "early stopping at epoch 10\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7895, Recall: 0.7317, F1: 0.7595, Loss: 0.5901\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.80        93\n",
            "           1       0.79      0.73      0.76        82\n",
            "\n",
            "    accuracy                           0.78       175\n",
            "   macro avg       0.78      0.78      0.78       175\n",
            "weighted avg       0.78      0.78      0.78       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use our labeled data\n",
        "\n",
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.0]\n",
        "\n",
        "result = []\n",
        "label_cols = ['label']\n",
        "\n",
        "for col in label_cols:\n",
        "    print(\"\\n------------\") \n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "    \n",
        "    y = df[col].astype(int).values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in skf.split(vectors, y): \n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = vectors[train_index], vectors[test_index]\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        #weight = 10\n",
        "        #train_sample_weight = np.array([weight if i ==1 else 1 for i in Y_train])\n",
        "        #test_sample_weight = np.array([weight if i ==1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name = \"/content/drive/MyDrive/temp/bert_model/model_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = lstm_cnn(emb_dim, seq_len, 100, \\\n",
        "                         num_filters, kernel_sizes, num_labels)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "        \n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        tokenized_texts, pred_labels, true_labels,avg_val_loss = model_eval(model, validation_dataloader, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100 \n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "   \n",
        "    \n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "        \n",
        "    \n",
        "        #p, r, f = train_model(model, X_train, Y_train, train_sample_weight,\\\n",
        "        #                   X_test, Y_test, test_sample_weight, \\\n",
        "        #                   'baseline_models/lstm_cnn/'+col)\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oX2u74djlwQ",
        "outputId": "60974b1f-bcf6-4821-8fa7-e94a8ac62f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "   precision    recall        f1  epoch\n",
            "0   0.736842  0.691358  0.713376     13\n",
            "1   0.620690  0.878049  0.727273      3\n",
            "2   0.789474  0.731707  0.759494      5\n",
            " \n",
            "       precision    recall        f1  epoch\n",
            "label                                      \n",
            "label   0.715668  0.767038  0.733381    7.0\n"
          ]
        }
      ],
      "source": [
        "result_df = pd.DataFrame(result, columns =[\"label\",\"fold\",\"precision\",\"recall\",\"f1\",\"epoch\"])\n",
        "\n",
        "for col in label_cols:\n",
        "    print(col)\n",
        "    print(result_df[result_df.label == col][[\"precision\",\"recall\",\"f1\",\"epoch\"]])\n",
        "    print(\" \")\n",
        "print(result_df[[\"label\",\"precision\",\"recall\",\"f1\",\"epoch\"]].groupby(\"label\").mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "j99LBCGGHaZw",
        "outputId": "4c19caca-e376-4cce-f9f9-3c4a8c1b84af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e9337e810>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VnSQQQlZICIR9ERQJoiKyCIiKYhUFQVy6UK1W69NF2traWm3t8/Rn1dZKrXUtrlgrWtnBXZCAKHsCCCQsSUjYQsh+/f44Q5xgQgJMOJmZ6/165TUzZ5sro3znzn3ucx9RVYwxxgSuELcLMMYY07Is6I0xJsBZ0BtjTICzoDfGmABnQW+MMQHOgt4YYwJcWFMbiMgzwASgUFXPamD9T4FpXsfrCySpaomIbAcOAzVAtapm+apwY4wxzSNNjaMXkYuBUuCFhoL+uG2vBO5R1dGe19uBLFXd55tyjTHGnKwmu25U9QOgpJnHuwF4+bQqMsYY41NNdt00l4hEA+OBO70WK7BQRBT4u6o+1ZxjJSYmateuXX1VmjHGBLxVq1btU9Wkhtb5LOiBK4GPVdW79X+Rqu4SkWRgkYhs8vyF8A0iMgOYAZCRkUF2drYPSzPGmMAmIjsaW+fLUTdTOK7bRlV3eR4LgTeB8xrbWVWfUtUsVc1KSmrwS8kYY8wp8EnQi0gcMAJ4y2tZjIi0PfYcGAes88X7GWOMab7mDK98GRgJJIpIPnA/EA6gqrM8m30LWKiqR7x2TQHeFJFj7/OSqs73XenGGGOao8mgV9UbmrHNc8Bzxy3bBpx9qoUdr6qqivz8fMrLy311yKAUFRVFeno64eHhbpdijDlDfHkytkXl5+fTtm1bunbtiuevBHOSVJXi4mLy8/PJzMx0uxxjzBniN1MglJeXk5CQYCF/GkSEhIQE+6vImCDjN0EPWMj7gH2GxgQfvwp6Y4zxudJCWD4L9jc6DN3vWdAbY4LbO/fA/HvhsbPhhYmwdg5UBVb3pgV9Mx04cIC//e1vJ73f5ZdfzoEDB056v1tuuYU5c+ac9H7GmJOw7T3Y9A5ccCeMnAnF2+CN78D/6w3v/gz2rnW7Qp+woG+mxoK+urr6hPu9++67tG/fvqXKMsacqppqmP9zaJ8Bo+9zgv7uL2D6m9B9NKx6FmZdBH8fAZ/9A46efIOttfCb4ZXefvv2ejbsPuTTY/br1I77r+zf6PqZM2eydetWzjnnHMLDw4mKiiI+Pp5NmzaRk5PD1VdfTV5eHuXl5dx9993MmDEDgK5du5KdnU1paSmXXXYZF110EZ988glpaWm89dZbtGnTpsnalixZwk9+8hOqq6sZMmQITz75JJGRkcycOZO5c+cSFhbGuHHj+NOf/sTrr7/Ob3/7W0JDQ4mLi+ODDxqcWsgYs+pZKNwA178A4Z5/hyEhTsh3Hw1lJfDla/D5i/DuT2DhfdD3Kjh3OnS5yNnWT/hl0Lvh4YcfZt26daxZs4b33nuPK664gnXr1tWNR3/mmWfo0KEDR48eZciQIVx77bUkJCTUO0Zubi4vv/wy//jHP7j++ut54403uPHGG0/4vuXl5dxyyy0sWbKEXr16cdNNN/Hkk08yffp03nzzTTZt2oSI1HUPPfDAAyxYsIC0tLRT6jIyJiiUlcCyh6DrcCe8GxLdAc6/DYZ+H3Z/7gT+2jmw9jWI7wqDboRzpkG7Tme09FPhl0F/opb3mXLeeefVu+jo8ccf58033wQgLy+P3NzcbwR9ZmYm55xzDgCDBw9m+/btTb7P5s2byczMpFevXgDcfPPNPPHEE9x5551ERUXxne98hwkTJjBhwgQAhg0bxi233ML111/PNddc44tf1ZjA8/4fofwgjP8DNDXkWATSznV+xj0EG992Qn/pg7Ds99BjDAyaDr3GQ1jEman/JPnP3x6tTExMTN3z9957j8WLF/Ppp5/yxRdfMGjQoAYvSoqMjKx7Hhoa2mT//omEhYXx2WefMWnSJN555x3Gjx8PwKxZs3jwwQfJy8tj8ODBFBcXn/J7GBOQCjc5fe6Db4HUASe3b0Q0nD0ZbnkHfrgaLrrHOWH72nR4pC8s+KVz/FbGL1v0bmjbti2HDx9ucN3BgweJj48nOjqaTZs2sXz5cp+9b+/evdm+fTtbtmyhR48evPjii4wYMYLS0lLKysq4/PLLGTZsGN26dQNg69atDB06lKFDhzJv3jzy8vK+8ZeFMUFLFebPhMhYGPXL0ztWQne45Ncw8hewdQmsfgFWzIJP/wrpQ5xW/lnXQGRb39R+GizomykhIYFhw4Zx1lln0aZNG1JSUurWjR8/nlmzZtG3b1969+7N+eef77P3jYqK4tlnn+W6666rOxl72223UVJSwsSJEykvL0dVeeSRRwD46U9/Sm5uLqrKJZdcwtln+2xeOWP8X8582LYMxj8MMYm+OWZoGPS61PkpLYQvX4XVL8Lbdzmjevp/yzmB23lo091ELaTJm4O7ISsrS4+/w9TGjRvp27evSxUFFvssTVCqroC/nQ8hYXD7JxDagjO4qkL+SqeVv/5NqCyFhJ7OCdyzb4C2KU0f4ySJyCpVzWponfXRG2OCw4pZULINLv1Dy4Y8OC33zufBxL/CjzfDVX91RvEsvt/py395Kmye54zlPwOs68Zld9xxBx9//HG9ZXfffTe33nqrSxUZE4BKC+H9/4Oel0LPMWf2vSNjna6bc6dD0WZnxM4Xr8Dm/0JsKpxzg9Ofn9C9xUqwoHfZE0884XYJxgS+JQ9A9VG49Pfu1pHUG8Y9CJfcDzkLnND/+DH46M+QcaHzZTDgeqff34es68YYE9h2fw6f/wuG3gaJPdyuxhEaDn0nwNRX4Z4Nzuid0r3OuHzxfSxbi94YE7hUYd5MiE6AET9zu5qGtesIw38MF/0PHNrVIlMrWNAbYwLXujcgbzlc+ThExbldzYmJQFx6ixzaum6MMYGpsgwW/RpSBzrDGoNYk0EvIs+ISKGIrGtk/UgROSgiazw/v/ZaN15ENovIFhGZ6cvCW7vY2NhG123fvp2zzjrrDFZjTBD6+DGnK+SyP0JIqNvVuKo5LfrngPFNbPOhqp7j+XkAQERCgSeAy4B+wA0i0u90ijXGmGY5kAcfPwr9r4EuF7pdjeua7KNX1Q9EpOspHPs8YIuqbgMQkVeAicCGUzhWffNm+v7OL6kD4LKHG109c+ZMOnfuzB133AHAb37zG8LCwli2bBn79++nqqqKBx98kIkTJ57U25aXl3P77beTnZ1NWFgYjzzyCKNGjWL9+vXceuutVFZWUltbyxtvvEGnTp24/vrryc/Pp6amhl/96ldMnjz5tH5tYwLS4vudx7EPuFtHK+Grk7EXiMgXwG7gJ6q6HkgD8ry2yQeGNnYAEZkBzADIyMjwUVm+M3nyZH70ox/VBf1rr73GggULuOuuu2jXrh379u3j/PPP56qrrkJOYj6LJ554AhFh7dq1bNq0iXHjxpGTk8OsWbO4++67mTZtGpWVldTU1PDuu+/SqVMn/vvf/wLOZGrGmOPs+MQ5CTviXmjf2e1qWgVfBP1qoIuqlorI5cB/gJ4nexBVfQp4Cpy5bk648Qla3i1l0KBBFBYWsnv3boqKioiPjyc1NZV77rmHDz74gJCQEHbt2kVBQQGpqanNPu5HH33ED3/4QwD69OlDly5dyMnJ4YILLuChhx4iPz+fa665hp49ezJgwAB+/OMfc++99zJhwgSGDx/eUr+uMf6ptgbm3Qvt0mDY3W5X02qc9qgbVT2kqqWe5+8C4SKSCOwCvL9O0z3L/NZ1113HnDlzePXVV5k8eTKzZ8+mqKiIVatWsWbNGlJSUhqch/5UTJ06lblz59KmTRsuv/xyli5dSq9evVi9ejUDBgzgvvvu44EH7M9SY+pZMxv2ful02UTENL19kDjtFr2IpAIFqqoich7Ol0cxcADoKSKZOAE/BZh6uu/npsmTJ/O9732Pffv28f777/Paa6+RnJxMeHg4y5YtY8eOHSd9zOHDhzN79mxGjx5NTk4OO3fupHfv3mzbto1u3bpx1113sXPnTr788kv69OlDhw4duPHGG2nfvj1PP/10C/yWxvip8oPOVAedz4ezrnW7mlalyaAXkZeBkUCiiOQD9wPhAKo6C5gE3C4i1cBRYIo6cx9Xi8idwAIgFHjG03fvt/r378/hw4dJS0ujY8eOTJs2jSuvvJIBAwaQlZVFnz59TvqYP/jBD7j99tsZMGAAYWFhPPfcc0RGRvLaa6/x4osvEh4eTmpqKr/4xS9YuXIlP/3pTwkJCSE8PJwnn3yyBX5LY/zUB/8HR/bBtNddm/e9tbL56IOQfZYm4BRvhSeGOrf5mxicEwXafPTGmMC24JcQFgWjf930tkHI5rppQWvXrmX69On1lkVGRrJixQqXKjImAG1ZDDnznBOwLXDnpkDgV0Gvqic1Rt1tAwYMYM2aNW6XUU9r7Koz5pTVVMH8X0B8pjMNsWmQ33TdREVFUVxcbEF1GlSV4uJioqKi3C7FGN9Y+U/Yt9m5oUhYpNvVtFp+06JPT08nPz+foqIit0vxa1FRUaSnt8xUqMacUUeK4b3fQ7dR0Psyt6tp1fwm6MPDw8nMzHS7DGNMa7HsIagohfF/sOGUTfCbrhtjjKmzdx2sehaGfBeSbahwUyzojTH+RRXmz3TuGDUyqG5zccos6I0x/mXTO7D9Qxj1S4ju4HY1fsGC3hjjP6rKnYujkvvB4FvdrsZv+M3JWGOMYfkTcGAH3PQWhFp8NZe16I0x/uHQHvjg/0GfCdBtpNvV+BULemOMf1jyW6itgnEPul2J37GgN8a0fvnZ8MXLcMEd0MGupzlZFvTGmNattta5PWBsCgz/sdvV+CU7m2GMad3Wvg67suHqJyGyrdvV+CVr0RtjWq+KUlh8P3Q6FwZOcbsav2UtemNM6/XRn+HwHrj+BQixdumpsk/OGNM67d8On/wFBk6Gzue5XY1fs6A3xrROC38FIaEw5jduV+L3mgx6EXlGRApFZF0j66eJyJcislZEPhGRs73WbfcsXyMi2Q3tb4wx3/DVh7BxLgz/H2jXye1q/F5zWvTPAeNPsP4rYISqDgB+Bzx13PpRqnpOY3cnN8aYemprnNkp4zLggjvdriYgNHkyVlU/EJGuJ1j/idfL5YDdvsgYc+pWPw8F6+C65yG8jdvVBARf99F/B5jn9VqBhSKySkRm+Pi9jDGB5uh+WPI76HIR9JvodjUBw2fDK0VkFE7QX+S1+CJV3SUiycAiEdmkqh80sv8MYAZARkaGr8oyxviT9/8Xyg/Y7QF9zCctehEZCDwNTFTV4mPLVXWX57EQeBNodIyUqj6lqlmqmpWUlOSLsowx/qRoM3z2FJx7M3Qc6HY1AeW0g15EMoB/A9NVNcdreYyItD32HBgHNDhyxxgT5FRh/s8hPAZG3+d2NQGnya4bEXkZGAkkikg+cD8QDqCqs4BfAwnA38T5U6vaM8ImBXjTsywMeElV57fA72CM8Xe5C2HrErj0DxCT6HY1AUdU1e0aviErK0uzs23YvTFBoboS/na+c3HU7Z9AaLjbFfklEVnV2DB2m+vGGOOuz56Ckq0w7Q0L+RZiUyAYY9xTWgTv/xF6joOeY9yuJmBZ0Btj3LP0d1BVBpf+3u1KApoFvTHGHds/gtUvwNDbILGn29UENAt6Y8yZt28LvDLNCfgR97pdTcCzoDfGnFllJfDSdRASBlNfg6h2blcU8GzUjTHmzKmucFryB3fBzW9Dh0y3KwoKFvTGmDNDFd6+G3Z+Atf+EzKGul1R0LCuG2PMmfHBn+CLl2HUL2HAJLerCSoW9MaYlrd2Dix7EAZOgYt/6nY1QceC3hjTsvI+g//8ADIuhKset+mHXWBBb4xpOSVfwcs3QFwaTJkNYZFuVxSULOiNMS3j6AF4aTLUVjvDKKM7uF1R0LJRN8YY36upgtdvhpJtMP1Nu/LVZRb0xhjfUoX//hi2vQcT/waZw92uKOhZ140xxrc++Qusfh6G/xgGTXO7GoMFvTHGlza+DYt+Df2uhlF2S8DWwoLeGOMbuz+HN74HaYPhW7MgxOKltbD/EsaY03cwH16aAjFJcMPLEN7G7YqMFzsZa4w5PRWHnWGUVWVw038gNtntisxxLOiNMaeuphrmfBsKN8K01yG5r9sVmQY0q+tGRJ4RkUIRWdfIehGRx0Vki4h8KSLneq27WURyPT83+6pwY0wrsPCXkLsQrvgT9LjE7WpMI5rbR/8cMP4E6y8Denp+ZgBPAohIB+B+YChwHnC/iMSfarHGmFZkxVOwYhZccCdkfdvtaswJNCvoVfUDoOQEm0wEXlDHcqC9iHQELgUWqWqJqu4HFnHiLwxjjD/IWQjz74Xel8PYB9yuxjTBV6Nu0oA8r9f5nmWNLTfG+Ku962DOrZByFlz7NISEul2RaUKrGV4pIjNEJFtEsouKitwuxxjTkMN7nRE2ke1g6qsQEeN2RaYZfBX0u4DOXq/TPcsaW/4NqvqUqmapalZSUpKPyjLG+EzlESfkj+6Hqa9Au05uV2SayVdBPxe4yTP65nzgoKruARYA40Qk3nMSdpxnmTHGn9TWwr9nwN4vYdI/oePZbldkTkKzxtGLyMvASCBRRPJxRtKEA6jqLOBd4HJgC1AG3OpZVyIivwNWeg71gKqe6KSuMaY1WvIb2PQOjH8Yel/mdjXmJDUr6FX1hibWK3BHI+ueAZ45+dKMMa3Cqufg48dgyHdh6G1uV2NOQas5GWuMaYW2LnPmlu8xBsb/0e736qcs6I0xDSvaDK/dDIm9YNKzEGozpvgrC3pjzDeVFsHs65ybeU99FaLauV2ROQ32FW2Mqa+qHF6ZCqUFcMu70D7D7YrMabKgN8Z8TRXe+gHkfwbXPQ/pg92uyPiAdd0YY7723h9g3Rsw5jfQ/2q3qzE+YkFvjHF88Qq8/0cYdCMM+5Hb1RgfsqA3xsD2j+GtO6HrcLjizzaMMsBY0BsT7Iq3wqvTIL4rTH4RwiLcrsj4mAW9McGsrAReuh4QmPYatLH7AgUiG3VjTLCqroRXp8OBnXDTXOjQze2KTAuxoDcmGKnC23fDjo/gmn9Alwvcrsi0IOu6MSbYqMIHf4IvXoKRP4eB17tdkWlh1qI3JpgUbYb5M2HrUhhwHYy41+2KzBlgQW9MMDh6wBkj/9lTEB7jzCs/5Hs2jDJIWNAbE8hqa+DzF2HJ76CsGAbfAqPvg5hEtyszZ5AFvTGBasenMO9nzu3/Mi6Ey/4IHQe6XZVxgQW9MYHmYD4s+rUzZ027dJj0DPS/xrppgpgFvTGBouoofPIX+OjPoLXOidZhP4KIaLcrMy6zoDfG36nCxrmw8D7n4qd+E2Hs7yC+i9uVmVbCgt4Yf1awHubdC9s/hOT+cPPbkHmx21WZVqZZQS8i44HHgFDgaVV9+Lj1fwZGeV5GA8mq2t6zrgZY61m3U1Wv8kXhxgS1shJY9hBkPwNRcXD5n2DwrXZfV9OgJv+vEJFQ4AlgLJAPrBSRuaq64dg2qnqP1/Y/BAZ5HeKoqp7ju5KNCWI11bDqWSfkyw9C1ndg1C8guoPblZlWrDlf/+cBW1R1G4CIvAJMBDY0sv0NwP2+Kc8YU+erD2DeTChc78wbf9kfIaW/21UZP9CcoE8D8rxe5wNDG9pQRLoAmcBSr8VRIpINVAMPq+p/Gtl3BjADICPDbkZsTJ39O5wTrRvnQlwGXP8C9L3KhkuaZvN1h94UYI6q1ngt66Kqu0SkG7BURNaq6tbjd1TVp4CnALKystTHdRnjfyqPOEMlP34cQkJh1H1w4Z0Q3sbtyoyfaU7Q7wI6e71O9yxryBTgDu8FqrrL87hNRN7D6b//RtAbYzxUnYudFv0aDu2CsybB2N9CXLrblRk/1ZygXwn0FJFMnICfAkw9fiMR6QPEA596LYsHylS1QkQSgWHA//qicGMC0p4vnOGSOz+F1IFw7T9trnhz2poMelWtFpE7gQU4wyufUdX1IvIAkK2qcz2bTgFeUVXvbpe+wN9FpBZn7vuHvUfrGGM8juyDJQ/A6hecETRXPgaDpjtdNsacJqmfy61DVlaWZmdnu12GMS2vpgo++we89zBUHYHzZjhTF7Rp73Zlxs+IyCpVzWpoXUBdXfHPj75iQFocQ7rGIzYiwbR2WxbD/J/DvhzofgmM/wMk9Xa7KhOAAiboj1RU8+jiHA6XV9MlIZprz03nmnPTSI+3CZ1MK1O8FRb8EnLmQXwm3PAK9BpvwyVNiwmorpuyymrmrd3LnFX5fLqtGIALuydwXVY64/t3pE2E9Xcal9RUOSdYN8yF1c9DaARc/BM4/wcQFul2dSYAnKjrJqCC3lteSRn/Xr2LOavzyCs5SmxkGFcM6MikrHSyuljXjjkDykqc7pnN82DLEqg46AT8WZPgkl9Du45uV2gCSPAE/avToePZMOhGaJsKQG2t8tn2EuasyufdtXsoq6yha0I0kwan861z00lrbxefGB9RhX25TpdMzgLYuRy0BmKSoOel0Hs8dBsJkW3drtQEoOAI+orD8PINznStEgq9L3Puj9l9dN0QtSMV1cxbt5c5q/JYvq0EERjWPZHrstIZ1y/VunbMyaupgh2fOMGeMw9KtjnLU85y+t17XwadzoWQEHfrNAEvOIL+mOKtTh/o57OhbB/EdXbGIw+6EeLS6jbbWVzGG6vzeWN1Pvn7j9I2MowJZ3dk0uB0zs2wrh1zAo11yWRe7IR7r0uhvc3XZM6s4Ar6Y6orYfO7sOo52LYMJAR6jnNa+T3G1s3bXVurrPiqhNdX5TFv7V6OVtXQLTGGawc7o3Y6xlnXTtDz7pLZPB/ylju36otJhl7joNdlni6ZWLcrNUEsOIPeW8lX8PmL8Pm/oLQA2nZ0WvnnTq/X8iqtqObdtXuYsyqfz75yunYu6pHIpMHpXNo/lahw69oJGnVdMvOdlvv+r5zlKQOcvvZel0GnQdYlY1oNC/pjaqqcvtRVzzl/egP0uMRp5fcaD6HhdZvuKD7CG6t38caqfHYdOErbqDCuPLsTkwanM6hze+vaCURlJZC7yGm5b1kCFYcgNNLpkuk93jmh2r5z08cxxgUW9A05sNNp4a9+EQ7vhtgUOGcanHsTdMis26y2Vlm+rdgZtbNuD+VVtXRLimHS4HSuGZROalxUy9ZpWo6qc1Xq5nlOyz1vhVeXzKXOidTMEdYlY/yCBf2J1FQ7rftVz0HuAucfereRTiu/9xUQFlG36eHyKuat3cvrq/JYuX0/IQLDeyYxaXA6Y/ulWNeOP6iuhJ2fOH3tOfO/7pJJHeB0x/Qab10yxi9Z0DfXwV2wZrYzg+DBPIhOhHOmwrk3Q2KPeptu33fEGbWzKp/dB8tp5+nauS6rM2enx1nXjptUnW6XwwVQuvfrx12r6nfJdBvx9SgZm+vd+DkL+pNVWwNblzk3Yd48z7nopetwp5XfZwKEf91dU1urfLqtmNez85i/fi/lVbX0SI5lypDOTBqcTvvoiMbfx5yc2looK64f3qUF3wz0wwVQffSb+8emOKHey3PhUkTMmf4NjGkxFvSn4/Der1v5+7dDm3g4eyoMvvkbMw0eKq/i3S/38Fp2Hqt3HiAiLIQJAzoy7fwMG5t/IjVV9QO7sfA+Ugi11d/cP7KdE+JtU+s/xqZA2xSITXUeo9rbxGEmYFnQ+0JtLXz1vnMx1sZ3oLYKMi5wunX6X/2N+3hu3HOIl1bs5M3Pd1FaUU2f1LZMHZrB1YPSaBcV3sibBBhVOLzHubn18aHt/VhW3PD+0YlNh3dsKkTYDKXGWND7WmkRfPGycwK3ZCtExcHAKU4rP6V/vU2PVFTz9he7mb1iJ2t3HaRNeCgTz+nE1KEZDEwPkJtLlJVA8RbnquTiLV8/L9nm3EzDW0iYV2CnQmxy/dA+9hibXG+4qzHmxCzoW4oqbP/IaeVveAtqKiF9iDNEM+UsJ6xikuqmof0y/wAvrdjJW2t2c7SqhgFpcUwbmsGVZ3ciJrKV3xqgotT5Uive+nWgl3gej+7/ejsJhfgu0KE7JPSAhO7OnOttU52fNh1sRIsxLcCC/kwoK4EvXnFa+fs2118XFeeMzfYEf0WbJDYcjOS9XbDuYCRHwhPI6t+bCRcMpE/nZFfKB6C6wjkP4d0yL9nmPB7eU3/bdmlOiNcFuifU23epNyTVGHNmWNCfSapQsA4O5DknD0uLnJOLx54fe6w42ODuRySG2ugkYjp0JKRtcr0vCKfL49jz5G+cF2iW2ho4mF+/q+VYy/zATuc6gmOiE5wA79DdCfFjgd4h00asGNPKnPY9Y0VkPPAYEAo8raoPH7f+FuD/gF2eRX9V1ac9624G7vMsf1BVnz/p38CfiDgX36QOOPF2VeVwpAhKC+FIIUdKdrMxdys787YTcaiY1CMH6Bq1i3g9SGgjXwpEtIXYJM+XgeeL4NjzmGTnis79O+q3zEu2OV1MdceIdUI8bTAMuN6rdd7NGWFkjPF7TbboRSQUyAHGAvnASuAGVd3gtc0tQJaq3nncvh2AbCALUGAVMFhV93MCft2iP02qzrj82St2snD9XqpqlIsyY7l5YCwj0yC8fJ/zF0JpodcXheextADKD3zzoKER0KGbpzXerX5XS2yKDTk0JgCcbov+PGCLqm7zHOwVYCKw4YR7OS4FFqlqiWffRcB44OXmFB6MRIQLuydyYfdEig5X8PqqPF5asZPvvbWXhJgIrsvqwtTzhpOR0MiQwupKJ/iPFDo3Y2nfxbnqM8SmZzAmWDUn6NOAPK/X+cDQBra7VkQuxmn936OqeY3sm9bAvqYBSW0j+cHIHtx2cXc+3LKP2ct38I8PtzHr/a0M75nItKFdGNM3mbBQr1EsYRHODVbi7GM2xjh8NabvbeBlVa0Qke8DzwOjT+YAIjIDmAGQkWF35/EWEiKM6JXEiF5J7D1Yzqsr83hl5U5u+9cqUtpFMnlIBlOGdKaT3f/WGNOA5gxo3gV4T8KdztcnXQFQ1WJVrfC8fBoY3Nx9vY7xlKpmqWpWUlJSc2oPSqlxUUVP3YAAABF5SURBVNw9picf/mwU/7gpi74d2/GXpblc9MelfPf5lSzbVEhNbesbSWWMcU9zWvQrgZ4ikokT0lOAqd4biEhHVT020PoqYKPn+QLg9yJybPjGOODnp121ISw0hLH9UhjbL4W8kjJeWbmTV1fms3jjStLat+GG8zpzfVZnktvZfPnGBLtmjaMXkcuBR3GGVz6jqg+JyANAtqrOFZE/4AR8NVAC3K6qmzz7fhv4hedQD6nqs029XzCPujkdldW1LN5YwOwVO/h4SzEhAkO6dmBsvxTG9Utt/ASuMcbv2QVTQeirfUd4Y1U+izYUsLngMAB9UtvWhf5Zae1sNk1jAogFfZDbUXyERRsKWLihgOztJdQqdIyLYkzfFMb1T2FoZgIRYTb/jDH+zILe1Ck5UsmSjQUs2lDAB7lFlFfV0jYyjJF9khnXL4WRvZNoGyzTKBsTQCzoTYOOVtbw0ZZ9LNqwlyUbCyk+Ukl4qHB+twTG9U9lbN8Uu/m5MX7Cgt40qaZWWb1zP4s2OK39r/Y588gPTI9jXL8UxvZLpVdKrPXrG9NKWdCbk6KqbC0qZcF6J/TX5Dnz52R0iPaczE1hcJf4+lfkGmNcZUFvTkvBoXIWe/r1P9lSTGVNLfHR4Yzu45zMvbhnEm0ibC4dY9xkQW98prSimvc3F7Fow16WbirkUHk1kWEhDO+ZxLh+KYzum0xibKTbZRoTdE57PnpjjomNDOOKgR25YmBHqmpqWflVCQs9/fqLNxYgAlld4j1X7aaSmWg3KDHGbdaiNz6hqmzYc4iFnn79DXsOAdAjOZbLB3Tklgu70iHGbjFoTEuxrhtzxuWVlNX163+6rZjo8FBuHZbJd4dn0j7aAt8YX7OgN67KLTjMo0ty+e+Xe2gbGca3L8rk2xdlEtfGLswyxlcs6E2rsHHPIR5bnMv89XtpFxXG94Z345ZhXe1KXGN8wILetCrrdh3k0cW5LN5YQPvocCfwL+xKTKSNDTDmVFnQm1bpy/wDPLo4l6WbCukQE8H3L+7G9Au6EB1hgW/MybKgN63a5zv38+fFuXyQU0RibAS3jejOtKFd7CIsY06CBb3xC9nbS/jz4hw+3lLsuTF6d244L4OocAt8Y5piQW/8yoptxTyyKIcVX5WQ2i6KO0Z15/ohnYkMs8A3pjEW9MYvfbJ1H48szCF7x346xUVxx+geXDe4s90kxZgGWNAbv6WqfLRlH48syuHznQdIa9+Guy7pwTXnphNus2caU8eC3vg9VeW9nCIeXZTDF/kHyegQzV2X9OTqczrZdMnGYEFvAoiqsnRTIY8symH97kNkJsZw9yU9ufLsToSG2E1RTPA6UdA3qykkIuNFZLOIbBGRmQ2s/x8R2SAiX4rIEhHp4rWuRkTWeH7mnvqvYQyICJf0TeGdH17E36cPJjIshB+9uoZxf36fuV/spra29TVcjHFbky16EQkFcoCxQD6wErhBVTd4bTMKWKGqZSJyOzBSVSd71pWqauzJFGUtetNctbXK/PV7eXRxDjkFpfRKieVHY3oxvn8qIdbCN0HkdFv05wFbVHWbqlYCrwATvTdQ1WWqWuZ5uRxIP52CjWmukBDh8gEdmX/3xfzlhkHU1Co/mL2ayx//kAXr99IauyaNOdOaE/RpQJ7X63zPssZ8B5jn9TpKRLJFZLmIXH0KNRrTpJAQ4cqzO7HwnhE8OvkcKqpr+f6Lq5jwl49YvKHAAt8ENZ9OKiIiNwJZwAivxV1UdZeIdAOWishaVd3awL4zgBkAGRkZvizLBJHQEOHqQWlMGNiR/6zZzeNLcvnuC9kMTI/j+xd35+JeiTZbpgk6zemjvwD4jape6nn9cwBV/cNx240B/gKMUNXCRo71HPCOqs450XtaH73xlaqaWt5cvYvHl+aSv/8oYSHCkK4dGN0nmVF9kuieFIuI9eUb/3dawytFJAznZOwlwC6ck7FTVXW91zaDgDnAeFXN9VoeD5SpaoWIJAKfAhO9T+Q2xILe+FpVTS2rd+xn6eZC3ttUxOaCwwCkx7dhVG8n9C/olmgTqRm/ddrj6EXkcuBRIBR4RlUfEpEHgGxVnSsii4EBwB7PLjtV9SoRuRD4O1CLcz7gUVX9Z1PvZ0FvWtquA0d5b3MhyzYV8fGWfRytqiEyLIQLuic4wd87mYyEaLfLNKbZ7IIpY06gvKqGldtLWLapiGWbC/lq3xEAuiXF1IX+kMx4m1TNtGoW9MachK/2HXFa+5uLWL6tmMrqWmIiQhnWI5FRfZIZ2TuJjnFt3C7TmHpOFPR2Kx9jjpOZGENmYia3DsukrLKaT7cWs8zTzbNwQwEAfVLbMqqP09o/N6O9zbdjWjVr0RvTTKpKbmEpyzYVsmxzIdnb91Ndq7SLCuPiXkmM6p3MiN5JJMZGul2qCULWdWNMCzhUXsXHufuc1v7mIooOVyACA9PiGNk7mVF9khmYFmdTMZgzwoLemBZWW6ts2HOorrX/ed4BVCEhJoIRvZ3W/sU9k4iLtou1TMuwoDfmDCs5UsmHuUUs21TI+zlF7C+rIkRgcJd4RvdJYWy/ZLtYy/iUBb0xLqqpVdbkHeC9zYUs3VTI+t2HAOiaEM2YvimM6ZdCVpd4O6FrTosFvTGtyJ6DR1mysZDFGwv4ZEsxlTW1xLUJZ3SfZMb0TbH5eMwpsaA3ppUqrajmo9wiFm0oZOmmAvaXVREeKpzfLYGx/VK4pG8Kae1tzL5pmgW9MX6gplZZtWM/izcWsGhDQd0Vuv06tmNMvxTG9Uuhf6d21q9vGmRBb4wf2lpUyuINBSzeWMCqHfupVUhtF8WYfk4XzwXdE2xaBlPHgt4YP1dcWsGyzUUs3lDAB7lFlFXWEBMRysW9khjTN4VRfZLpEBPhdpnGRRb0xgSQ8qoaPt1WXNfaLzhUQYhAVpcOda39bkkndZtmEwAs6I0JUKrKul2HWLSxgMUbCtiwxxm62S0phrGeoZvnZsQTalfnBjwLemOCRP7+MpZuKmTRhgKWbyumqkbpEBPBqN7JjO2XzPCeScRE2lyGgciC3pggdLi8ivdznH79pZsKOVReTURYCBd2T2BM3xQGZbSne1IsUeF2QjcQWNAbE+SqamrJ3v710M2dJWUAhAh0SYihZ3IsvVPb0jOlLb1SYslMjLERPX7Ggt4YU0dV2bbvCBt2HyK34DA5BaXkFB5mR3EZNbVOHoSGCF0ToumV4oR/b88XQNfEGMJtqoZWyW48YoypIyJ0T4ql+3Ejcyqqa9hWdIScgsOen1I27jnE/PV7OdYeDA8VMhNjnJZ/clt6p8bSM6UtXTpE21w9rZgFvTEGgMiwUPp2bEffju3qLS+vqmFLYSm5hYfZvLeU3ILDfJl/gP9+uadum4jQELolxdDL0/I/9ldA5w7RNuKnFWhW0IvIeOAxIBR4WlUfPm59JPACMBgoBiar6nbPup8D3wFqgLtUdYHPqjfGtLio8FDOSovjrLS4esvLKqvZUlhKToET/psLDrNqx37mfrG7bpvIsBB6JMd6uoBi6ZXcll4pbUmPb2M3ZDmDmgx6EQkFngDGAvnAShGZq6obvDb7DrBfVXuIyBTgj8BkEekHTAH6A52AxSLSS1VrfP2LGGPOrOiIMAamt2dgevt6y0srqsktOExuQanTBVRYyqdbi3nz811127QJD6VnitN9FNcmnJjIUKIjwoiOCCUmIozoSM9jRCgxkWG08VoeHR5q3UQnqTkt+vOALaq6DUBEXgEmAt5BPxH4jef5HOCv4sy8NBF4RVUrgK9EZIvneJ/6pnxjTGsTGxnGoIx4BmXE11t+8GgVWwo9J389XwQrthVzuKKassqauhPBzREZFuJ8AYSH1n1JeH9ZREeEERMRSnTk14/RJ9i2TUQoIQIhngnjQkQIEed8xrFHf9acoE8D8rxe5wNDG9tGVatF5CCQ4Fm+/Lh90065WmOM34prE87gLh0Y3KXDN9apKpU1tZRV1HCk0gn+IxXVHK2s4UhlDWWV1RypcB7LKj3bVNR/PFpZQ8mRo9/Y1lfE80UgeB6lsWVS96Vx7PWx9ce+NMRr/bH9RSAhJpLXbrvAZzUf02pOxorIDGAGQEZGhsvVGGPOJBEhMiyUyLBQ4n04OVttrVJeXVMX/N5fAN6vj1bVUKugCrWeIUa1teosw/OoWrde8Tx6ltdq/dfH1h87pve+x46pXvscO2bbFrpquTlH3QV09nqd7lnW0Db5IhIGxOGclG3OvgCo6lPAU+CMo29O8cYYcyIhIeLpogkDIt0uxzXNOaOxEugpIpkiEoFzcnXucdvMBW72PJ8ELFXnSqy5wBQRiRSRTKAn8JlvSjfGGNMcTbboPX3udwILcIZXPqOq60XkASBbVecC/wRe9JxsLcH5MsCz3Ws4J26rgTtsxI0xxpxZNgWCMcYEgBNNgWCDUY0xJsBZ0BtjTICzoDfGmABnQW+MMQHOgt4YYwJcqxx1IyJFwI5T3D0R2OfDcvyZfRb12edRn30eXwuEz6KLqiY1tKJVBv3pEJHsxoYYBRv7LOqzz6M++zy+FuifhXXdGGNMgLOgN8aYABeIQf+U2wW0IvZZ1GefR332eXwtoD+LgOujN8YYU18gtuiNMcZ4CZigF5HxIrJZRLaIyEy363GTiHQWkWUiskFE1ovI3W7X5DYRCRWRz0XkHbdrcZuItBeROSKySUQ2iojvb2nkR0TkHs+/k3Ui8rKIRLldk68FRNB73cD8MqAfcIPnxuTBqhr4sar2A84H7gjyzwPgbmCj20W0Eo8B81W1D3A2Qfy5iEgacBeQpapn4UzFPsXdqnwvIIIerxuYq2olcOwG5kFJVfeo6mrP88M4/5CD9l69IpIOXAE87XYtbhOROOBinHtIoKqVqnrA3apcFwa08dwdLxrY7XI9PhcoQd/QDcyDNti8iUhXYBCwwt1KXPUo8DOg1u1CWoFMoAh41tOV9bSIxLhdlFtUdRfwJ2AnsAc4qKoL3a3K9wIl6E0DRCQWeAP4kaoecrseN4jIBKBQVVe5XUsrEQacCzypqoOAI0DQntMSkXicv/4zgU5AjIjc6G5VvhcoQd/sm5AHCxEJxwn52ar6b7frcdEw4CoR2Y7TpTdaRP7lbkmuygfyVfXYX3hzcII/WI0BvlLVIlWtAv4NXOhyTT4XKEHfnBuYBw0REZw+2I2q+ojb9bhJVX+uqumq2hXn/4ulqhpwLbbmUtW9QJ6I9PYsugTnns7BaidwvohEe/7dXEIAnpxu8ubg/qCxG5i7XJabhgHTgbUissaz7Beq+q6LNZnW44fAbE+jaBtwq8v1uEZVV4jIHGA1zmi1zwnAq2TtylhjjAlwgdJ1Y4wxphEW9MYYE+As6I0xJsBZ0BtjTICzoDfGmABnQW+MD4nISJsh07Q2FvTGGBPgLOhNUBKRG0XkMxFZIyJ/98xXXyoif/bMTb5ERJI8254jIstF5EsRedMzPwoi0kNEFovIFyKyWkS6ew4f6zXf+2zPFZfGuMaC3gQdEekLTAaGqeo5QA0wDYgBslW1P/A+cL9nlxeAe1V1ILDWa/ls4AlVPRtnfpQ9nuWDgB/h3BuhG86Vysa4JiCmQDDmJF0CDAZWehrbbYBCnGmMX/Vs8y/g357529ur6vue5c8Dr4tIWyBNVd8EUNVyAM/xPlPVfM/rNUBX4KOW/7WMaZgFvQlGAjyvqj+vt1DkV8dtd6rzg1R4Pa/B/p0Zl1nXjQlGS4BJIpIMICIdRKQLzr+HSZ5tpgIfqepBYL+IDPcsnw6877lzV76IXO05RqSIRJ/R38KYZrKWhgk6qrpBRO4DFopICFAF3IFzE47zPOsKcfrxAW4GZnmC3Hu2x+nA30XkAc8xrjuDv4YxzWazVxrjISKlqhrrdh3G+Jp13RhjTICzFr0xxgQ4a9EbY0yAs6A3xpgAZ0FvjDEBzoLeGGMCnAW9McYEOAt6Y4wJcP8fAXZe6PgeklUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss = [[i, item['Training Loss'], item['Valid. Loss']] for i, item in enumerate(training_stats)]\n",
        "acc = [[item[\"Best epoch\"], 'Valid. Accur.'] for item in training_stats]\n",
        "\n",
        "pd.DataFrame(loss, columns=[\"epoch\", \"train_loss\",\"val_loss\"]).set_index(\"epoch\").plot(kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_NnDGxRpEI"
      },
      "source": [
        "# 7. Train a model with all data for prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9CMlS_dkAGD",
        "outputId": "7774cc81-1fe1-4487-ffc5-ba64b7c2be45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lstm_cnn(\n",
              "  (lstm): LSTM(768, 100, batch_first=True, bidirectional=True)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(1, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 64, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 64, kernel_size=(5, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=192, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss: 0.6600\t Val Loss 0.5186\t Val Acc: 0.8400\t Val F1: 90.1235\n",
            "model saved\n",
            "Epoch 2\t Train Loss: 0.5130\t Val Loss 0.3386\t Val Acc: 0.8800\t Val F1: 92.7711\n",
            "model saved\n",
            "Epoch 3\t Train Loss: 0.3815\t Val Loss 0.1561\t Val Acc: 0.9400\t Val F1: 96.5116\n",
            "model saved\n",
            "Epoch 4\t Train Loss: 0.2424\t Val Loss 0.0984\t Val Acc: 0.9700\t Val F1: 98.2249\n",
            "model saved\n",
            "Epoch 5\t Train Loss: 0.1440\t Val Loss 0.0536\t Val Acc: 0.9800\t Val F1: 98.8235\n",
            "model saved\n",
            "Epoch 6\t Train Loss: 0.0706\t Val Loss 0.2302\t Val Acc: 0.9100\t Val F1: 94.4099\n",
            "Epoch 7\t Train Loss: 0.0650\t Val Loss 0.0156\t Val Acc: 0.9900\t Val F1: 99.4152\n",
            "model saved\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "emb_dim = vectors.size(-1)\n",
        "seq_len = vectors.size(1)\n",
        "num_filters = 64\n",
        "kernel_sizes = [1, 3, 5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,1.0]\n",
        "\n",
        "epochs = 7\n",
        "\n",
        "result = []\n",
        "X_train =  torch.tensor(vectors)\n",
        "Y_train = torch.tensor(pd.get_dummies(df.label).values)\n",
        "\n",
        "X_val =  torch.tensor(vectors[0:100])\n",
        "Y_val = torch.tensor(pd.get_dummies(df.label).values[0:100])\n",
        "\n",
        "# not needed. just to fulfill the traning function need\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "val_dataset = TensorDataset(X_val, Y_val)  \n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,  # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset, # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "    batch_size = batch_size # Evaluate with this batch size.\n",
        ")\n",
        "\n",
        "model_name = '/content/drive/MyDrive/temp/bert_model/genbert_forpred_v2'\n",
        "model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model, training_stats = train_single_label_model(model, num_labels, labels, train_dataloader, validation_dataloader, \\\n",
        "                                                         model_path = model_name, class_weight = class_weight,\n",
        "                                                        optimizer=None, scheduler=None, \\\n",
        "                                                        epochs = epochs, patience = 8)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNMfeMGJ9ipY"
      },
      "source": [
        "# Predict sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hEii1FGP88n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OsAkD8KSPW5",
        "outputId": "a4643571-c967-4cca-8401-e4299f352faf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "bert_pred = pd.read_csv('/content/drive/MyDrive/temp/raw_text_forbert.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DD120gtXSPhu",
        "outputId": "49531a47-732b-49a2-b68e-7a0d17b5da88"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15e888d5-6d3b-46e4-a178-7d68101f9fa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_unique_ticker_ts</th>\n",
              "      <th>rid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chun Hong, you're accusing DRAM of being high ...</td>\n",
              "      <td>new386</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So you are talking about trending issue rather...</td>\n",
              "      <td>new386</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you predict the -- I assume it will be...</td>\n",
              "      <td>new386</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[indiscernible].</td>\n",
              "      <td>new386</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That covers the cooling?</td>\n",
              "      <td>new386</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e888d5-6d3b-46e4-a178-7d68101f9fa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15e888d5-6d3b-46e4-a178-7d68101f9fa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15e888d5-6d3b-46e4-a178-7d68101f9fa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text encoded_unique_ticker_ts  \\\n",
              "0  Chun Hong, you're accusing DRAM of being high ...                   new386   \n",
              "1  So you are talking about trending issue rather...                   new386   \n",
              "2  What do you predict the -- I assume it will be...                   new386   \n",
              "3                                   [indiscernible].                   new386   \n",
              "4                           That covers the cooling?                   new386   \n",
              "\n",
              "   rid  \n",
              "0    1  \n",
              "1    2  \n",
              "2    3  \n",
              "3    4  \n",
              "4    5  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV3NSd1vYOTL",
        "outputId": "eadfa89d-e390-46f1-ed7e-6aa817633676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text                        30\n",
              "encoded_unique_ticker_ts     0\n",
              "rid                          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_pred.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_TakBdoYS4g"
      },
      "outputs": [],
      "source": [
        "bert_pred = bert_pred.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyEiB-RHi-pN",
        "outputId": "9faa1bfb-44ad-41e8-df95-b77044819af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4334161, 3)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "1NEW0bWBAahp",
        "outputId": "b8e3c941-7796-4439-b98c-d54801c20d9f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-260ab1f5cc04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mthe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mthe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mthe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lstm_cnn' is not defined"
          ]
        }
      ],
      "source": [
        "model_path= '/content/drive/MyDrive/temp/bert_model/genbert_forpred_v2'\n",
        "emb_dim = 768\n",
        "seq_len = 100\n",
        "num_filters = 64\n",
        "kernel_sizes = [1,3,5]\n",
        "num_labels = 2\n",
        "labels = ['0','1']\n",
        "class_weight = [1.0,2] \n",
        "    \n",
        "the_model = lstm_cnn(emb_dim, seq_len, 100, num_filters, kernel_sizes, num_labels)\n",
        "the_model.load_state_dict(torch.load(model_path))\n",
        "the_model = the_model.to(device)\n",
        "the_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsBfoOzUYrcT"
      },
      "outputs": [],
      "source": [
        "conf_ids = bert_pred[\"encoded_unique_ticker_ts\"].unique().tolist()\n",
        "len(conf_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmDte7QlYneS",
        "outputId": "c50275c0-c9d7-4e1a-d5c0-99807b28eb96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "target_file = '/content/drive/MyDrive/temp/predict_skp_gen_v2.csv'\n",
        "checkpoint = 0\n",
        "\n",
        "if os.path.isfile(target_file):\n",
        "  result = pd.read_csv(target_file)\n",
        "\n",
        "  if len(bert_pred) >0:\n",
        "    checkpoint = conf_ids.index(result[\"rid\"].iloc[-1])\n",
        "    checkpoint += 1\n",
        "  else:\n",
        "    result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "    result.to_csv(target_file, header=True, index = False)\n",
        "else:\n",
        "  result = pd.DataFrame([], columns = [\"encoded_unique_ticker_ts\",\"rid\", \"text\", \"predict\"])\n",
        "  result.to_csv(target_file, header=True, index = False)\n",
        "\n",
        "print(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoKkAiqbdVnQ",
        "outputId": "d2ad8ea2-81e4-425c-82cb-8e69899a5404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4334161, 4)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi722JC2YngX",
        "outputId": "8decd8ff-691a-4290-f649-0b5d324f6acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100:  68.46\n",
            "200:  145.18\n",
            "300:  215.88\n",
            "400:  292.69\n",
            "500:  372.65\n",
            "600:  450.12\n",
            "700:  515.31\n",
            "800:  585.78\n",
            "900:  664.95\n",
            "1000:  746.13\n",
            "1100:  822.90\n",
            "1200:  899.05\n",
            "1300:  983.69\n",
            "1400:  1058.92\n",
            "1500:  1130.58\n",
            "1600:  1195.09\n",
            "1700:  1271.10\n",
            "1800:  1344.76\n",
            "1900:  1416.31\n",
            "2000:  1495.99\n",
            "2100:  1578.61\n",
            "2200:  1644.30\n",
            "2300:  1710.51\n",
            "2400:  1789.53\n",
            "2500:  1874.00\n",
            "2600:  1950.14\n",
            "2700:  2019.27\n",
            "2800:  2081.03\n",
            "2900:  2157.85\n",
            "3000:  2227.28\n",
            "3100:  2310.10\n",
            "3200:  2383.64\n",
            "3300:  2462.97\n",
            "3400:  2550.28\n",
            "3500:  2630.66\n",
            "3600:  2718.38\n",
            "3700:  2802.27\n",
            "3800:  2888.60\n",
            "3900:  2976.14\n",
            "4000:  3033.84\n",
            "4100:  3108.99\n",
            "4200:  3192.83\n",
            "4300:  3260.18\n",
            "4400:  3352.94\n",
            "4500:  3423.97\n",
            "4600:  3521.37\n",
            "4700:  3640.23\n",
            "4800:  3727.47\n",
            "4900:  3806.14\n",
            "5000:  3904.75\n",
            "5100:  3984.05\n",
            "5200:  4046.22\n",
            "5300:  4126.88\n",
            "5400:  4225.50\n",
            "5500:  4286.50\n",
            "5600:  4364.13\n",
            "5700:  4461.23\n",
            "5800:  4540.54\n",
            "5900:  4629.08\n",
            "6000:  4686.93\n",
            "6100:  4751.60\n",
            "6200:  4850.60\n",
            "6300:  4924.81\n",
            "6400:  5001.53\n",
            "6500:  5087.23\n",
            "6600:  5195.86\n",
            "6700:  5266.32\n",
            "6800:  5338.98\n",
            "6900:  5410.26\n",
            "7000:  5510.74\n",
            "7100:  5593.15\n",
            "7200:  5672.06\n",
            "7300:  5765.88\n",
            "7400:  5843.53\n",
            "7500:  5927.47\n",
            "7600:  5997.38\n",
            "7700:  6069.98\n",
            "7800:  6163.01\n",
            "7900:  6246.31\n",
            "8000:  6309.45\n",
            "8100:  6389.49\n",
            "8200:  6475.31\n",
            "8300:  6546.90\n",
            "8400:  6646.64\n",
            "8500:  6719.49\n",
            "8600:  6816.05\n",
            "8700:  6904.70\n",
            "8800:  6993.90\n",
            "8900:  7071.88\n",
            "9000:  7146.98\n",
            "9100:  7221.70\n",
            "9200:  7313.73\n",
            "9300:  7407.44\n",
            "9400:  7480.31\n",
            "9500:  7559.88\n",
            "9600:  7635.61\n",
            "9700:  7694.66\n",
            "9800:  7783.46\n",
            "9900:  7870.52\n",
            "10000:  7943.72\n",
            "10100:  8036.29\n",
            "10200:  8110.05\n",
            "10300:  8175.85\n",
            "10400:  8232.20\n",
            "10500:  8315.67\n",
            "10600:  8380.06\n",
            "10700:  8436.47\n",
            "10800:  8501.96\n",
            "10900:  8574.19\n",
            "11000:  8657.71\n",
            "11100:  8754.33\n",
            "11200:  8825.23\n",
            "11300:  8891.81\n",
            "11400:  8974.05\n",
            "11500:  9039.46\n",
            "11600:  9116.83\n",
            "11700:  9181.91\n",
            "11800:  9255.46\n",
            "11900:  9331.99\n",
            "12000:  9414.28\n",
            "12100:  9491.74\n",
            "12200:  9562.75\n",
            "12300:  9636.78\n",
            "12400:  9709.38\n",
            "12500:  9789.17\n",
            "12600:  9871.74\n",
            "12700:  9943.48\n",
            "12800:  10018.76\n",
            "12900:  10096.77\n",
            "13000:  10170.33\n",
            "13100:  10254.74\n",
            "13200:  10331.01\n",
            "13300:  10407.73\n",
            "13400:  10471.97\n",
            "13500:  10553.04\n",
            "13600:  10637.32\n",
            "13700:  10706.82\n",
            "13800:  10795.53\n",
            "13900:  10885.98\n",
            "14000:  10986.84\n",
            "14100:  11045.25\n",
            "14200:  11126.34\n",
            "14300:  11203.78\n",
            "14400:  11294.17\n",
            "14500:  11413.72\n",
            "14600:  11492.11\n",
            "14700:  11581.07\n",
            "14800:  11655.86\n",
            "14900:  11756.52\n",
            "15000:  11845.81\n",
            "15100:  11920.17\n",
            "15200:  11996.36\n",
            "15300:  12086.02\n",
            "15400:  12157.93\n",
            "15500:  12238.92\n",
            "15600:  12303.69\n",
            "15700:  12377.01\n",
            "15800:  12463.64\n",
            "15900:  12538.66\n",
            "16000:  12623.53\n",
            "16100:  12699.33\n",
            "16200:  12807.25\n",
            "16300:  12880.16\n",
            "16400:  12970.93\n",
            "16500:  13033.58\n",
            "16600:  13091.24\n",
            "16700:  13163.71\n",
            "16800:  13229.27\n",
            "16900:  13311.65\n",
            "17000:  13388.00\n",
            "17100:  13461.88\n",
            "17200:  13530.94\n",
            "17300:  13590.73\n",
            "17400:  13667.95\n",
            "17500:  13746.04\n",
            "17600:  13826.99\n",
            "17700:  13894.72\n",
            "17800:  13982.57\n",
            "17900:  14056.59\n",
            "18000:  14137.26\n",
            "18100:  14219.59\n",
            "18200:  14286.65\n",
            "18300:  14361.22\n",
            "18400:  14429.56\n",
            "18500:  14520.80\n",
            "18600:  14594.32\n",
            "18700:  14669.98\n",
            "18800:  14748.08\n",
            "18900:  14814.57\n",
            "19000:  14898.29\n",
            "19100:  14975.28\n",
            "19200:  15043.29\n",
            "19300:  15113.74\n",
            "19400:  15174.52\n",
            "19500:  15258.98\n",
            "19600:  15334.03\n",
            "19700:  15396.82\n",
            "19800:  15499.83\n",
            "19900:  15599.72\n",
            "20000:  15671.74\n",
            "20100:  15753.63\n",
            "20200:  15822.39\n",
            "20300:  15898.74\n",
            "20400:  15958.53\n",
            "20500:  16036.86\n",
            "20600:  16122.94\n",
            "20700:  16186.97\n",
            "20800:  16261.55\n",
            "20900:  16338.27\n",
            "21000:  16391.06\n",
            "21100:  16457.43\n",
            "21200:  16528.55\n",
            "21300:  16601.84\n",
            "21400:  16665.80\n",
            "21500:  16731.91\n",
            "21600:  16804.30\n",
            "21700:  16875.92\n",
            "21800:  16934.02\n",
            "21900:  17004.16\n",
            "22000:  17068.10\n",
            "22100:  17142.54\n",
            "22200:  17216.76\n",
            "22300:  17284.80\n",
            "22400:  17358.42\n",
            "22500:  17443.91\n",
            "22600:  17524.40\n",
            "22700:  17600.86\n",
            "22800:  17661.09\n",
            "22900:  17730.48\n",
            "23000:  17806.29\n",
            "23100:  17883.86\n",
            "23200:  17968.44\n",
            "23300:  18041.14\n",
            "23400:  18125.06\n",
            "23500:  18191.21\n",
            "23600:  18253.25\n",
            "23700:  18326.43\n",
            "23800:  18393.93\n",
            "23900:  18469.11\n",
            "24000:  18546.37\n",
            "24100:  18629.35\n",
            "24200:  18705.46\n",
            "24300:  18782.22\n",
            "24400:  18857.69\n",
            "24500:  18934.24\n",
            "24600:  19024.78\n",
            "24700:  19081.02\n",
            "24800:  19153.47\n",
            "24900:  19226.20\n",
            "25000:  19311.40\n",
            "25100:  19390.10\n",
            "25200:  19465.36\n",
            "25300:  19542.69\n",
            "25400:  19622.04\n",
            "25500:  19680.36\n",
            "25600:  19748.72\n",
            "25700:  19827.96\n",
            "25800:  19912.28\n",
            "25900:  19982.67\n",
            "26000:  20097.75\n",
            "26100:  20175.56\n",
            "26200:  20247.12\n",
            "26300:  20340.42\n",
            "26400:  20428.37\n",
            "26500:  20515.17\n",
            "26600:  20588.53\n",
            "26700:  20668.79\n",
            "26800:  20734.32\n",
            "26900:  20802.10\n",
            "27000:  20873.07\n",
            "27100:  20947.11\n",
            "27200:  21021.53\n",
            "27300:  21091.54\n",
            "27400:  21158.36\n",
            "27500:  21256.08\n",
            "27600:  21323.15\n",
            "27700:  21390.25\n",
            "27800:  21459.75\n",
            "27900:  21540.58\n",
            "28000:  21622.12\n",
            "28100:  21694.86\n",
            "28200:  21777.85\n",
            "28300:  21850.90\n",
            "28400:  21920.63\n",
            "28500:  21999.12\n",
            "28600:  22086.26\n",
            "28700:  22159.00\n",
            "28800:  22233.42\n",
            "28900:  22322.29\n",
            "29000:  22400.65\n",
            "29100:  22471.78\n",
            "29200:  22538.75\n",
            "29300:  22617.23\n",
            "29400:  22692.75\n",
            "29500:  22769.43\n",
            "29600:  22859.06\n",
            "29700:  22946.63\n",
            "29800:  23015.71\n",
            "29900:  23086.01\n",
            "30000:  23165.23\n",
            "30100:  23243.87\n",
            "30200:  23310.19\n",
            "30300:  23409.89\n",
            "30400:  23493.14\n",
            "30500:  23567.16\n",
            "30600:  23647.73\n",
            "30700:  23729.42\n",
            "30800:  23800.91\n",
            "30900:  23876.84\n",
            "31000:  23941.48\n",
            "31100:  24022.47\n",
            "31200:  24101.11\n",
            "31300:  24180.61\n",
            "31400:  24247.40\n",
            "31500:  24316.94\n",
            "31600:  24396.94\n",
            "31700:  24480.15\n",
            "31800:  24547.06\n",
            "31900:  24620.68\n",
            "32000:  24699.39\n",
            "32100:  24766.18\n",
            "32200:  24829.49\n",
            "32300:  24932.18\n",
            "32400:  25007.66\n",
            "32500:  25093.35\n",
            "32600:  25165.42\n",
            "32700:  25244.33\n",
            "32800:  25303.35\n",
            "32900:  25378.95\n",
            "33000:  25485.27\n",
            "33100:  25564.60\n",
            "33200:  25654.02\n",
            "33300:  25726.26\n",
            "33400:  25798.25\n",
            "33500:  25876.37\n",
            "33600:  25943.69\n",
            "33700:  26012.35\n",
            "33800:  26079.72\n",
            "33900:  26166.40\n",
            "34000:  26230.73\n",
            "34100:  26305.68\n",
            "34200:  26378.15\n",
            "34300:  26436.03\n",
            "34400:  26508.40\n",
            "34500:  26587.18\n",
            "34600:  26661.06\n",
            "34700:  26751.09\n",
            "34800:  26846.08\n",
            "34900:  26914.08\n",
            "35000:  26998.31\n",
            "35100:  27085.78\n",
            "35200:  27148.08\n",
            "35300:  27211.71\n",
            "35400:  27300.93\n",
            "35500:  27383.44\n",
            "35600:  27461.51\n",
            "35700:  27535.95\n",
            "35800:  27601.08\n",
            "35900:  27685.88\n",
            "36000:  27770.44\n",
            "36100:  27855.36\n",
            "36200:  27922.03\n",
            "36300:  27997.38\n",
            "36400:  28077.20\n",
            "36500:  28149.78\n",
            "36600:  28236.35\n",
            "36700:  28320.83\n",
            "36800:  28391.39\n",
            "36900:  28449.64\n",
            "37000:  28523.99\n",
            "37100:  28582.89\n",
            "37200:  28646.26\n",
            "37300:  28712.13\n",
            "37400:  28790.98\n",
            "37500:  28869.95\n",
            "37600:  28964.89\n",
            "37700:  29037.32\n",
            "37800:  29103.82\n",
            "37900:  29179.14\n",
            "38000:  29256.23\n",
            "38100:  29330.11\n",
            "38200:  29402.92\n",
            "38300:  29463.56\n",
            "38400:  29524.06\n",
            "38500:  29592.12\n",
            "38600:  29694.64\n",
            "38700:  29777.50\n",
            "38800:  29850.62\n",
            "38900:  29910.07\n",
            "39000:  29983.37\n",
            "39100:  30071.19\n",
            "39200:  30149.77\n",
            "39300:  30234.46\n",
            "39400:  30310.49\n",
            "39500:  30395.41\n",
            "39600:  30472.59\n",
            "39700:  30561.16\n",
            "39800:  30641.86\n",
            "39900:  30712.72\n",
            "40000:  30781.96\n",
            "40100:  30869.19\n",
            "40200:  30934.56\n",
            "40300:  31025.66\n",
            "40400:  31098.32\n",
            "40500:  31175.16\n",
            "40600:  31259.85\n",
            "40700:  31332.83\n",
            "40800:  31413.88\n",
            "40900:  31477.89\n",
            "41000:  31543.47\n",
            "41100:  31622.35\n",
            "41200:  31700.01\n",
            "41300:  31771.73\n",
            "41400:  31868.12\n",
            "41500:  31940.44\n",
            "41600:  32015.31\n",
            "41700:  32104.75\n",
            "41800:  32206.37\n",
            "41900:  32288.42\n",
            "42000:  32359.31\n",
            "42100:  32439.35\n",
            "42200:  32519.00\n",
            "42300:  32588.39\n",
            "42400:  32656.91\n",
            "42500:  32734.11\n",
            "42600:  32811.68\n",
            "42700:  32875.44\n",
            "42800:  32945.55\n",
            "42900:  33031.14\n",
            "43000:  33100.53\n",
            "43100:  33172.28\n",
            "43200:  33239.56\n",
            "43300:  33322.87\n",
            "43400:  33400.77\n",
            "43500:  33492.01\n",
            "43600:  33575.70\n",
            "43700:  33639.34\n",
            "43800:  33728.77\n",
            "43900:  33795.05\n",
            "44000:  33859.70\n",
            "44100:  33927.85\n",
            "44200:  33992.79\n",
            "44300:  34067.50\n",
            "44400:  34147.99\n",
            "44500:  34224.75\n",
            "44600:  34297.03\n",
            "44700:  34377.00\n",
            "44800:  34452.03\n",
            "44900:  34517.71\n",
            "45000:  34569.62\n",
            "45100:  34629.90\n",
            "45200:  34717.35\n",
            "45300:  34804.22\n",
            "45400:  34877.11\n",
            "45500:  34954.22\n",
            "45600:  35022.88\n",
            "45700:  35100.83\n",
            "45800:  35164.89\n",
            "45900:  35220.41\n",
            "46000:  35300.14\n",
            "46100:  35362.34\n",
            "46200:  35433.69\n",
            "46300:  35510.72\n",
            "46400:  35566.47\n",
            "46500:  35644.64\n",
            "46600:  35721.55\n",
            "46700:  35801.37\n",
            "46800:  35880.54\n",
            "46900:  35948.04\n",
            "47000:  36022.85\n",
            "47100:  36084.77\n",
            "47200:  36156.58\n",
            "47300:  36223.64\n",
            "47400:  36291.74\n",
            "47500:  36377.89\n",
            "47600:  36457.47\n",
            "47700:  36523.66\n",
            "47800:  36594.38\n",
            "47900:  36662.83\n",
            "48000:  36740.85\n",
            "48100:  36815.55\n",
            "48200:  36883.96\n",
            "48300:  36969.03\n",
            "48400:  37042.15\n",
            "48500:  37115.53\n",
            "48600:  37181.87\n",
            "48700:  37255.94\n",
            "48800:  37332.81\n",
            "48900:  37403.66\n",
            "49000:  37465.81\n",
            "49100:  37529.69\n",
            "49200:  37603.62\n",
            "49300:  37664.90\n",
            "49400:  37736.18\n",
            "49500:  37807.43\n",
            "49600:  37883.00\n",
            "49700:  37955.52\n",
            "49800:  38029.37\n",
            "49900:  38114.35\n",
            "50000:  38182.08\n",
            "50100:  38249.16\n",
            "50200:  38335.78\n",
            "50300:  38420.92\n",
            "50400:  38485.13\n",
            "50500:  38556.20\n",
            "50600:  38641.33\n",
            "50700:  38707.57\n",
            "50800:  38786.06\n",
            "50900:  38842.77\n",
            "51000:  38897.94\n",
            "51100:  38964.71\n",
            "51200:  39041.60\n",
            "51300:  39119.85\n",
            "51400:  39183.40\n",
            "51500:  39270.06\n",
            "51600:  39330.23\n",
            "51700:  39398.62\n",
            "51800:  39477.84\n",
            "51900:  39552.09\n",
            "52000:  39618.77\n",
            "52100:  39692.49\n",
            "52200:  39764.99\n",
            "52300:  39844.50\n",
            "52400:  39921.10\n",
            "52500:  39982.75\n",
            "52600:  40049.32\n",
            "52700:  40105.62\n",
            "52800:  40184.84\n",
            "52900:  40254.52\n",
            "53000:  40336.20\n",
            "53100:  40413.85\n",
            "53200:  40498.92\n",
            "53300:  40582.74\n",
            "53400:  40651.41\n",
            "53500:  40735.40\n",
            "53600:  40812.94\n",
            "53700:  40886.49\n",
            "53800:  40948.29\n",
            "53900:  41018.21\n",
            "54000:  41102.69\n",
            "54100:  41175.25\n",
            "54200:  41252.05\n",
            "54300:  41329.10\n",
            "54400:  41411.32\n",
            "54500:  41480.78\n",
            "54600:  41558.83\n",
            "54700:  41636.21\n",
            "54800:  41694.13\n",
            "54900:  41777.08\n",
            "55000:  41856.63\n",
            "55100:  41926.69\n",
            "55200:  41986.17\n",
            "55300:  42051.19\n",
            "55400:  42116.99\n",
            "55500:  42185.68\n",
            "55600:  42259.32\n",
            "55700:  42347.94\n",
            "55800:  42418.74\n",
            "55900:  42505.33\n",
            "56000:  42577.09\n",
            "56100:  42645.37\n",
            "56200:  42712.06\n",
            "56300:  42783.09\n",
            "56400:  42849.32\n",
            "56500:  42923.61\n",
            "56600:  42998.05\n",
            "56700:  43071.73\n",
            "56800:  43141.35\n",
            "56900:  43214.44\n",
            "57000:  43292.29\n",
            "57100:  43372.70\n",
            "57200:  43447.57\n",
            "57300:  43525.14\n",
            "57400:  43595.33\n",
            "57500:  43674.02\n",
            "57600:  43760.16\n",
            "57700:  43819.86\n",
            "57800:  43877.87\n",
            "57900:  43937.23\n",
            "58000:  44001.40\n",
            "58100:  44079.69\n",
            "58200:  44140.44\n",
            "58300:  44207.24\n",
            "58400:  44290.27\n",
            "58500:  44381.43\n",
            "58600:  44443.78\n",
            "58700:  44511.22\n",
            "58800:  44586.04\n",
            "58900:  44660.67\n",
            "59000:  44723.94\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "batch_size  = 200\n",
        "\n",
        "for cid in conf_ids[checkpoint:]:\n",
        "  result = bert_pred[bert_pred.encoded_unique_ticker_ts==cid].copy()\n",
        "  preds = []\n",
        "  for i in range(0, len(result), batch_size):\n",
        "    # get embedding\n",
        "    x, masks = get_pretrained_wordvector(result[\"text\"].iloc[i:(i+batch_size)], tokenizer, bert_model)\n",
        "    x =  x * (masks.unsqueeze(-1).to(device))  ## 这里利用的是 broadcasting\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = the_model(x)\n",
        "      pred = torch.softmax(pred, dim = -1)\n",
        "      pred = pred[:,-1].detach().cpu().numpy()\n",
        "\n",
        "      preds.append(pred)\n",
        "     \n",
        "  result[\"predict\"] = np.concatenate(preds, axis = 0)\n",
        "  result.to_csv(target_file, header=False, index= False, mode='a')\n",
        "\n",
        "  checkpoint += 1\n",
        "\n",
        "  if checkpoint%100 ==0:\n",
        "    print(\"{0}: {1: .2f}\".format(checkpoint, time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXqK0r9YZH0U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS7Mm5gdYnlS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLrMP2avP8_U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bee06b1c197441996f4aaf65e4b7909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3c61014751624528a7ddd3b131354d06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f92b1f942c4680bd4acb939319cb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "676db17bed42496c9c573c16942ac10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c61014751624528a7ddd3b131354d06",
            "placeholder": "​",
            "style": "IPY_MODEL_68bfc5eb341f4f79ab831026fa3fb169",
            "value": ""
          }
        },
        "68bfc5eb341f4f79ab831026fa3fb169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a424c272de154766ba398d315490580c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9af45b31f434b67917cf13b770bb58d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2b44daf1eb42b4856f8e904c42bba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_676db17bed42496c9c573c16942ac10c",
              "IPY_MODEL_dcd98b2453024598ad3de4b6a5819cc2",
              "IPY_MODEL_eadecbee1e9748f580b2ff3711026247"
            ],
            "layout": "IPY_MODEL_a9af45b31f434b67917cf13b770bb58d"
          }
        },
        "dcd98b2453024598ad3de4b6a5819cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bee06b1c197441996f4aaf65e4b7909",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a424c272de154766ba398d315490580c",
            "value": 0
          }
        },
        "eab53918d4db48edb41b55010714c0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadecbee1e9748f580b2ff3711026247": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab53918d4db48edb41b55010714c0c2",
            "placeholder": "​",
            "style": "IPY_MODEL_56f92b1f942c4680bd4acb939319cb45",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}